{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D5OXbsWb97UD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. ë°ì´í„° ë‹¤ìš´ë¡œë“œ & í´ë” êµ¬ì¡° ì„¸íŒ…\n",
        "- Colabì—ì„œ Kaggle APIë¥¼ ì“°ê¸° ìœ„í•œ kaggle.json ì—…ë¡œë“œ\n",
        "- PCB ë¶ˆëŸ‰ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ í›„ /content/pcb_data ë°‘ì— ì••ì¶•í•´ì œ"
      ],
      "metadata": {
        "id": "Z7sXmxmH98HR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "y-a_ru-NcBCe",
        "outputId": "eaf402d3-f84a-479a-984b-0a3cfd740853"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-833cad41-3d15-4932-a443-f80dfb750649\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-833cad41-3d15-4932-a443-f80dfb750649\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Dataset URL: https://www.kaggle.com/datasets/akhatova/pcb-defects\n",
            "License(s): unknown\n",
            "Downloading pcb-defects.zip to /content\n",
            " 98% 1.84G/1.88G [00:15<00:00, 108MB/s] \n",
            "100% 1.88G/1.88G [00:15<00:00, 128MB/s]\n",
            "âœ” ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì™„ë£Œ\n"
          ]
        }
      ],
      "source": [
        "!pip install -q ultralytics\n",
        "!pip install -q opencv-python pyyaml\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()   # kaggle.json ì—…ë¡œë“œ\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d akhatova/pcb-defects\n",
        "!unzip -q pcb-defects.zip -d pcb_data\n",
        "\n",
        "print(\"âœ” ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ì›ë³¸ ì´ë¯¸ì§€ / ë¼ë²¨ ê²½ë¡œ ì •ì˜\n",
        "- YOLO í˜•ì‹ ë°ì´í„°ì…‹ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬ (dataset_yolo_seg)ì™€ ê·¸ ì•ˆì˜ train / val /test í´ë” êµ¬ì¡° ìƒì„±"
      ],
      "metadata": {
        "id": "P5q6KeoK-Jr4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. XML â†’ YOLO ë¼ë²¨ ë³€í™˜ & ë°ì´í„° ë‚˜ëˆ„ê¸°\n",
        "\n",
        "2-1. í´ë˜ìŠ¤ ì´ë¦„ ìˆ˜ì§‘ ë° ì¸ë±ìŠ¤ ë§¤í•‘\n",
        "\n",
        "XML ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ì„ ì „ë¶€ ëŒë©´ì„œ íƒœê·¸ë¥¼ ì½ì–´ í´ë˜ìŠ¤ ì´ë¦„ ìë™ ìˆ˜ì§‘\n",
        "\n",
        "ì†Œë¬¸ì + ê³µë°± _ ë¡œ normalize\n",
        "\n",
        "{'missing_hole': 0, 'mouse_bite': 1, ...} ì´ëŸ° ì‹ìœ¼ë¡œ í´ë˜ìŠ¤ â†’ ìˆ«ì ID ë§¤í•‘"
      ],
      "metadata": {
        "id": "eKjGLZqs-jx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from glob import glob\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import xml.etree.ElementTree as ET\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "ROOT = \"/content/pcb_data/PCB_DATASET\"\n",
        "IMG_DIR = f\"{ROOT}/images\"\n",
        "ANN_DIR = f\"{ROOT}/Annotations\"\n",
        "\n",
        "OUT_YOLO = \"/content/dataset_yolo_seg\"\n",
        "os.makedirs(OUT_YOLO, exist_ok=True)\n",
        "for split in [\"train\",\"val\",\"test\"]:\n",
        "    os.makedirs(f\"{OUT_YOLO}/images/{split}\", exist_ok=True)\n",
        "    os.makedirs(f\"{OUT_YOLO}/labels/{split}\", exist_ok=True)\n",
        "\n",
        "def normalize(c):\n",
        "    return c.lower().replace(\" \", \"_\")\n",
        "\n",
        "# í´ë˜ìŠ¤ ìë™ ìˆ˜ì§‘\n",
        "xml_classes = set()\n",
        "for xml in glob(f\"{ANN_DIR}/**/*.xml\", recursive=True):\n",
        "    root = ET.parse(xml).getroot()\n",
        "    for obj in root.findall(\"object\"):\n",
        "        xml_classes.add(normalize(obj.findtext(\"name\")))\n",
        "\n",
        "CLASS2ID = {cls:i for i,cls in enumerate(sorted(xml_classes))}\n",
        "print(\"CLASS2ID:\", CLASS2ID)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6xQPuF-cIeK",
        "outputId": "c76e9de8-40ed-439c-bf86-38b06e766404"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLASS2ID: {'missing_hole': 0, 'mouse_bite': 1, 'open_circuit': 2, 'short': 3, 'spur': 4, 'spurious_copper': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2-2. XML bndbox â†’ YOLO í˜•ì‹ ë³€í™˜ í•¨ìˆ˜\n",
        "\n",
        "ì›ë³¸ XMLì˜ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ì½ì–´ì„œ\n",
        "â†’ YOLOê°€ ìš”êµ¬í•˜ëŠ” í˜•ì‹ (class_id, x_center, y_center, width, height)ë¡œ ë³€í™˜\n",
        "\n",
        "ì¢Œí‘œëŠ” ì „ë¶€ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë‚˜ëˆˆ ì •ê·œí™”(normalized) í˜•íƒœ\n",
        "\n",
        "2-3. train / val / test split & ì €ì¥\n",
        "\n",
        "ì´ë¯¸ì§€â€“XML ìŒì„ ë¨¼ì € ë§Œë“  ë’¤,\n",
        "\n",
        "70% train, 20% test, 10% val ì •ë„ ë¹„ìœ¨ë¡œ ë¶„í• \n",
        "\n",
        "YOLO í¬ë§·ì— ë§ì¶°:\n",
        "\n",
        "ì´ë¯¸ì§€ëŠ” images/split/ì— ì €ì¥\n",
        "\n",
        "ë¼ë²¨ì€ labels/split/ì— .txtë¡œ ì €ì¥\n",
        "\n",
        "txt í•œ ì¤„ë‹¹ í•œ ê°œ ê°ì²´ì˜ ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´"
      ],
      "metadata": {
        "id": "zbKlIHpgCL8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def xml_to_yolo(xml_path, img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    h, w = img.shape[:2]\n",
        "    boxes = []\n",
        "\n",
        "    root = ET.parse(xml_path).getroot()\n",
        "    for obj in root.findall(\"object\"):\n",
        "        name = normalize(obj.findtext(\"name\"))\n",
        "        cls_id = CLASS2ID[name]\n",
        "\n",
        "        bbox = obj.find(\"bndbox\")\n",
        "        xmin = int(bbox.findtext(\"xmin\"))\n",
        "        ymin = int(bbox.findtext(\"ymin\"))\n",
        "        xmax = int(bbox.findtext(\"xmax\"))\n",
        "        ymax = int(bbox.findtext(\"ymax\"))\n",
        "\n",
        "        cx = (xmin + xmax)/2 / w\n",
        "        cy = (ymin + ymax)/2 / h\n",
        "        bw = (xmax - xmin)/w\n",
        "        bh = (ymax - ymin)/h\n",
        "\n",
        "        boxes.append((cls_id, cx, cy, bw, bh))\n",
        "    return boxes\n",
        "\n",
        "# ì´ë¯¸ì§€-XML pair ë§Œë“¤ê¸°\n",
        "pairs=[]\n",
        "for img in glob(f\"{IMG_DIR}/**/*.jpg\", recursive=True):\n",
        "    xml = img.replace(\"/images/\", \"/Annotations/\").replace(\".jpg\",\".xml\")\n",
        "    if os.path.exists(xml):\n",
        "        pairs.append((img,xml))\n",
        "\n",
        "train_p, temp = train_test_split(pairs, test_size=0.3, random_state=42)\n",
        "val_p, test_p = train_test_split(temp, test_size=0.33, random_state=42)\n",
        "\n",
        "def save_split(pairs, split):\n",
        "    for img_p, xml_p in tqdm(pairs, desc=f\"{split} split\"):\n",
        "        img = cv2.imread(img_p)\n",
        "        cls_folder = normalize(Path(img_p).parts[-2])\n",
        "        base = f\"{cls_folder}_{Path(img_p).stem}\"\n",
        "\n",
        "        out_img = f\"{OUT_YOLO}/images/{split}/{base}.jpg\"\n",
        "        out_txt = f\"{OUT_YOLO}/labels/{split}/{base}.txt\"\n",
        "\n",
        "        cv2.imwrite(out_img, img)\n",
        "        boxes = xml_to_yolo(xml_p, img_p)\n",
        "\n",
        "        with open(out_txt, \"w\") as f:\n",
        "            for b in boxes:\n",
        "                f.write(\" \".join(map(str, b)) + \"\\n\")\n",
        "\n",
        "save_split(train_p, \"train\")\n",
        "save_split(val_p, \"val\")\n",
        "save_split(test_p, \"test\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zjrc1mQccWtL",
        "outputId": "a3d161de-3d4c-4d23-8294-f7c97bafa23a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 485/485 [01:00<00:00,  7.96it/s]\n",
            "val split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:17<00:00,  7.88it/s]\n",
            "test split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:08<00:00,  8.02it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ultralytics YOLOê°€ ìš”êµ¬í•˜ëŠ” dataset.yaml íŒŒì¼ ìë™ ìƒì„±:\n",
        "\n",
        "ë°ì´í„° ê²½ë¡œ\n",
        "\n",
        "train/val/test ìƒëŒ€ ê²½ë¡œ\n",
        "\n",
        "í´ë˜ìŠ¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸"
      ],
      "metadata": {
        "id": "C3CNWcp6CryA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "names = [None] * len(CLASS2ID)\n",
        "for cls, idx in CLASS2ID.items():\n",
        "    names[idx] = cls\n",
        "\n",
        "yaml_data = {\n",
        "    \"path\": OUT_YOLO,\n",
        "    \"train\": \"images/train\",\n",
        "    \"val\": \"images/val\",\n",
        "    \"test\": \"images/test\",\n",
        "    \"names\": names\n",
        "}\n",
        "\n",
        "with open(f\"{OUT_YOLO}/dataset.yaml\",\"w\") as f:\n",
        "    yaml.dump(yaml_data, f)\n",
        "\n",
        "print(open(f\"{OUT_YOLO}/dataset.yaml\").read())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1XjoTNbcW_6",
        "outputId": "ccd146c4-91cc-43f7-a2a1-c7258b5c8570"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "names:\n",
            "- missing_hole\n",
            "- mouse_bite\n",
            "- open_circuit\n",
            "- short\n",
            "- spur\n",
            "- spurious_copper\n",
            "path: /content/dataset_yolo_seg\n",
            "test: images/test\n",
            "train: images/train\n",
            "val: images/val\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "c9xFZIeGCqCT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. YOLO í•™ìŠµ & ROI ì¶”ì¶œ\n",
        "\n",
        "4-1. YOLO ëª¨ë¸ í•™ìŠµ\n",
        "\n",
        "ì‚¬ì „í•™ìŠµëœ yolov8s.ptë¥¼ ë¡œë“œí•´ì„œ\n",
        "\n",
        "â†’ ë°©ê¸ˆ ë§Œë“  PCB YOLO ë°ì´í„°ì…‹ìœ¼ë¡œ fine-tuning ì§„í–‰"
      ],
      "metadata": {
        "id": "t-eP5M-RC62F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from ultralytics import YOLO\n",
        "\n",
        "# DATA_YAML = f\"{OUT_YOLO}/dataset.yaml\"\n",
        "\n",
        "# # detection-only ëª¨ë¸ ì‚¬ìš©!\n",
        "# det_model = YOLO(\"yolov8s.pt\")   # ë˜ëŠ” yolov11s.pt\n",
        "\n",
        "# det_model.train(\n",
        "#     data=DATA_YAML,\n",
        "#     epochs=200,\n",
        "#     imgsz=1024,\n",
        "#     batch=8,\n",
        "#     lr0=1e-3,\n",
        "#     optimizer=\"Adam\",\n",
        "#     device=0\n",
        "# )\n",
        "\n",
        "# # í•™ìŠµ ì™„ë£Œ í›„ best weight\n",
        "# detector = YOLO(\"runs/detect/train/weights/best.pt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Qpq-BSAckUJ2",
        "outputId": "5238b123-646b-448f-fcb9-fe37dff9d2d3",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 21.5MB 102.8MB/s 0.2s\n",
            "Ultralytics 8.3.228 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/dataset_yolo_seg/dataset.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=200, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=1024, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 22.9MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2118370  ultralytics.nn.modules.head.Detect           [6, [128, 256, 512]]          \n",
            "Model summary: 129 layers, 11,137,922 parameters, 11,137,906 gradients, 28.7 GFLOPs\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 114.9MB/s 0.0s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3479.0Â±750.3 MB/s, size: 1406.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset_yolo_seg/labels/train... 485 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 485/485 2.3Kit/s 0.2s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/dataset_yolo_seg/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1880.6Â±1388.2 MB/s, size: 1518.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset_yolo_seg/labels/val... 139 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 139/139 1.1Kit/s 0.1s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/dataset_yolo_seg/labels/val.cache\n",
            "Plotting labels to /content/runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 1024 train, 1024 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/train\u001b[0m\n",
            "Starting training for 200 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      1/200      4.68G      2.734       9.47      1.536         25       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.7it/s 35.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 1.1s/it 9.5s\n",
            "                   all        139        608      0.294      0.205      0.186       0.08\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      2/200      6.53G      2.145      2.422      1.243         40       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.0it/s 30.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.9it/s 3.1s\n",
            "                   all        139        608       0.51      0.476      0.469      0.215\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      3/200      6.56G      1.987      1.928      1.176         27       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.7it/s 35.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.9it/s 3.1s\n",
            "                   all        139        608      0.731      0.586      0.685      0.292\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      4/200       6.6G      1.867      1.559      1.117         29       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.8it/s 34.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.8it/s 3.2s\n",
            "                   all        139        608      0.767       0.68      0.774      0.377\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      5/200      6.63G      1.842      1.389      1.116         39       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.7it/s 35.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.7it/s 3.3s\n",
            "                   all        139        608      0.853      0.736      0.823      0.389\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      6/200      6.67G       1.82      1.354        1.1         31       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.7it/s 35.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.0it/s 3.0s\n",
            "                   all        139        608      0.852      0.799      0.848      0.417\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      7/200      6.71G      1.758      1.216      1.085         36       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.7it/s 36.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.7it/s 3.4s\n",
            "                   all        139        608      0.785      0.798      0.838      0.388\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      8/200      6.74G      1.692      1.109      1.064         22       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.8it/s 34.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.6it/s 3.4s\n",
            "                   all        139        608      0.877      0.839      0.877      0.428\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      9/200      6.78G      1.683      1.052      1.063         34       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.8it/s 34.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.7it/s 3.4s\n",
            "                   all        139        608      0.893      0.836      0.904      0.458\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     10/200      6.81G      1.651      1.009      1.048         31       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.8it/s 34.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.8it/s 3.2s\n",
            "                   all        139        608      0.919      0.853      0.915      0.434\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     11/200      6.85G       1.66     0.9644      1.057         30       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.8it/s 34.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.6it/s 3.5s\n",
            "                   all        139        608      0.917      0.881       0.92      0.464\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     12/200      6.89G      1.626     0.9701      1.041         26       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.7it/s 35.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.9it/s 3.1s\n",
            "                   all        139        608      0.937       0.88      0.931      0.482\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     13/200      6.93G      1.596     0.9462      1.045         30       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.7it/s 35.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.8it/s 3.2s\n",
            "                   all        139        608      0.961      0.877      0.932      0.485\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     14/200      6.96G      1.635     0.9433      1.041         38       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.8it/s 34.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.7it/s 3.3s\n",
            "                   all        139        608      0.914      0.889      0.936      0.488\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     15/200         7G      1.587     0.9338      1.028         29       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.8it/s 34.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.7it/s 3.3s\n",
            "                   all        139        608      0.932      0.858      0.933      0.469\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     16/200      7.04G      1.574      0.872      1.025         43       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.8it/s 34.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.8it/s 3.2s\n",
            "                   all        139        608      0.945      0.907      0.946      0.494\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     17/200      7.07G      1.618     0.8781      1.048         24       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.8it/s 34.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.8it/s 3.2s\n",
            "                   all        139        608      0.943      0.884      0.947      0.516\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     18/200      7.11G      1.559     0.8618      1.029         22       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.7it/s 35.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.8it/s 3.3s\n",
            "                   all        139        608      0.948      0.904      0.949      0.492\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     19/200      7.14G      1.578      0.863      1.024         40       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.8it/s 34.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.8it/s 3.2s\n",
            "                   all        139        608      0.934      0.907      0.941      0.482\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     20/200      7.18G      1.564     0.8389      1.019         23       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.8it/s 34.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.5it/s 3.6s\n",
            "                   all        139        608      0.954      0.918      0.952       0.51\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     21/200      7.22G      1.551     0.8444      1.034         22       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.8it/s 34.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.5it/s 3.6s\n",
            "                   all        139        608      0.942      0.926      0.962      0.505\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     22/200      7.25G      1.561      0.817      1.035         26       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.8it/s 34.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.5it/s 3.5s\n",
            "                   all        139        608      0.954      0.912       0.96      0.508\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     23/200      7.29G      1.526     0.8082       1.02         26       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.8it/s 34.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.5it/s 3.6s\n",
            "                   all        139        608       0.94      0.933      0.957      0.516\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     24/200      7.33G      1.508     0.7919     0.9908         39       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.7it/s 35.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.7it/s 3.3s\n",
            "                   all        139        608      0.948      0.926      0.962      0.531\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     25/200      7.36G       1.51     0.7763      1.003         32       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.8it/s 34.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.5it/s 3.6s\n",
            "                   all        139        608      0.967      0.909      0.961      0.525\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     26/200      4.71G      1.503     0.7638      1.008         21       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.9it/s 32.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.3it/s 3.9s\n",
            "                   all        139        608      0.962      0.925      0.957      0.506\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     27/200      6.52G      1.535     0.7891       1.02         23       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.8it/s 34.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.2it/s 4.0s\n",
            "                   all        139        608      0.954      0.909       0.95      0.488\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     28/200      6.52G      1.559     0.7824      1.013         34       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.8it/s 33.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.5it/s 3.6s\n",
            "                   all        139        608      0.949      0.883      0.944      0.493\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     29/200      6.52G      1.541     0.8005      1.029         37       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.8it/s 34.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.6it/s 3.4s\n",
            "                   all        139        608      0.944      0.927       0.96      0.503\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     30/200      6.52G      1.521     0.7856      1.016         39       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.8it/s 33.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.7it/s 3.3s\n",
            "                   all        139        608      0.946      0.925      0.959      0.518\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     31/200      6.52G      1.475     0.7574     0.9993         26       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.8it/s 34.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.9it/s 3.1s\n",
            "                   all        139        608      0.946       0.93      0.956      0.516\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     32/200      6.54G       1.46     0.7421     0.9988         38       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.8it/s 34.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.8it/s 3.2s\n",
            "                   all        139        608      0.943      0.925      0.954      0.513\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     33/200      6.58G      1.434     0.7283      0.992         27       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.7it/s 35.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.9it/s 3.1s\n",
            "                   all        139        608      0.954      0.932      0.957      0.522\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     34/200      6.61G      1.453     0.7542     0.9871         20       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.8it/s 34.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.7it/s 3.3s\n",
            "                   all        139        608      0.971      0.924       0.96      0.519\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     35/200      6.65G       1.43     0.7059     0.9833         27       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.7it/s 35.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.8it/s 3.2s\n",
            "                   all        139        608      0.953      0.944      0.964      0.521\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     36/200      6.69G      1.458      0.728     0.9962         34       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.8it/s 34.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.7it/s 3.3s\n",
            "                   all        139        608      0.963       0.93      0.965       0.53\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     37/200      6.72G      1.442      0.702     0.9832         28       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.7it/s 35.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.0it/s 3.0s\n",
            "                   all        139        608      0.967      0.941      0.965      0.535\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     38/200      6.76G      1.444     0.7398     0.9947         15       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.7it/s 35.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.9it/s 3.1s\n",
            "                   all        139        608      0.974      0.927      0.954      0.523\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     39/200      6.79G      1.407     0.7239     0.9809         22       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.7it/s 35.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.8it/s 3.2s\n",
            "                   all        139        608      0.966      0.938      0.968      0.518\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     40/200      6.83G       1.41     0.7008     0.9833         38       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.8it/s 34.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.8it/s 3.2s\n",
            "                   all        139        608      0.963       0.95      0.966      0.531\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     41/200      6.87G      1.433     0.7113     0.9792         27       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.7it/s 35.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.0it/s 3.0s\n",
            "                   all        139        608       0.95      0.941      0.965      0.513\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     42/200       6.9G      1.425     0.7084     0.9738         33       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.7it/s 35.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.7it/s 3.3s\n",
            "                   all        139        608      0.947      0.927      0.955      0.525\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     43/200      6.94G      1.398     0.6996     0.9604         28       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 1.7it/s 35.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.8it/s 3.2s\n",
            "                   all        139        608      0.943      0.945      0.954      0.508\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     44/200      6.97G      1.383      0.701       0.99         50       1024: 13% â”â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 8/61 1.9it/s 4.6s<27.7s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2384994578.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdet_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"yolov8s.pt\"\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# ë˜ëŠ” yolov11s.pt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m det_model.train(\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDATA_YAML\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m         \u001b[0;31m# Update model and cfg after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    425\u001b[0m                         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munwrap_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m                         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \"\"\"\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for cases of training and validating while training.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, batch, preds)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"img\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for cases of training and validating while training.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_augment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36m_predict_once\u001b[0;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_profile_one_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# save output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/nn/modules/block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;34m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# -------------------------\n",
        "# 0. ê¸°ë³¸ ì„¤ì •\n",
        "# -------------------------\n",
        "DATA_YAML = f\"{OUT_YOLO}/dataset.yaml\"\n",
        "MODEL_NAME = \"yolov8s.pt\"\n",
        "DEVICE = 0 if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "torch.manual_seed(42)  # reproducibility\n",
        "\n",
        "# -------------------------\n",
        "# 1. ëª¨ë¸ ë¡œë“œ\n",
        "# -------------------------\n",
        "det_model = YOLO(MODEL_NAME)\n",
        "\n",
        "# -------------------------\n",
        "# 2. Train ì˜µì…˜ í™•ì¥\n",
        "# -------------------------\n",
        "det_model.train(\n",
        "    data=DATA_YAML,\n",
        "    epochs=200,\n",
        "    imgsz=1024,\n",
        "    batch=8,\n",
        "    lr0=1e-3,\n",
        "    optimizer=\"Adam\",\n",
        "    device=DEVICE,\n",
        "\n",
        "    # ---- ì—…ê·¸ë ˆì´ë“œ ì˜µì…˜ ----\n",
        "    project=\"runs/detect\",\n",
        "    name=\"exp_upgraded\",\n",
        "    pretrained=True,\n",
        "    patience=30,\n",
        "    mosaic=0.5,\n",
        "    mixup=0.2,\n",
        "    hsv_h=0.015, hsv_s=0.7, hsv_v=0.4,\n",
        "    degrees=5, translate=0.1, scale=0.2, shear=0.1,\n",
        "    fliplr=0.5, flipud=0.0,\n",
        "    weight_decay=0.0005,\n",
        "    amp=True,\n",
        "    cache=True,\n",
        "    workers=8,\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# 3. Best weight ìë™ ë¡œë“œ\n",
        "# -------------------------\n",
        "best_weight_path = \"runs/detect/exp_upgraded/weights/best.pt\"\n",
        "detector = YOLO(best_weight_path)\n",
        "\n",
        "print(f\"[INFO] Best model loaded from: {best_weight_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iznXn1kkxZH8",
        "outputId": "a1b714b6-6f52-4f37-bde4-67353d23c187"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.230 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/dataset_yolo_seg/dataset.yaml, degrees=5, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=200, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=1024, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.2, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=exp_upgraded, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=30, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/detect, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/exp_upgraded, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.2, seed=0, shear=0.1, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2118370  ultralytics.nn.modules.head.Detect           [6, [128, 256, 512]]          \n",
            "Model summary: 129 layers, 11,137,922 parameters, 11,137,906 gradients, 28.7 GFLOPs\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3949.3Â±762.2 MB/s, size: 1486.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset_yolo_seg/labels/train.cache... 485 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 485/485 1.1Mit/s 0.0s\n",
            "WARNING âš ï¸ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.1GB RAM): 100% â”â”â”â”â”â”â”â”â”â”â”â” 485/485 23.9it/s 20.3s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1885.0Â±1961.4 MB/s, size: 1569.2 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset_yolo_seg/labels/val... 139 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 139/139 961.1it/s 0.1s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/dataset_yolo_seg/labels/val.cache\n",
            "WARNING âš ï¸ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.3GB RAM): 100% â”â”â”â”â”â”â”â”â”â”â”â” 139/139 21.6it/s 6.4s\n",
            "Plotting labels to /content/runs/detect/exp_upgraded/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 1024 train, 1024 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/exp_upgraded\u001b[0m\n",
            "Starting training for 200 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      1/200      4.73G      2.566      9.584      1.559         18       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.4it/s 25.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.9it/s 3.1s\n",
            "                   all        139        595      0.417      0.238      0.259      0.122\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      2/200      6.63G      2.014      2.355      1.255         24       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.8it/s 21.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.6it/s 2.5s\n",
            "                   all        139        595      0.676      0.464      0.525      0.244\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      3/200      6.67G      1.883      1.929       1.21         32       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.4it/s 2.6s\n",
            "                   all        139        595      0.755      0.594      0.685      0.337\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      4/200      6.71G      1.818      1.592      1.161         29       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 20.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.3it/s 2.1s\n",
            "                   all        139        595      0.825      0.721      0.786      0.378\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      5/200      6.74G      1.711      1.461      1.132         26       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.6it/s 2.5s\n",
            "                   all        139        595      0.863      0.774      0.832      0.401\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      6/200      6.78G      1.719      1.385      1.134         23       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 3.0it/s 20.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.9it/s 2.3s\n",
            "                   all        139        595       0.89      0.817      0.877      0.429\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      7/200      6.81G      1.653      1.216      1.107         34       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.3it/s 2.1s\n",
            "                   all        139        595      0.888      0.814      0.871      0.431\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      8/200      6.85G       1.64      1.177      1.099         27       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.3it/s 2.7s\n",
            "                   all        139        595      0.925      0.838      0.903      0.444\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      9/200      6.89G      1.637      1.143      1.102         15       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 20.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.7it/s 2.4s\n",
            "                   all        139        595      0.922      0.839      0.891      0.405\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     10/200      6.92G      1.598      1.117      1.093         19       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.3it/s 2.1s\n",
            "                   all        139        595       0.93      0.844      0.888      0.435\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     11/200      6.96G      1.577      1.072       1.08         18       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 20.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.2it/s 2.9s\n",
            "                   all        139        595      0.947      0.862      0.919       0.46\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     12/200         7G      1.579      1.076      1.065         27       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 3.0it/s 20.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.1it/s 2.2s\n",
            "                   all        139        595      0.932      0.889      0.933      0.482\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     13/200      7.03G      1.546      1.048      1.068         26       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.8it/s 2.4s\n",
            "                   all        139        595      0.954      0.876      0.924      0.495\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     14/200      7.07G       1.51     0.9778      1.051         29       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.4it/s 2.7s\n",
            "                   all        139        595       0.95      0.874      0.932      0.505\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     15/200      7.11G      1.539     0.9944      1.057         30       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 3.0it/s 20.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.5it/s 2.0s\n",
            "                   all        139        595      0.973      0.884      0.943      0.492\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     16/200      7.14G      1.522     0.9776      1.056         42       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.9it/s 2.3s\n",
            "                   all        139        595      0.954      0.895      0.938      0.497\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     17/200      7.18G      1.523     0.9648      1.055         29       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.4it/s 2.7s\n",
            "                   all        139        595      0.957      0.853      0.921      0.472\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     18/200      7.21G      1.533     0.9663      1.059         31       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 20.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.5it/s 2.0s\n",
            "                   all        139        595      0.955      0.883      0.933      0.494\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     19/200      7.25G      1.536     0.9578      1.068         29       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.0it/s 2.3s\n",
            "                   all        139        595      0.937      0.879      0.919      0.451\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     20/200      7.29G      1.524     0.9424      1.046         24       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 20.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.4it/s 2.7s\n",
            "                   all        139        595      0.947       0.89      0.942       0.47\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     21/200      7.33G      1.497     0.9219       1.04         19       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 3.0it/s 20.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.4it/s 2.1s\n",
            "                   all        139        595      0.961      0.901      0.938      0.508\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     22/200      7.36G      1.452     0.9016      1.029         19       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.1it/s 2.2s\n",
            "                   all        139        595      0.957      0.917       0.95      0.504\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     23/200      4.73G       1.46     0.8697      1.037         16       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 20.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.3it/s 2.7s\n",
            "                   all        139        595      0.974      0.898      0.948      0.505\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     24/200       6.6G      1.489      0.855      1.051         33       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 3.0it/s 20.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.6it/s 2.0s\n",
            "                   all        139        595      0.974      0.892       0.95      0.502\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     25/200       6.6G      1.443     0.8585      1.033         22       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.3it/s 2.1s\n",
            "                   all        139        595      0.959      0.907      0.954      0.513\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     26/200       6.6G      1.475     0.8932      1.037         30       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 20.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.5it/s 2.6s\n",
            "                   all        139        595      0.957      0.909      0.941      0.516\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     27/200       6.6G      1.462     0.8367      1.042         25       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 3.0it/s 20.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.6it/s 2.0s\n",
            "                   all        139        595      0.941      0.897      0.936      0.499\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     28/200       6.6G      1.442     0.8475      1.031         40       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.7it/s 2.4s\n",
            "                   all        139        595      0.942      0.909      0.949      0.523\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     29/200      6.61G      1.445     0.8672       1.02         27       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 20.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.5it/s 2.6s\n",
            "                   all        139        595      0.961      0.907      0.945        0.5\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     30/200      6.64G      1.454     0.8781      1.032         30       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.7it/s 22.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.3it/s 2.8s\n",
            "                   all        139        595      0.967      0.899      0.948      0.503\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     31/200      6.68G      1.459     0.8465       1.03         28       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.5it/s 2.0s\n",
            "                   all        139        595      0.963      0.918       0.95      0.511\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     32/200      6.71G      1.413     0.7771      1.017         26       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.4it/s 2.7s\n",
            "                   all        139        595      0.966      0.926      0.956      0.526\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     33/200      6.75G      1.412     0.8162      1.019         35       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 3.0it/s 20.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.5it/s 2.0s\n",
            "                   all        139        595       0.96      0.909      0.947      0.527\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     34/200      6.79G      1.425     0.8431      1.019         21       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.7it/s 22.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.3it/s 2.1s\n",
            "                   all        139        595      0.958      0.912       0.95       0.51\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     35/200      6.82G      1.405     0.7906       1.01         26       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 20.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.4it/s 2.6s\n",
            "                   all        139        595      0.945      0.928      0.948      0.525\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     36/200      6.86G      1.401     0.7898      1.013         33       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 3.0it/s 20.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.4it/s 2.0s\n",
            "                   all        139        595      0.957      0.897      0.945      0.515\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     37/200       6.9G      1.408     0.8197      1.012         22       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.8it/s 21.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.0it/s 2.2s\n",
            "                   all        139        595      0.962      0.922      0.957      0.536\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     38/200      6.93G      1.377     0.7681     0.9996         32       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 3.0it/s 20.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.4it/s 2.6s\n",
            "                   all        139        595      0.967      0.915      0.955      0.531\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     39/200      6.97G      1.383     0.7966       1.02         32       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 20.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.4it/s 2.1s\n",
            "                   all        139        595      0.966      0.915      0.952      0.523\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     40/200      7.01G      1.389      0.802      1.008         19       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.2it/s 2.1s\n",
            "                   all        139        595      0.951      0.925      0.954      0.509\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     41/200      7.04G      1.359     0.7772     0.9948         20       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 20.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.5it/s 2.6s\n",
            "                   all        139        595      0.945      0.926      0.951      0.515\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     42/200      7.08G      1.364      0.771     0.9998         24       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.3it/s 2.1s\n",
            "                   all        139        595       0.96      0.918      0.955      0.525\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     43/200      7.12G      1.377     0.7715      1.004         28       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.9it/s 2.3s\n",
            "                   all        139        595      0.957      0.914      0.954      0.523\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     44/200      7.15G      1.364     0.7666     0.9995         27       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 20.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.1it/s 2.2s\n",
            "                   all        139        595      0.971      0.918      0.962       0.51\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     45/200      7.19G      1.362     0.7703     0.9928         37       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.4it/s 2.1s\n",
            "                   all        139        595      0.962       0.93      0.965      0.516\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     46/200      7.22G      1.356     0.7353     0.9888         28       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.6it/s 2.5s\n",
            "                   all        139        595      0.976      0.904       0.96      0.531\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     47/200      7.26G      1.324     0.7446     0.9885         25       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 3.0it/s 20.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.4it/s 2.0s\n",
            "                   all        139        595      0.966      0.905      0.952      0.542\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     48/200       7.3G      1.317     0.7311     0.9798         32       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 20.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.1it/s 2.2s\n",
            "                   all        139        595      0.965      0.924      0.956      0.529\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     49/200      7.33G      1.329      0.744     0.9876         31       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.1it/s 2.9s\n",
            "                   all        139        595      0.972      0.892      0.957       0.53\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     50/200      7.37G      1.358     0.7815     0.9921         23       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 3.0it/s 20.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.8it/s 1.9s\n",
            "                   all        139        595      0.955      0.917      0.955      0.529\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     51/200      4.69G      1.319     0.7203     0.9847         34       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.2it/s 2.1s\n",
            "                   all        139        595      0.978      0.909      0.961      0.534\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     52/200      4.69G      1.314     0.7266     0.9713         26       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 20.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.2it/s 2.8s\n",
            "                   all        139        595      0.972      0.932      0.964      0.536\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     53/200      4.69G      1.283     0.6838     0.9828         22       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 3.0it/s 20.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.7it/s 1.9s\n",
            "                   all        139        595      0.982       0.91       0.96      0.532\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     54/200      4.69G      1.325     0.7201     0.9853         21       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.3it/s 2.1s\n",
            "                   all        139        595      0.954      0.923      0.957       0.53\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     55/200      4.69G      1.314     0.7243     0.9784         24       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 3.0it/s 20.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.9it/s 2.3s\n",
            "                   all        139        595      0.969       0.92      0.964      0.547\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     56/200      4.69G      1.301     0.7168     0.9884         21       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.6it/s 2.0s\n",
            "                   all        139        595      0.973      0.908      0.956      0.517\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     57/200      4.71G      1.279     0.7155     0.9776         20       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.8it/s 21.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.8it/s 2.4s\n",
            "                   all        139        595      0.965      0.922      0.957       0.53\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     58/200      4.75G      1.317     0.7281       0.98         37       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 20.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.2it/s 2.1s\n",
            "                   all        139        595      0.972      0.916      0.959      0.529\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     59/200      4.82G      1.304     0.6974     0.9783         34       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 20.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.4it/s 2.1s\n",
            "                   all        139        595      0.964      0.937      0.966      0.533\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     60/200      4.86G      1.275     0.7008     0.9665         30       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.3it/s 2.7s\n",
            "                   all        139        595      0.949      0.933      0.961      0.523\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     61/200      4.98G      1.287     0.7038     0.9774         35       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 20.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.6it/s 2.0s\n",
            "                   all        139        595       0.97      0.911      0.958       0.52\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     62/200      5.02G       1.27     0.6845     0.9704         29       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.5it/s 2.0s\n",
            "                   all        139        595      0.969      0.927       0.97      0.527\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     63/200       5.1G      1.285     0.7047     0.9646         32       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.7it/s 23.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.2it/s 2.8s\n",
            "                   all        139        595      0.975      0.904      0.962      0.535\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     64/200      5.18G      1.261     0.6902     0.9741         24       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 20.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.4it/s 2.0s\n",
            "                   all        139        595      0.968      0.925      0.965      0.547\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     65/200      5.21G      1.259     0.7026     0.9694         32       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.7it/s 22.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.2it/s 2.8s\n",
            "                   all        139        595      0.945       0.93       0.96      0.535\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     66/200      5.29G      1.227     0.6647     0.9661         25       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.8it/s 21.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.1it/s 2.2s\n",
            "                   all        139        595      0.963      0.917       0.96      0.543\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     67/200      5.33G      1.241     0.6845      0.962         33       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 3.0it/s 20.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.1it/s 2.2s\n",
            "                   all        139        595      0.969      0.901      0.959      0.541\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     68/200      5.41G      1.248     0.6944     0.9645         30       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.8it/s 2.4s\n",
            "                   all        139        595      0.946      0.941       0.96      0.532\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     69/200      5.45G      1.243     0.6802     0.9647         31       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.3it/s 2.7s\n",
            "                   all        139        595      0.966      0.928      0.963      0.536\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     70/200      5.58G      1.232     0.6903     0.9585         32       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.0it/s 2.3s\n",
            "                   all        139        595      0.977      0.925      0.963      0.521\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     71/200      5.61G      1.239     0.6977     0.9599         33       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.1it/s 2.2s\n",
            "                   all        139        595      0.955      0.931      0.962      0.539\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     72/200       5.7G      1.214      0.665     0.9561         27       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 20.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.1it/s 2.9s\n",
            "                   all        139        595      0.978       0.92      0.961      0.543\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     73/200      5.73G       1.23     0.6736     0.9578         29       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 20.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.5it/s 2.0s\n",
            "                   all        139        595      0.948      0.928      0.956      0.535\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     74/200      5.77G      1.223     0.6553     0.9534         31       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.7it/s 2.5s\n",
            "                   all        139        595      0.962      0.926      0.958      0.527\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     75/200       5.9G      1.244     0.6625     0.9662         21       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.3it/s 2.7s\n",
            "                   all        139        595      0.968      0.939      0.964      0.536\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     76/200      5.94G      1.227     0.6767     0.9546         31       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 20.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.5it/s 2.0s\n",
            "                   all        139        595      0.979      0.932      0.963      0.525\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     77/200      5.98G      1.205     0.6619     0.9525         33       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.2it/s 2.1s\n",
            "                   all        139        595      0.977      0.919      0.965      0.522\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     78/200      6.11G      1.194     0.6326     0.9499         24       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 3.0it/s 20.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.3it/s 2.7s\n",
            "                   all        139        595      0.954      0.933      0.962      0.529\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     79/200      6.15G      1.192     0.6491      0.952         28       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 3.0it/s 20.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.7it/s 1.9s\n",
            "                   all        139        595      0.969      0.919      0.959      0.523\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     80/200      6.18G      1.182     0.6268      0.942         45       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.3it/s 2.1s\n",
            "                   all        139        595      0.959      0.926      0.956      0.527\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     81/200      6.22G      1.191     0.6779     0.9449         26       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 20.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.4it/s 2.6s\n",
            "                   all        139        595       0.97      0.939      0.967      0.521\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     82/200      6.35G      1.185     0.6237     0.9495         29       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 3.0it/s 20.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.6it/s 2.0s\n",
            "                   all        139        595      0.974      0.917      0.963      0.535\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     83/200      6.39G      1.188      0.643     0.9525         33       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.8it/s 2.4s\n",
            "                   all        139        595      0.973      0.931      0.966      0.532\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     84/200      6.46G      1.171      0.646     0.9369         26       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 20.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.1it/s 2.2s\n",
            "                   all        139        595      0.976      0.936      0.966      0.534\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     85/200       6.5G      1.151     0.6328     0.9411         25       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.0it/s 2.2s\n",
            "                   all        139        595      0.964      0.939      0.968      0.537\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     86/200      6.54G      1.184     0.6508     0.9407         26       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.7it/s 2.4s\n",
            "                   all        139        595      0.974      0.934      0.966      0.542\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     87/200      6.61G      1.211      0.672      0.951         35       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 3.0it/s 20.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.7it/s 1.9s\n",
            "                   all        139        595      0.965      0.936      0.964       0.54\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     88/200      6.69G      1.165     0.6447     0.9303         32       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.4it/s 2.0s\n",
            "                   all        139        595      0.962      0.934      0.967      0.535\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     89/200      6.77G      1.138     0.6181     0.9321         27       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 20.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.3it/s 2.7s\n",
            "                   all        139        595      0.967      0.918      0.964      0.529\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     90/200       6.8G       1.12      0.596     0.9292         39       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 3.0it/s 20.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.6it/s 2.0s\n",
            "                   all        139        595      0.964      0.939      0.969      0.545\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     91/200      6.88G       1.16     0.6424     0.9426         42       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.8it/s 2.4s\n",
            "                   all        139        595      0.953      0.954      0.967      0.523\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     92/200      6.92G       1.15     0.6416     0.9352         21       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.1it/s 2.9s\n",
            "                   all        139        595      0.978       0.93      0.971       0.53\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     93/200      7.04G      1.126     0.6184      0.924         25       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 3.0it/s 20.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.5it/s 2.0s\n",
            "                   all        139        595      0.966      0.949      0.969       0.54\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     94/200      7.07G      1.127      0.612     0.9317         40       1024: 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 2.9it/s 21.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.9it/s 2.3s\n",
            "                   all        139        595      0.965      0.936      0.961      0.525\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 30 epochs. Best results observed at epoch 64, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=30) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "94 epochs completed in 0.623 hours.\n",
            "Optimizer stripped from /content/runs/detect/exp_upgraded/weights/last.pt, 22.6MB\n",
            "Optimizer stripped from /content/runs/detect/exp_upgraded/weights/best.pt, 22.6MB\n",
            "\n",
            "Validating /content/runs/detect/exp_upgraded/weights/best.pt...\n",
            "Ultralytics 8.3.230 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,127,906 parameters, 0 gradients, 28.4 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.3it/s 3.8s\n",
            "                   all        139        595      0.968      0.925      0.965      0.546\n",
            "          missing_hole         17         79      0.994          1      0.995      0.624\n",
            "            mouse_bite         19         78      0.931       0.91      0.956       0.54\n",
            "          open_circuit         22         90      0.982      0.956      0.981      0.552\n",
            "                 short         24         99      0.969      0.939      0.968       0.52\n",
            "                  spur         26        114      0.989      0.819      0.928      0.486\n",
            "       spurious_copper         31        135      0.943      0.926      0.964      0.555\n",
            "Speed: 0.4ms preprocess, 11.2ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/exp_upgraded\u001b[0m\n",
            "[INFO] Best model loaded from: runs/detect/exp_upgraded/weights/best.pt\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "test_images/ does not exist",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-340524508.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# -------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m results = detector.predict(\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test_images/\"\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;31m# ì´ë¯¸ì§€ or í´ë”\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m               \u001b[0;31m# âœ” ê²°ê³¼ ì´ë¯¸ì§€ ìë™ ì €ì¥\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprompts\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"set_prompts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for SAM-type models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_prompts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_cli\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m     def track(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# merge list of Result into one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mgenerator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;31m# Issuing `None` to a generator fires it up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36mstream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for thread-safe inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;31m# Setup source every time predict is called\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msource\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0;31m# Check if save_dir/ label file exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36msetup_source\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \"\"\"\n\u001b[1;32m    254\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgsz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_imgsz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# check image size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         self.dataset = load_inference_source(\n\u001b[0m\u001b[1;32m    256\u001b[0m             \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/data/build.py\u001b[0m in \u001b[0;36mload_inference_source\u001b[0;34m(source, batch, vid_stride, buffer, channels)\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoadPilAndNumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoadImagesAndVideos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvid_stride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvid_stride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;31m# Attach source types to the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/data/loaders.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, batch, vid_stride, channels)\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# files (relative to *.txt file parent)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{p} does not exist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;31m# Define files as images or videos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: test_images/ does not exist"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 4. â˜… ìë™ ì €ì¥ë˜ëŠ” Predict ì½”ë“œ ì¶”ê°€ â˜…\n",
        "# -------------------------\n",
        "\n",
        "results = detector.predict(\n",
        "    source=\"/content/dataset_yolo_seg/images/test\",   # ì´ë¯¸ì§€ or í´ë”\n",
        "    save=True,               # âœ” ê²°ê³¼ ì´ë¯¸ì§€ ìë™ ì €ì¥\n",
        "    save_txt=True,           # (ì„ íƒ) YOLO ë¼ë²¨ txt ì €ì¥\n",
        "    imgsz=1024,\n",
        "    conf=0.3,\n",
        "    project=\"runs/predict\",\n",
        "    name=\"exp_results\"\n",
        ")\n",
        "\n",
        "print(\"[INFO] Prediction results saved to: runs/predict/exp_results/\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSal_hxE7PIf",
        "outputId": "960b378f-59ad-4346-97fd-c12f4df6923e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/69 /content/dataset_yolo_seg/images/test/missing_hole_01_missing_hole_10.jpg: 544x1024 3 missing_holes, 68.5ms\n",
            "image 2/69 /content/dataset_yolo_seg/images/test/missing_hole_01_missing_hole_14.jpg: 544x1024 3 missing_holes, 20.0ms\n",
            "image 3/69 /content/dataset_yolo_seg/images/test/missing_hole_04_missing_hole_09.jpg: 832x1024 3 missing_holes, 65.0ms\n",
            "image 4/69 /content/dataset_yolo_seg/images/test/missing_hole_05_missing_hole_01.jpg: 896x1024 3 missing_holes, 74.1ms\n",
            "image 5/69 /content/dataset_yolo_seg/images/test/missing_hole_05_missing_hole_06.jpg: 896x1024 5 missing_holes, 28.8ms\n",
            "image 6/69 /content/dataset_yolo_seg/images/test/missing_hole_06_missing_hole_08.jpg: 832x1024 5 missing_holes, 28.9ms\n",
            "image 7/69 /content/dataset_yolo_seg/images/test/missing_hole_06_missing_hole_10.jpg: 832x1024 5 missing_holes, 27.9ms\n",
            "image 8/69 /content/dataset_yolo_seg/images/test/missing_hole_08_missing_hole_01.jpg: 800x1024 5 missing_holes, 72.4ms\n",
            "image 9/69 /content/dataset_yolo_seg/images/test/missing_hole_08_missing_hole_06.jpg: 800x1024 5 missing_holes, 27.3ms\n",
            "image 10/69 /content/dataset_yolo_seg/images/test/missing_hole_09_missing_hole_04.jpg: 800x1024 6 missing_holes, 27.9ms\n",
            "image 11/69 /content/dataset_yolo_seg/images/test/missing_hole_11_missing_hole_09.jpg: 1024x1024 5 missing_holes, 42.7ms\n",
            "image 12/69 /content/dataset_yolo_seg/images/test/mouse_bite_04_mouse_bite_02.jpg: 832x1024 3 mouse_bites, 52.6ms\n",
            "image 13/69 /content/dataset_yolo_seg/images/test/mouse_bite_04_mouse_bite_13.jpg: 832x1024 3 mouse_bites, 55.9ms\n",
            "image 14/69 /content/dataset_yolo_seg/images/test/mouse_bite_05_mouse_bite_02.jpg: 896x1024 5 mouse_bites, 29.9ms\n",
            "image 15/69 /content/dataset_yolo_seg/images/test/mouse_bite_05_mouse_bite_03.jpg: 896x1024 5 mouse_bites, 28.7ms\n",
            "image 16/69 /content/dataset_yolo_seg/images/test/mouse_bite_06_mouse_bite_10.jpg: 832x1024 4 mouse_bites, 28.6ms\n",
            "image 17/69 /content/dataset_yolo_seg/images/test/mouse_bite_07_mouse_bite_02.jpg: 704x1024 5 mouse_bites, 46.7ms\n",
            "image 18/69 /content/dataset_yolo_seg/images/test/mouse_bite_07_mouse_bite_04.jpg: 704x1024 5 mouse_bites, 25.4ms\n",
            "image 19/69 /content/dataset_yolo_seg/images/test/mouse_bite_08_mouse_bite_05.jpg: 800x1024 6 mouse_bites, 27.9ms\n",
            "image 20/69 /content/dataset_yolo_seg/images/test/mouse_bite_09_mouse_bite_10.jpg: 800x1024 5 mouse_bites, 27.2ms\n",
            "image 21/69 /content/dataset_yolo_seg/images/test/mouse_bite_10_mouse_bite_02.jpg: 928x1024 6 mouse_bites, 51.1ms\n",
            "image 22/69 /content/dataset_yolo_seg/images/test/mouse_bite_10_mouse_bite_05.jpg: 928x1024 5 mouse_bites, 30.2ms\n",
            "image 23/69 /content/dataset_yolo_seg/images/test/mouse_bite_11_mouse_bite_01.jpg: 1024x1024 5 mouse_bites, 33.5ms\n",
            "image 24/69 /content/dataset_yolo_seg/images/test/mouse_bite_12_mouse_bite_06.jpg: 1024x1024 6 mouse_bites, 32.9ms\n",
            "image 25/69 /content/dataset_yolo_seg/images/test/open_circuit_01_open_circuit_04.jpg: 544x1024 3 open_circuits, 20.9ms\n",
            "image 26/69 /content/dataset_yolo_seg/images/test/open_circuit_01_open_circuit_13.jpg: 544x1024 2 open_circuits, 19.8ms\n",
            "image 27/69 /content/dataset_yolo_seg/images/test/open_circuit_01_open_circuit_17.jpg: 544x1024 2 open_circuits, 19.9ms\n",
            "image 28/69 /content/dataset_yolo_seg/images/test/open_circuit_01_open_circuit_20.jpg: 544x1024 3 open_circuits, 19.9ms\n",
            "image 29/69 /content/dataset_yolo_seg/images/test/open_circuit_04_open_circuit_05.jpg: 832x1024 3 open_circuits, 28.4ms\n",
            "image 30/69 /content/dataset_yolo_seg/images/test/open_circuit_05_open_circuit_03.jpg: 896x1024 3 open_circuits, 29.4ms\n",
            "image 31/69 /content/dataset_yolo_seg/images/test/open_circuit_05_open_circuit_08.jpg: 896x1024 3 open_circuits, 28.7ms\n",
            "image 32/69 /content/dataset_yolo_seg/images/test/open_circuit_06_open_circuit_02.jpg: 832x1024 5 open_circuits, 29.0ms\n",
            "image 33/69 /content/dataset_yolo_seg/images/test/open_circuit_07_open_circuit_09.jpg: 704x1024 5 open_circuits, 26.0ms\n",
            "image 34/69 /content/dataset_yolo_seg/images/test/open_circuit_08_open_circuit_01.jpg: 800x1024 5 open_circuits, 28.4ms\n",
            "image 35/69 /content/dataset_yolo_seg/images/test/open_circuit_08_open_circuit_03.jpg: 800x1024 1 mouse_bite, 4 open_circuits, 27.2ms\n",
            "image 36/69 /content/dataset_yolo_seg/images/test/open_circuit_11_open_circuit_05.jpg: 1024x1024 5 open_circuits, 33.7ms\n",
            "image 37/69 /content/dataset_yolo_seg/images/test/short_01_short_01.jpg: 544x1024 1 short, 20.7ms\n",
            "image 38/69 /content/dataset_yolo_seg/images/test/short_01_short_09.jpg: 544x1024 6 shorts, 19.9ms\n",
            "image 39/69 /content/dataset_yolo_seg/images/test/short_04_short_04.jpg: 832x1024 3 shorts, 28.5ms\n",
            "image 40/69 /content/dataset_yolo_seg/images/test/short_04_short_19.jpg: 832x1024 2 shorts, 27.8ms\n",
            "image 41/69 /content/dataset_yolo_seg/images/test/short_07_short_09.jpg: 704x1024 5 shorts, 26.0ms\n",
            "image 42/69 /content/dataset_yolo_seg/images/test/short_08_short_01.jpg: 800x1024 5 shorts, 27.9ms\n",
            "image 43/69 /content/dataset_yolo_seg/images/test/short_09_short_10.jpg: 800x1024 5 shorts, 27.2ms\n",
            "image 44/69 /content/dataset_yolo_seg/images/test/short_10_short_02.jpg: 928x1024 4 shorts, 30.9ms\n",
            "image 45/69 /content/dataset_yolo_seg/images/test/short_11_short_04.jpg: 1024x1024 5 shorts, 33.5ms\n",
            "image 46/69 /content/dataset_yolo_seg/images/test/short_12_short_02.jpg: 1024x1024 5 shorts, 32.9ms\n",
            "image 47/69 /content/dataset_yolo_seg/images/test/spur_01_spur_10.jpg: 544x1024 1 spur, 20.6ms\n",
            "image 48/69 /content/dataset_yolo_seg/images/test/spur_04_spur_14.jpg: 832x1024 3 spurs, 28.6ms\n",
            "image 49/69 /content/dataset_yolo_seg/images/test/spur_04_spur_19.jpg: 832x1024 3 spurs, 27.9ms\n",
            "image 50/69 /content/dataset_yolo_seg/images/test/spur_06_spur_10.jpg: 832x1024 5 spurs, 27.8ms\n",
            "image 51/69 /content/dataset_yolo_seg/images/test/spur_07_spur_01.jpg: 704x1024 5 spurs, 26.2ms\n",
            "image 52/69 /content/dataset_yolo_seg/images/test/spur_08_spur_02.jpg: 800x1024 4 spurs, 28.1ms\n",
            "image 53/69 /content/dataset_yolo_seg/images/test/spur_09_spur_05.jpg: 800x1024 5 spurs, 27.2ms\n",
            "image 54/69 /content/dataset_yolo_seg/images/test/spur_09_spur_07.jpg: 800x1024 5 spurs, 27.2ms\n",
            "image 55/69 /content/dataset_yolo_seg/images/test/spur_09_spur_08.jpg: 800x1024 5 spurs, 27.2ms\n",
            "image 56/69 /content/dataset_yolo_seg/images/test/spurious_copper_01_spurious_copper_09.jpg: 544x1024 3 spurious_coppers, 20.7ms\n",
            "image 57/69 /content/dataset_yolo_seg/images/test/spurious_copper_01_spurious_copper_12.jpg: 544x1024 2 spurious_coppers, 19.8ms\n",
            "image 58/69 /content/dataset_yolo_seg/images/test/spurious_copper_01_spurious_copper_20.jpg: 544x1024 3 spurious_coppers, 19.9ms\n",
            "image 59/69 /content/dataset_yolo_seg/images/test/spurious_copper_04_spurious_copper_11.jpg: 832x1024 2 spurious_coppers, 28.6ms\n",
            "image 60/69 /content/dataset_yolo_seg/images/test/spurious_copper_04_spurious_copper_16.jpg: 832x1024 2 spurious_coppers, 27.9ms\n",
            "image 61/69 /content/dataset_yolo_seg/images/test/spurious_copper_05_spurious_copper_07.jpg: 896x1024 7 spurious_coppers, 29.4ms\n",
            "image 62/69 /content/dataset_yolo_seg/images/test/spurious_copper_05_spurious_copper_10.jpg: 896x1024 7 spurious_coppers, 28.7ms\n",
            "image 63/69 /content/dataset_yolo_seg/images/test/spurious_copper_06_spurious_copper_02.jpg: 832x1024 5 spurious_coppers, 28.6ms\n",
            "image 64/69 /content/dataset_yolo_seg/images/test/spurious_copper_06_spurious_copper_06.jpg: 832x1024 5 spurious_coppers, 27.9ms\n",
            "image 65/69 /content/dataset_yolo_seg/images/test/spurious_copper_06_spurious_copper_07.jpg: 832x1024 5 spurious_coppers, 27.8ms\n",
            "image 66/69 /content/dataset_yolo_seg/images/test/spurious_copper_07_spurious_copper_01.jpg: 704x1024 5 spurious_coppers, 26.4ms\n",
            "image 67/69 /content/dataset_yolo_seg/images/test/spurious_copper_07_spurious_copper_07.jpg: 704x1024 5 spurious_coppers, 25.3ms\n",
            "image 68/69 /content/dataset_yolo_seg/images/test/spurious_copper_08_spurious_copper_03.jpg: 800x1024 1 mouse_bite, 5 spurious_coppers, 28.0ms\n",
            "image 69/69 /content/dataset_yolo_seg/images/test/spurious_copper_09_spurious_copper_02.jpg: 800x1024 5 spurious_coppers, 27.2ms\n",
            "Speed: 7.9ms preprocess, 31.1ms inference, 1.5ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "69 labels saved to /content/runs/predict/exp_results/labels\n",
            "[INFO] Prediction results saved to: runs/predict/exp_results/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "save_crop_dir = \"runs/predict/exp_results/crops\"\n",
        "os.makedirs(save_crop_dir, exist_ok=True)\n",
        "\n",
        "for r in results:\n",
        "    img = r.orig_img  # ì›ë³¸ ì´ë¯¸ì§€ëŠ” í•œë²ˆë§Œ ê°€ì ¸ë„ ë¨\n",
        "    img_name = Path(r.path).stem  # ì—¬ê¸°ì„œ Pathë¡œ ê°ì‹¸ì„œ stem ì‚¬ìš©!\n",
        "\n",
        "    for i, box in enumerate(r.boxes.xyxy):\n",
        "        x1, y1, x2, y2 = box.cpu().numpy().astype(int)\n",
        "        roi = img[y1:y2, x1:x2]\n",
        "\n",
        "        save_path = f\"{save_crop_dir}/{img_name}_crop_{i}.jpg\"\n",
        "        cv2.imwrite(save_path, roi)\n"
      ],
      "metadata": {
        "id": "IsLULMG43xER"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# í•™ìŠµ ì™„ë£Œ í›„ best weight\n",
        "# detector = YOLO(\"runs/detect/train/weights/best.pt\")"
      ],
      "metadata": {
        "id": "o2mQaZYGHKJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "í•™ìŠµ í›„ ê°€ì¥ ì„±ëŠ¥ ì¢‹ì€ ê°€ì¤‘ì¹˜(best.pt)ë¥¼ ë¶ˆëŸ¬ì™€ ìµœì¢… detectorë¡œ ì‚¬ìš©"
      ],
      "metadata": {
        "id": "uefLsJZTDIKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_rois(image_path, conf=0.25):\n",
        "    results = detector(image_path)[0]\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    rois = []\n",
        "    boxes = []\n",
        "\n",
        "    for box in results.boxes:\n",
        "        if box.conf < conf:\n",
        "            continue\n",
        "\n",
        "        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n",
        "        roi = img[y1:y2, x1:x2]\n",
        "\n",
        "        rois.append(roi)\n",
        "        boxes.append((x1, y1, x2, y2))\n",
        "\n",
        "    return img, rois, boxes\n"
      ],
      "metadata": {
        "id": "dK6U9pj4cfUI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "YOLO detectorë¥¼ í˜¸ì¶œí•´ì„œ ë¶ˆëŸ‰ ì˜ì—­ ë°”ìš´ë”© ë°•ìŠ¤ ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜´\n",
        "\n",
        "ê° ë°•ìŠ¤ë§ˆë‹¤:\n",
        "\n",
        "ì›ë³¸ ì´ë¯¸ì§€ì—ì„œ ì˜ë¼ë‚¸ ROI(roi)\n",
        "\n",
        "ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ((x1, y1, x2, y2))\n",
        "\n",
        "ë°˜í™˜: ì›ë³¸ ì´ë¯¸ì§€, ROI ë¦¬ìŠ¤íŠ¸, ë°•ìŠ¤ ì¢Œí‘œ ë¦¬ìŠ¤íŠ¸"
      ],
      "metadata": {
        "id": "0P5LRm4tDOz5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. ROIì—ì„œ ìë™ ë§ˆìŠ¤í¬ ë§Œë“¤ê¸° (Pseudo Ground Truth)\n",
        "\n",
        "Ground Truth ë§ˆìŠ¤í¬ê°€ ì—†ê¸° ë•Œë¬¸ì—, ìë™ìœ¼ë¡œ â€œì˜ì‚¬ ì •ë‹µ(pseudo mask)â€ ìƒì„±:\n",
        "\n",
        "ROIë¥¼ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜\n",
        "\n",
        "Gaussian Blurë¡œ ë…¸ì´ì¦ˆ ì œê±°\n",
        "\n",
        "Otsu Thresholdë¡œ ì–´ë‘ìš´ ì˜ì—­(ë¶ˆëŸ‰ì¼ ê°€ëŠ¥ì„± ë†’ì€ ë¶€ë¶„) ì´ì§„í™”\n",
        "\n",
        "Morphology Open/Closeë¡œ ì‘ì€ ì  ì œê±° + ì˜ì—­ ë§¤ë„ëŸ½ê²Œ ë§Œë“¤ê¸°"
      ],
      "metadata": {
        "id": "IIczIEDYDYBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def create_auto_mask(roi):\n",
        "#     \"\"\"\n",
        "#     ROIì—ì„œ ìë™ìœ¼ë¡œ ê²°í•¨ maskë¥¼ ìƒì„±\n",
        "#     - grayscale ë³€í™˜\n",
        "#     - Otsu thresholdë¡œ ë¶ˆëŸ‰ ì˜ì—­ ì¶”ì¶œ\n",
        "#     - morphologyë¡œ ì •ì œ\n",
        "#     \"\"\"\n",
        "#     gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "#     # ì¡ìŒ ì œê±°\n",
        "#     blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
        "\n",
        "#     # ë¶ˆëŸ‰ì€ ëŒ€ì²´ë¡œ ì–´ë‘ì›€ â†’ Otsu threshold ì‚¬ìš©\n",
        "#     _, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "#     # ì‘ì€ ì  ì œê±°\n",
        "#     kernel = np.ones((3,3), np.uint8)\n",
        "#     mask = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "\n",
        "#     # í´ëŸ¬ìŠ¤í„° í™•ì¥í•´ì„œ mask ë§¤ë„ëŸ½ê²Œ\n",
        "#     mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
        "\n",
        "#     return mask\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "def create_auto_mask(roi, save_prefix=None):\n",
        "    \"\"\"\n",
        "    ROIì—ì„œ ìë™ìœ¼ë¡œ ê²°í•¨ mask ìƒì„± + ë‹¨ê³„ë³„ ì´ë¯¸ì§€ ì €ì¥\n",
        "    save_prefix: ì €ì¥ íŒŒì¼ëª… ì•ì— ë¶™ì¼ ì´ë¦„ (ì˜ˆ: \"img1_roi0\")\n",
        "    \"\"\"\n",
        "\n",
        "    # ì €ì¥ ê²½ë¡œ ìƒì„±\n",
        "    if save_prefix is not None:\n",
        "        base_dir = Path(\"debug_masks\")\n",
        "        dirs = [\"gray\", \"blur\", \"thresh\", \"final\"]\n",
        "        for d in dirs:\n",
        "            (base_dir / d).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # 1) grayscale\n",
        "    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
        "    if save_prefix:\n",
        "        cv2.imwrite(f\"debug_masks/gray/{save_prefix}_gray.png\", gray)\n",
        "\n",
        "    # 2) blur\n",
        "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
        "    if save_prefix:\n",
        "        cv2.imwrite(f\"debug_masks/blur/{save_prefix}_blur.png\", blur)\n",
        "\n",
        "    # 3) threshold(Otsu)\n",
        "    _, thresh = cv2.threshold(\n",
        "        blur, 0, 255,\n",
        "        cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU\n",
        "    )\n",
        "    if save_prefix:\n",
        "        cv2.imwrite(f\"debug_masks/thresh/{save_prefix}_thresh.png\", thresh)\n",
        "\n",
        "    # 4) morphology\n",
        "    kernel = np.ones((3,3), np.uint8)\n",
        "    mask = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
        "    if save_prefix:\n",
        "        cv2.imwrite(f\"debug_masks/final/{save_prefix}_final.png\", mask)\n",
        "\n",
        "    return mask\n",
        "\n"
      ],
      "metadata": {
        "id": "1HBXoOt1H282"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. U-Net í•™ìŠµìš© Dataset (ROI + Mask) ë§Œë“¤ê¸°\n",
        "\n",
        "YOLOê°€ ì˜ë¼ì¤€ ROIë“¤ë§ˆë‹¤ create_auto_mask()ë¡œ ë§ˆìŠ¤í¬ë¥¼ ë§Œë“¤ê³ \n",
        "\n",
        "images/idx.png, masks/idx.pngë¡œ ì €ì¥\n",
        "\n",
        "ê²°êµ­ U-Net í•™ìŠµì— ë°”ë¡œ ì“¸ ìˆ˜ ìˆëŠ” ì´ë¯¸ì§€â€“ë§ˆìŠ¤í¬ í˜ì–´ ë°ì´í„°ì…‹ì´ ìë™ ìƒì„±ë¨"
      ],
      "metadata": {
        "id": "sieWbmdqDeos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_unet_dataset(img_dir, out_dir):\n",
        "    os.makedirs(f\"{out_dir}/images\", exist_ok=True)\n",
        "    os.makedirs(f\"{out_dir}/masks\", exist_ok=True)\n",
        "\n",
        "    idx = 0\n",
        "    for img_path in sorted(glob(f\"{img_dir}/*.jpg\")):\n",
        "        original, rois, boxes = extract_rois(img_path)\n",
        "\n",
        "        for roi in rois:\n",
        "            # mask = create_auto_mask(roi)\n",
        "            mask = create_auto_mask(roi, save_prefix=f\"{idx}\")\n",
        "\n",
        "\n",
        "            cv2.imwrite(f\"{out_dir}/images/{idx}.png\", roi)\n",
        "            cv2.imwrite(f\"{out_dir}/masks/{idx}.png\", mask)\n",
        "            idx += 1\n",
        "\n",
        "    print(f\"ìƒì„± ì™„ë£Œ! ì´ {idx}ê°œì˜ ROI+maskê°€ ìƒì„±ë¨.\")\n"
      ],
      "metadata": {
        "id": "97nQLsSpcg9R"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "build_unet_dataset(\n",
        "    \"/content/dataset_yolo_seg/images/train\",\n",
        "    \"/content/unet_dataset\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "E_Chk7kFyk1K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db7954c0-f7d5-4c9b-d11f-fe267dadc065"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_01_missing_hole_01.jpg: 544x1024 3 missing_holes, 20.7ms\n",
            "Speed: 4.3ms preprocess, 20.7ms inference, 4.4ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_01_missing_hole_04.jpg: 544x1024 3 missing_holes, 19.9ms\n",
            "Speed: 4.3ms preprocess, 19.9ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_01_missing_hole_05.jpg: 544x1024 4 missing_holes, 19.9ms\n",
            "Speed: 4.0ms preprocess, 19.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_01_missing_hole_06.jpg: 544x1024 3 missing_holes, 19.9ms\n",
            "Speed: 4.2ms preprocess, 19.9ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_01_missing_hole_07.jpg: 544x1024 3 missing_holes, 19.9ms\n",
            "Speed: 4.2ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_01_missing_hole_08.jpg: 544x1024 3 missing_holes, 19.9ms\n",
            "Speed: 4.1ms preprocess, 19.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_01_missing_hole_09.jpg: 544x1024 3 missing_holes, 19.9ms\n",
            "Speed: 4.0ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_01_missing_hole_11.jpg: 544x1024 3 missing_holes, 19.9ms\n",
            "Speed: 4.0ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_01_missing_hole_12.jpg: 544x1024 3 missing_holes, 19.9ms\n",
            "Speed: 4.3ms preprocess, 19.9ms inference, 2.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_01_missing_hole_13.jpg: 544x1024 3 missing_holes, 19.9ms\n",
            "Speed: 4.1ms preprocess, 19.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_01_missing_hole_15.jpg: 544x1024 3 missing_holes, 19.9ms\n",
            "Speed: 4.1ms preprocess, 19.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_01_missing_hole_16.jpg: 544x1024 3 missing_holes, 19.9ms\n",
            "Speed: 4.1ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_01_missing_hole_17.jpg: 544x1024 3 missing_holes, 19.9ms\n",
            "Speed: 4.0ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_01_missing_hole_18.jpg: 544x1024 3 missing_holes, 20.0ms\n",
            "Speed: 6.6ms preprocess, 20.0ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_01_missing_hole_19.jpg: 544x1024 3 missing_holes, 19.9ms\n",
            "Speed: 4.0ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_01_missing_hole_20.jpg: 544x1024 3 missing_holes, 19.9ms\n",
            "Speed: 4.0ms preprocess, 19.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_04_missing_hole_01.jpg: 832x1024 3 missing_holes, 28.7ms\n",
            "Speed: 6.4ms preprocess, 28.7ms inference, 1.2ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_04_missing_hole_02.jpg: 832x1024 3 missing_holes, 27.9ms\n",
            "Speed: 6.2ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_04_missing_hole_03.jpg: 832x1024 3 missing_holes, 27.9ms\n",
            "Speed: 6.2ms preprocess, 27.9ms inference, 1.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_04_missing_hole_04.jpg: 832x1024 3 missing_holes, 27.9ms\n",
            "Speed: 6.4ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_04_missing_hole_05.jpg: 832x1024 3 missing_holes, 27.9ms\n",
            "Speed: 6.5ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_04_missing_hole_06.jpg: 832x1024 3 missing_holes, 27.9ms\n",
            "Speed: 6.4ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_04_missing_hole_07.jpg: 832x1024 3 missing_holes, 27.9ms\n",
            "Speed: 6.2ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_04_missing_hole_08.jpg: 832x1024 3 missing_holes, 27.9ms\n",
            "Speed: 6.3ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_04_missing_hole_10.jpg: 832x1024 3 missing_holes, 28.0ms\n",
            "Speed: 6.3ms preprocess, 28.0ms inference, 1.7ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_04_missing_hole_11.jpg: 832x1024 3 missing_holes, 27.9ms\n",
            "Speed: 6.2ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_04_missing_hole_13.jpg: 832x1024 3 missing_holes, 27.9ms\n",
            "Speed: 6.2ms preprocess, 27.9ms inference, 1.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_04_missing_hole_14.jpg: 832x1024 3 missing_holes, 27.9ms\n",
            "Speed: 6.3ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_04_missing_hole_15.jpg: 832x1024 3 missing_holes, 27.8ms\n",
            "Speed: 6.3ms preprocess, 27.8ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_04_missing_hole_16.jpg: 832x1024 3 missing_holes, 27.8ms\n",
            "Speed: 6.1ms preprocess, 27.8ms inference, 1.2ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_04_missing_hole_17.jpg: 832x1024 3 missing_holes, 27.9ms\n",
            "Speed: 6.2ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_04_missing_hole_18.jpg: 832x1024 3 missing_holes, 28.0ms\n",
            "Speed: 10.1ms preprocess, 28.0ms inference, 2.1ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_04_missing_hole_19.jpg: 832x1024 3 missing_holes, 28.0ms\n",
            "Speed: 9.5ms preprocess, 28.0ms inference, 1.6ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_04_missing_hole_20.jpg: 832x1024 3 missing_holes, 27.9ms\n",
            "Speed: 9.8ms preprocess, 27.9ms inference, 1.6ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_05_missing_hole_02.jpg: 896x1024 3 missing_holes, 29.8ms\n",
            "Speed: 10.4ms preprocess, 29.8ms inference, 1.6ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_05_missing_hole_03.jpg: 896x1024 5 missing_holes, 28.8ms\n",
            "Speed: 15.2ms preprocess, 28.8ms inference, 1.6ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_05_missing_hole_04.jpg: 896x1024 5 missing_holes, 28.7ms\n",
            "Speed: 10.1ms preprocess, 28.7ms inference, 1.6ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_05_missing_hole_05.jpg: 896x1024 5 missing_holes, 28.8ms\n",
            "Speed: 10.2ms preprocess, 28.8ms inference, 1.5ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_05_missing_hole_08.jpg: 896x1024 5 missing_holes, 28.8ms\n",
            "Speed: 10.1ms preprocess, 28.8ms inference, 1.9ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_05_missing_hole_09.jpg: 896x1024 5 missing_holes, 28.8ms\n",
            "Speed: 10.4ms preprocess, 28.8ms inference, 1.6ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_05_missing_hole_10.jpg: 896x1024 5 missing_holes, 28.8ms\n",
            "Speed: 10.3ms preprocess, 28.8ms inference, 1.9ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_06_missing_hole_03.jpg: 832x1024 5 missing_holes, 29.0ms\n",
            "Speed: 10.0ms preprocess, 29.0ms inference, 1.8ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_06_missing_hole_04.jpg: 832x1024 5 missing_holes, 27.9ms\n",
            "Speed: 9.7ms preprocess, 27.9ms inference, 1.6ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_06_missing_hole_05.jpg: 832x1024 5 missing_holes, 27.9ms\n",
            "Speed: 9.6ms preprocess, 27.9ms inference, 1.8ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_06_missing_hole_06.jpg: 832x1024 6 missing_holes, 27.9ms\n",
            "Speed: 9.7ms preprocess, 27.9ms inference, 1.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_06_missing_hole_07.jpg: 832x1024 5 missing_holes, 27.9ms\n",
            "Speed: 9.8ms preprocess, 27.9ms inference, 1.8ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_07_missing_hole_01.jpg: 704x1024 5 missing_holes, 26.3ms\n",
            "Speed: 8.2ms preprocess, 26.3ms inference, 1.8ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_07_missing_hole_04.jpg: 704x1024 5 missing_holes, 25.4ms\n",
            "Speed: 9.0ms preprocess, 25.4ms inference, 1.9ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_07_missing_hole_05.jpg: 704x1024 5 missing_holes, 25.4ms\n",
            "Speed: 8.2ms preprocess, 25.4ms inference, 1.8ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_07_missing_hole_06.jpg: 704x1024 5 missing_holes, 25.4ms\n",
            "Speed: 8.0ms preprocess, 25.4ms inference, 1.9ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_07_missing_hole_07.jpg: 704x1024 5 missing_holes, 25.7ms\n",
            "Speed: 8.4ms preprocess, 25.7ms inference, 1.8ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_07_missing_hole_08.jpg: 704x1024 5 missing_holes, 25.4ms\n",
            "Speed: 8.2ms preprocess, 25.4ms inference, 1.9ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_07_missing_hole_10.jpg: 704x1024 5 missing_holes, 25.4ms\n",
            "Speed: 8.0ms preprocess, 25.4ms inference, 1.9ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_08_missing_hole_02.jpg: 800x1024 5 missing_holes, 28.2ms\n",
            "Speed: 9.6ms preprocess, 28.2ms inference, 1.8ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_08_missing_hole_03.jpg: 800x1024 5 missing_holes, 27.2ms\n",
            "Speed: 5.8ms preprocess, 27.2ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_08_missing_hole_04.jpg: 800x1024 4 missing_holes, 27.2ms\n",
            "Speed: 9.2ms preprocess, 27.2ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_08_missing_hole_05.jpg: 800x1024 5 missing_holes, 27.2ms\n",
            "Speed: 5.9ms preprocess, 27.2ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_08_missing_hole_07.jpg: 800x1024 5 missing_holes, 27.2ms\n",
            "Speed: 5.8ms preprocess, 27.2ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_08_missing_hole_08.jpg: 800x1024 5 missing_holes, 27.2ms\n",
            "Speed: 5.9ms preprocess, 27.2ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_08_missing_hole_10.jpg: 800x1024 5 missing_holes, 27.2ms\n",
            "Speed: 6.0ms preprocess, 27.2ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_09_missing_hole_01.jpg: 800x1024 5 missing_holes, 27.2ms\n",
            "Speed: 6.8ms preprocess, 27.2ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_09_missing_hole_02.jpg: 800x1024 5 missing_holes, 27.2ms\n",
            "Speed: 5.8ms preprocess, 27.2ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_09_missing_hole_03.jpg: 800x1024 5 missing_holes, 27.2ms\n",
            "Speed: 5.8ms preprocess, 27.2ms inference, 1.2ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_09_missing_hole_05.jpg: 800x1024 6 missing_holes, 27.2ms\n",
            "Speed: 5.8ms preprocess, 27.2ms inference, 2.1ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_09_missing_hole_06.jpg: 800x1024 6 missing_holes, 27.3ms\n",
            "Speed: 5.9ms preprocess, 27.3ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_09_missing_hole_07.jpg: 800x1024 7 missing_holes, 27.2ms\n",
            "Speed: 5.7ms preprocess, 27.2ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_09_missing_hole_08.jpg: 800x1024 5 missing_holes, 27.2ms\n",
            "Speed: 5.9ms preprocess, 27.2ms inference, 1.9ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_09_missing_hole_10.jpg: 800x1024 5 missing_holes, 27.2ms\n",
            "Speed: 5.8ms preprocess, 27.2ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_10_missing_hole_01.jpg: 928x1024 5 missing_holes, 31.1ms\n",
            "Speed: 6.7ms preprocess, 31.1ms inference, 1.5ms postprocess per image at shape (1, 3, 928, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_10_missing_hole_02.jpg: 928x1024 5 missing_holes, 30.2ms\n",
            "Speed: 6.5ms preprocess, 30.2ms inference, 1.3ms postprocess per image at shape (1, 3, 928, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_10_missing_hole_03.jpg: 928x1024 5 missing_holes, 30.2ms\n",
            "Speed: 6.6ms preprocess, 30.2ms inference, 1.5ms postprocess per image at shape (1, 3, 928, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_10_missing_hole_04.jpg: 928x1024 5 missing_holes, 30.2ms\n",
            "Speed: 6.4ms preprocess, 30.2ms inference, 1.3ms postprocess per image at shape (1, 3, 928, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_10_missing_hole_05.jpg: 928x1024 5 missing_holes, 30.2ms\n",
            "Speed: 7.0ms preprocess, 30.2ms inference, 1.3ms postprocess per image at shape (1, 3, 928, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_11_missing_hole_01.jpg: 1024x1024 5 missing_holes, 33.6ms\n",
            "Speed: 7.3ms preprocess, 33.6ms inference, 1.2ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_11_missing_hole_02.jpg: 1024x1024 5 missing_holes, 32.9ms\n",
            "Speed: 7.3ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_11_missing_hole_03.jpg: 1024x1024 5 missing_holes, 32.9ms\n",
            "Speed: 8.8ms preprocess, 32.9ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_11_missing_hole_05.jpg: 1024x1024 5 missing_holes, 32.9ms\n",
            "Speed: 7.2ms preprocess, 32.9ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_11_missing_hole_06.jpg: 1024x1024 5 missing_holes, 32.9ms\n",
            "Speed: 7.8ms preprocess, 32.9ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_11_missing_hole_08.jpg: 1024x1024 5 missing_holes, 32.9ms\n",
            "Speed: 7.5ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_11_missing_hole_10.jpg: 1024x1024 5 missing_holes, 32.9ms\n",
            "Speed: 7.2ms preprocess, 32.9ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_12_missing_hole_02.jpg: 1024x1024 5 missing_holes, 33.0ms\n",
            "Speed: 7.6ms preprocess, 33.0ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_12_missing_hole_03.jpg: 1024x1024 6 missing_holes, 32.9ms\n",
            "Speed: 7.6ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_12_missing_hole_04.jpg: 1024x1024 5 missing_holes, 32.9ms\n",
            "Speed: 9.0ms preprocess, 32.9ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_12_missing_hole_05.jpg: 1024x1024 6 missing_holes, 32.9ms\n",
            "Speed: 7.5ms preprocess, 32.9ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_12_missing_hole_06.jpg: 1024x1024 5 missing_holes, 32.9ms\n",
            "Speed: 7.4ms preprocess, 32.9ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_12_missing_hole_08.jpg: 1024x1024 5 missing_holes, 32.9ms\n",
            "Speed: 8.8ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/missing_hole_12_missing_hole_10.jpg: 1024x1024 5 missing_holes, 32.9ms\n",
            "Speed: 7.7ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_01_mouse_bite_01.jpg: 544x1024 3 mouse_bites, 20.6ms\n",
            "Speed: 4.2ms preprocess, 20.6ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_01_mouse_bite_02.jpg: 544x1024 2 mouse_bites, 19.9ms\n",
            "Speed: 4.0ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_01_mouse_bite_04.jpg: 544x1024 3 mouse_bites, 19.9ms\n",
            "Speed: 4.0ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_01_mouse_bite_05.jpg: 544x1024 3 mouse_bites, 19.9ms\n",
            "Speed: 4.2ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_01_mouse_bite_06.jpg: 544x1024 3 mouse_bites, 19.9ms\n",
            "Speed: 4.2ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_01_mouse_bite_07.jpg: 544x1024 2 mouse_bites, 19.9ms\n",
            "Speed: 4.1ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_01_mouse_bite_10.jpg: 544x1024 2 mouse_bites, 19.9ms\n",
            "Speed: 4.1ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_01_mouse_bite_11.jpg: 544x1024 1 mouse_bite, 19.9ms\n",
            "Speed: 4.0ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_01_mouse_bite_12.jpg: 544x1024 3 mouse_bites, 19.9ms\n",
            "Speed: 4.0ms preprocess, 19.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_01_mouse_bite_14.jpg: 544x1024 2 mouse_bites, 19.9ms\n",
            "Speed: 4.2ms preprocess, 19.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_01_mouse_bite_15.jpg: 544x1024 1 mouse_bite, 2 open_circuits, 19.9ms\n",
            "Speed: 3.9ms preprocess, 19.9ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_01_mouse_bite_16.jpg: 544x1024 2 mouse_bites, 19.9ms\n",
            "Speed: 4.6ms preprocess, 19.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_01_mouse_bite_17.jpg: 544x1024 1 mouse_bite, 19.9ms\n",
            "Speed: 4.1ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_01_mouse_bite_18.jpg: 544x1024 1 mouse_bite, 19.9ms\n",
            "Speed: 3.9ms preprocess, 19.9ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_01_mouse_bite_19.jpg: 544x1024 1 mouse_bite, 19.9ms\n",
            "Speed: 5.4ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_01_mouse_bite_20.jpg: 544x1024 2 mouse_bites, 19.8ms\n",
            "Speed: 4.0ms preprocess, 19.8ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_04_mouse_bite_04.jpg: 832x1024 3 mouse_bites, 28.7ms\n",
            "Speed: 6.4ms preprocess, 28.7ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_04_mouse_bite_05.jpg: 832x1024 3 mouse_bites, 27.9ms\n",
            "Speed: 6.8ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_04_mouse_bite_06.jpg: 832x1024 3 mouse_bites, 27.8ms\n",
            "Speed: 6.2ms preprocess, 27.8ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_04_mouse_bite_07.jpg: 832x1024 3 mouse_bites, 27.9ms\n",
            "Speed: 6.3ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_04_mouse_bite_08.jpg: 832x1024 3 mouse_bites, 27.9ms\n",
            "Speed: 6.4ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_04_mouse_bite_09.jpg: 832x1024 3 mouse_bites, 27.9ms\n",
            "Speed: 6.2ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_04_mouse_bite_10.jpg: 832x1024 3 mouse_bites, 27.9ms\n",
            "Speed: 6.1ms preprocess, 27.9ms inference, 1.2ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_04_mouse_bite_11.jpg: 832x1024 3 mouse_bites, 27.9ms\n",
            "Speed: 6.6ms preprocess, 27.9ms inference, 1.7ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_04_mouse_bite_14.jpg: 832x1024 3 mouse_bites, 27.9ms\n",
            "Speed: 6.2ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_04_mouse_bite_15.jpg: 832x1024 3 mouse_bites, 27.9ms\n",
            "Speed: 6.2ms preprocess, 27.9ms inference, 1.2ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_04_mouse_bite_16.jpg: 832x1024 3 mouse_bites, 27.9ms\n",
            "Speed: 6.0ms preprocess, 27.9ms inference, 1.2ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_04_mouse_bite_17.jpg: 832x1024 3 mouse_bites, 27.8ms\n",
            "Speed: 9.3ms preprocess, 27.8ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_04_mouse_bite_19.jpg: 832x1024 3 mouse_bites, 27.8ms\n",
            "Speed: 6.2ms preprocess, 27.8ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_05_mouse_bite_01.jpg: 896x1024 5 mouse_bites, 29.5ms\n",
            "Speed: 6.2ms preprocess, 29.5ms inference, 1.4ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_05_mouse_bite_04.jpg: 896x1024 5 mouse_bites, 28.7ms\n",
            "Speed: 6.5ms preprocess, 28.7ms inference, 1.3ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_05_mouse_bite_06.jpg: 896x1024 6 mouse_bites, 28.7ms\n",
            "Speed: 6.5ms preprocess, 28.7ms inference, 1.3ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_05_mouse_bite_07.jpg: 896x1024 6 mouse_bites, 28.8ms\n",
            "Speed: 6.3ms preprocess, 28.8ms inference, 1.3ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_05_mouse_bite_08.jpg: 896x1024 6 mouse_bites, 28.7ms\n",
            "Speed: 6.4ms preprocess, 28.7ms inference, 1.3ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_05_mouse_bite_09.jpg: 896x1024 5 mouse_bites, 28.7ms\n",
            "Speed: 6.5ms preprocess, 28.7ms inference, 1.3ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_06_mouse_bite_01.jpg: 832x1024 5 mouse_bites, 28.6ms\n",
            "Speed: 9.6ms preprocess, 28.6ms inference, 1.2ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_06_mouse_bite_03.jpg: 832x1024 5 mouse_bites, 27.9ms\n",
            "Speed: 6.0ms preprocess, 27.9ms inference, 2.0ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_06_mouse_bite_04.jpg: 832x1024 5 mouse_bites, 27.9ms\n",
            "Speed: 6.1ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_06_mouse_bite_05.jpg: 832x1024 5 mouse_bites, 27.9ms\n",
            "Speed: 6.1ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_06_mouse_bite_06.jpg: 832x1024 5 mouse_bites, 27.9ms\n",
            "Speed: 6.3ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_06_mouse_bite_07.jpg: 832x1024 5 mouse_bites, 27.9ms\n",
            "Speed: 6.1ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_06_mouse_bite_09.jpg: 832x1024 5 mouse_bites, 27.9ms\n",
            "Speed: 6.1ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_07_mouse_bite_01.jpg: 704x1024 5 mouse_bites, 26.1ms\n",
            "Speed: 5.2ms preprocess, 26.1ms inference, 1.2ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_07_mouse_bite_03.jpg: 704x1024 5 mouse_bites, 25.3ms\n",
            "Speed: 5.3ms preprocess, 25.3ms inference, 1.3ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_07_mouse_bite_05.jpg: 704x1024 5 mouse_bites, 25.4ms\n",
            "Speed: 5.2ms preprocess, 25.4ms inference, 1.4ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_07_mouse_bite_07.jpg: 704x1024 5 mouse_bites, 25.3ms\n",
            "Speed: 7.2ms preprocess, 25.3ms inference, 1.3ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_07_mouse_bite_09.jpg: 704x1024 5 mouse_bites, 25.4ms\n",
            "Speed: 5.2ms preprocess, 25.4ms inference, 1.4ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_08_mouse_bite_01.jpg: 800x1024 6 mouse_bites, 28.5ms\n",
            "Speed: 9.9ms preprocess, 28.5ms inference, 1.9ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_08_mouse_bite_02.jpg: 800x1024 5 mouse_bites, 27.3ms\n",
            "Speed: 9.1ms preprocess, 27.3ms inference, 1.8ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_08_mouse_bite_03.jpg: 800x1024 5 mouse_bites, 27.3ms\n",
            "Speed: 9.7ms preprocess, 27.3ms inference, 1.7ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_08_mouse_bite_04.jpg: 800x1024 5 mouse_bites, 27.3ms\n",
            "Speed: 9.8ms preprocess, 27.3ms inference, 1.8ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_08_mouse_bite_06.jpg: 800x1024 6 mouse_bites, 27.3ms\n",
            "Speed: 10.0ms preprocess, 27.3ms inference, 1.9ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_08_mouse_bite_09.jpg: 800x1024 5 mouse_bites, 27.3ms\n",
            "Speed: 9.5ms preprocess, 27.3ms inference, 1.6ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_08_mouse_bite_10.jpg: 800x1024 5 mouse_bites, 27.2ms\n",
            "Speed: 9.7ms preprocess, 27.2ms inference, 1.6ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_09_mouse_bite_02.jpg: 800x1024 6 mouse_bites, 27.3ms\n",
            "Speed: 10.1ms preprocess, 27.3ms inference, 1.6ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_09_mouse_bite_03.jpg: 800x1024 5 mouse_bites, 27.2ms\n",
            "Speed: 9.8ms preprocess, 27.2ms inference, 1.7ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_09_mouse_bite_04.jpg: 800x1024 5 mouse_bites, 27.3ms\n",
            "Speed: 9.3ms preprocess, 27.3ms inference, 1.6ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_09_mouse_bite_05.jpg: 800x1024 5 mouse_bites, 27.3ms\n",
            "Speed: 9.2ms preprocess, 27.3ms inference, 1.7ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_09_mouse_bite_06.jpg: 800x1024 5 mouse_bites, 27.3ms\n",
            "Speed: 9.5ms preprocess, 27.3ms inference, 2.7ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_09_mouse_bite_07.jpg: 800x1024 5 mouse_bites, 27.2ms\n",
            "Speed: 9.5ms preprocess, 27.2ms inference, 1.8ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_09_mouse_bite_08.jpg: 800x1024 5 mouse_bites, 27.2ms\n",
            "Speed: 10.1ms preprocess, 27.2ms inference, 1.6ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_09_mouse_bite_09.jpg: 800x1024 7 mouse_bites, 27.2ms\n",
            "Speed: 9.8ms preprocess, 27.2ms inference, 1.6ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_10_mouse_bite_01.jpg: 928x1024 5 mouse_bites, 31.5ms\n",
            "Speed: 10.9ms preprocess, 31.5ms inference, 1.5ms postprocess per image at shape (1, 3, 928, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_10_mouse_bite_03.jpg: 928x1024 5 mouse_bites, 30.3ms\n",
            "Speed: 10.3ms preprocess, 30.3ms inference, 2.7ms postprocess per image at shape (1, 3, 928, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_10_mouse_bite_04.jpg: 928x1024 5 mouse_bites, 30.3ms\n",
            "Speed: 11.4ms preprocess, 30.3ms inference, 1.9ms postprocess per image at shape (1, 3, 928, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_11_mouse_bite_02.jpg: 1024x1024 5 mouse_bites, 33.8ms\n",
            "Speed: 12.1ms preprocess, 33.8ms inference, 1.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_11_mouse_bite_03.jpg: 1024x1024 5 mouse_bites, 33.0ms\n",
            "Speed: 11.8ms preprocess, 33.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_11_mouse_bite_04.jpg: 1024x1024 5 mouse_bites, 33.4ms\n",
            "Speed: 11.2ms preprocess, 33.4ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_11_mouse_bite_05.jpg: 1024x1024 5 mouse_bites, 33.0ms\n",
            "Speed: 11.8ms preprocess, 33.0ms inference, 2.1ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_11_mouse_bite_06.jpg: 1024x1024 5 mouse_bites, 33.0ms\n",
            "Speed: 12.1ms preprocess, 33.0ms inference, 3.2ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_11_mouse_bite_07.jpg: 1024x1024 5 mouse_bites, 32.9ms\n",
            "Speed: 7.5ms preprocess, 32.9ms inference, 2.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_11_mouse_bite_08.jpg: 1024x1024 5 mouse_bites, 32.9ms\n",
            "Speed: 7.5ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_11_mouse_bite_09.jpg: 1024x1024 5 mouse_bites, 32.9ms\n",
            "Speed: 7.4ms preprocess, 32.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_11_mouse_bite_10.jpg: 1024x1024 5 mouse_bites, 32.9ms\n",
            "Speed: 7.2ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_12_mouse_bite_01.jpg: 1024x1024 5 mouse_bites, 33.0ms\n",
            "Speed: 8.4ms preprocess, 33.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_12_mouse_bite_02.jpg: 1024x1024 5 mouse_bites, 32.9ms\n",
            "Speed: 7.7ms preprocess, 32.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_12_mouse_bite_03.jpg: 1024x1024 5 mouse_bites, 32.9ms\n",
            "Speed: 7.5ms preprocess, 32.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_12_mouse_bite_04.jpg: 1024x1024 5 mouse_bites, 32.9ms\n",
            "Speed: 7.5ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_12_mouse_bite_05.jpg: 1024x1024 5 mouse_bites, 32.9ms\n",
            "Speed: 8.2ms preprocess, 32.9ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_12_mouse_bite_07.jpg: 1024x1024 5 mouse_bites, 32.9ms\n",
            "Speed: 7.3ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_12_mouse_bite_08.jpg: 1024x1024 5 mouse_bites, 33.0ms\n",
            "Speed: 7.6ms preprocess, 33.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_12_mouse_bite_09.jpg: 1024x1024 5 mouse_bites, 32.9ms\n",
            "Speed: 7.8ms preprocess, 32.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/mouse_bite_12_mouse_bite_10.jpg: 1024x1024 5 mouse_bites, 32.9ms\n",
            "Speed: 7.6ms preprocess, 32.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_01_open_circuit_02.jpg: 544x1024 3 open_circuits, 20.6ms\n",
            "Speed: 4.1ms preprocess, 20.6ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_01_open_circuit_03.jpg: 544x1024 3 open_circuits, 19.9ms\n",
            "Speed: 4.1ms preprocess, 19.9ms inference, 5.0ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_01_open_circuit_05.jpg: 544x1024 3 open_circuits, 19.9ms\n",
            "Speed: 4.0ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_01_open_circuit_07.jpg: 544x1024 3 open_circuits, 19.9ms\n",
            "Speed: 4.2ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_01_open_circuit_08.jpg: 544x1024 3 open_circuits, 19.9ms\n",
            "Speed: 4.0ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_01_open_circuit_09.jpg: 544x1024 2 open_circuits, 19.9ms\n",
            "Speed: 4.0ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_01_open_circuit_12.jpg: 544x1024 3 open_circuits, 19.9ms\n",
            "Speed: 4.0ms preprocess, 19.9ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_01_open_circuit_14.jpg: 544x1024 3 open_circuits, 19.9ms\n",
            "Speed: 4.4ms preprocess, 19.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_01_open_circuit_15.jpg: 544x1024 3 open_circuits, 19.9ms\n",
            "Speed: 4.3ms preprocess, 19.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_01_open_circuit_16.jpg: 544x1024 2 open_circuits, 19.9ms\n",
            "Speed: 4.0ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_01_open_circuit_18.jpg: 544x1024 3 open_circuits, 19.9ms\n",
            "Speed: 4.2ms preprocess, 19.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_04_open_circuit_02.jpg: 832x1024 3 open_circuits, 28.7ms\n",
            "Speed: 6.3ms preprocess, 28.7ms inference, 1.2ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_04_open_circuit_04.jpg: 832x1024 3 open_circuits, 27.8ms\n",
            "Speed: 6.3ms preprocess, 27.8ms inference, 1.6ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_04_open_circuit_06.jpg: 832x1024 3 open_circuits, 27.9ms\n",
            "Speed: 6.3ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_04_open_circuit_07.jpg: 832x1024 3 open_circuits, 27.9ms\n",
            "Speed: 6.3ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_04_open_circuit_09.jpg: 832x1024 3 open_circuits, 27.9ms\n",
            "Speed: 6.6ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_04_open_circuit_10.jpg: 832x1024 3 open_circuits, 27.8ms\n",
            "Speed: 6.3ms preprocess, 27.8ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_04_open_circuit_11.jpg: 832x1024 3 open_circuits, 27.9ms\n",
            "Speed: 6.5ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_04_open_circuit_12.jpg: 832x1024 3 open_circuits, 27.9ms\n",
            "Speed: 6.4ms preprocess, 27.9ms inference, 1.6ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_04_open_circuit_13.jpg: 832x1024 3 open_circuits, 27.9ms\n",
            "Speed: 6.3ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_04_open_circuit_14.jpg: 832x1024 3 open_circuits, 27.9ms\n",
            "Speed: 6.2ms preprocess, 27.9ms inference, 1.2ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_04_open_circuit_15.jpg: 832x1024 3 open_circuits, 27.9ms\n",
            "Speed: 5.9ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_04_open_circuit_17.jpg: 832x1024 3 open_circuits, 27.8ms\n",
            "Speed: 6.4ms preprocess, 27.8ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_04_open_circuit_18.jpg: 832x1024 2 open_circuits, 27.8ms\n",
            "Speed: 6.0ms preprocess, 27.8ms inference, 1.2ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_04_open_circuit_20.jpg: 832x1024 3 open_circuits, 27.9ms\n",
            "Speed: 6.5ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_05_open_circuit_01.jpg: 896x1024 3 open_circuits, 29.7ms\n",
            "Speed: 6.8ms preprocess, 29.7ms inference, 1.3ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_05_open_circuit_02.jpg: 896x1024 3 open_circuits, 28.8ms\n",
            "Speed: 6.4ms preprocess, 28.8ms inference, 1.5ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_05_open_circuit_04.jpg: 896x1024 6 open_circuits, 28.8ms\n",
            "Speed: 11.4ms preprocess, 28.8ms inference, 1.5ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_05_open_circuit_05.jpg: 896x1024 3 open_circuits, 28.7ms\n",
            "Speed: 7.2ms preprocess, 28.7ms inference, 1.4ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_05_open_circuit_06.jpg: 896x1024 3 open_circuits, 28.7ms\n",
            "Speed: 6.5ms preprocess, 28.7ms inference, 1.3ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_05_open_circuit_07.jpg: 896x1024 3 open_circuits, 28.7ms\n",
            "Speed: 6.7ms preprocess, 28.7ms inference, 1.4ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_05_open_circuit_09.jpg: 896x1024 3 open_circuits, 28.7ms\n",
            "Speed: 6.3ms preprocess, 28.7ms inference, 1.3ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_05_open_circuit_10.jpg: 896x1024 3 open_circuits, 28.8ms\n",
            "Speed: 6.5ms preprocess, 28.8ms inference, 1.3ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_06_open_circuit_01.jpg: 832x1024 6 open_circuits, 28.7ms\n",
            "Speed: 6.3ms preprocess, 28.7ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_06_open_circuit_03.jpg: 832x1024 6 open_circuits, 27.9ms\n",
            "Speed: 6.2ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_06_open_circuit_04.jpg: 832x1024 5 open_circuits, 28.0ms\n",
            "Speed: 7.0ms preprocess, 28.0ms inference, 1.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_06_open_circuit_06.jpg: 832x1024 5 open_circuits, 27.9ms\n",
            "Speed: 6.0ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_06_open_circuit_07.jpg: 832x1024 5 open_circuits, 27.9ms\n",
            "Speed: 6.0ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_06_open_circuit_08.jpg: 832x1024 5 open_circuits, 27.9ms\n",
            "Speed: 6.0ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_06_open_circuit_09.jpg: 832x1024 1 mouse_bite, 6 open_circuits, 27.9ms\n",
            "Speed: 6.1ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_06_open_circuit_10.jpg: 832x1024 6 open_circuits, 27.9ms\n",
            "Speed: 6.1ms preprocess, 27.9ms inference, 1.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_07_open_circuit_01.jpg: 704x1024 5 open_circuits, 26.4ms\n",
            "Speed: 6.0ms preprocess, 26.4ms inference, 1.3ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_07_open_circuit_02.jpg: 704x1024 5 open_circuits, 25.4ms\n",
            "Speed: 5.4ms preprocess, 25.4ms inference, 5.1ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_07_open_circuit_03.jpg: 704x1024 5 open_circuits, 25.4ms\n",
            "Speed: 5.2ms preprocess, 25.4ms inference, 1.3ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_07_open_circuit_04.jpg: 704x1024 5 open_circuits, 25.3ms\n",
            "Speed: 5.2ms preprocess, 25.3ms inference, 1.4ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_07_open_circuit_05.jpg: 704x1024 5 open_circuits, 25.3ms\n",
            "Speed: 5.3ms preprocess, 25.3ms inference, 1.5ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_07_open_circuit_06.jpg: 704x1024 5 open_circuits, 25.3ms\n",
            "Speed: 5.4ms preprocess, 25.3ms inference, 1.3ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_07_open_circuit_08.jpg: 704x1024 5 open_circuits, 25.3ms\n",
            "Speed: 5.3ms preprocess, 25.3ms inference, 1.3ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_07_open_circuit_10.jpg: 704x1024 5 open_circuits, 25.3ms\n",
            "Speed: 7.3ms preprocess, 25.3ms inference, 1.3ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_08_open_circuit_04.jpg: 800x1024 5 open_circuits, 28.1ms\n",
            "Speed: 6.7ms preprocess, 28.1ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_08_open_circuit_05.jpg: 800x1024 5 open_circuits, 27.2ms\n",
            "Speed: 5.9ms preprocess, 27.2ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_08_open_circuit_06.jpg: 800x1024 5 open_circuits, 27.3ms\n",
            "Speed: 6.0ms preprocess, 27.3ms inference, 2.2ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_08_open_circuit_08.jpg: 800x1024 5 open_circuits, 27.2ms\n",
            "Speed: 5.9ms preprocess, 27.2ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_08_open_circuit_09.jpg: 800x1024 5 open_circuits, 27.3ms\n",
            "Speed: 5.7ms preprocess, 27.3ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_09_open_circuit_01.jpg: 800x1024 5 open_circuits, 27.2ms\n",
            "Speed: 5.8ms preprocess, 27.2ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_09_open_circuit_02.jpg: 800x1024 6 open_circuits, 27.2ms\n",
            "Speed: 6.0ms preprocess, 27.2ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_09_open_circuit_03.jpg: 800x1024 5 open_circuits, 27.3ms\n",
            "Speed: 7.7ms preprocess, 27.3ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_09_open_circuit_06.jpg: 800x1024 5 open_circuits, 27.2ms\n",
            "Speed: 6.1ms preprocess, 27.2ms inference, 1.5ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_09_open_circuit_07.jpg: 800x1024 5 open_circuits, 27.2ms\n",
            "Speed: 6.2ms preprocess, 27.2ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_09_open_circuit_08.jpg: 800x1024 5 open_circuits, 27.3ms\n",
            "Speed: 5.8ms preprocess, 27.3ms inference, 2.2ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_09_open_circuit_09.jpg: 800x1024 5 open_circuits, 27.3ms\n",
            "Speed: 6.2ms preprocess, 27.3ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_10_open_circuit_01.jpg: 928x1024 5 open_circuits, 31.2ms\n",
            "Speed: 7.0ms preprocess, 31.2ms inference, 1.3ms postprocess per image at shape (1, 3, 928, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_10_open_circuit_02.jpg: 928x1024 5 open_circuits, 30.3ms\n",
            "Speed: 6.6ms preprocess, 30.3ms inference, 1.6ms postprocess per image at shape (1, 3, 928, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_10_open_circuit_03.jpg: 928x1024 5 open_circuits, 30.3ms\n",
            "Speed: 6.4ms preprocess, 30.3ms inference, 1.4ms postprocess per image at shape (1, 3, 928, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_10_open_circuit_04.jpg: 928x1024 5 open_circuits, 30.3ms\n",
            "Speed: 6.8ms preprocess, 30.3ms inference, 2.0ms postprocess per image at shape (1, 3, 928, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_10_open_circuit_05.jpg: 928x1024 5 open_circuits, 30.4ms\n",
            "Speed: 12.1ms preprocess, 30.4ms inference, 2.0ms postprocess per image at shape (1, 3, 928, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_10_open_circuit_06.jpg: 928x1024 5 open_circuits, 30.3ms\n",
            "Speed: 10.8ms preprocess, 30.3ms inference, 1.6ms postprocess per image at shape (1, 3, 928, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_11_open_circuit_01.jpg: 1024x1024 5 open_circuits, 36.3ms\n",
            "Speed: 12.5ms preprocess, 36.3ms inference, 1.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_11_open_circuit_02.jpg: 1024x1024 6 open_circuits, 33.0ms\n",
            "Speed: 11.9ms preprocess, 33.0ms inference, 1.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_11_open_circuit_03.jpg: 1024x1024 5 open_circuits, 33.0ms\n",
            "Speed: 12.2ms preprocess, 33.0ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_11_open_circuit_06.jpg: 1024x1024 5 open_circuits, 33.0ms\n",
            "Speed: 12.1ms preprocess, 33.0ms inference, 1.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_11_open_circuit_07.jpg: 1024x1024 5 open_circuits, 33.0ms\n",
            "Speed: 12.2ms preprocess, 33.0ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_11_open_circuit_08.jpg: 1024x1024 5 open_circuits, 33.0ms\n",
            "Speed: 12.0ms preprocess, 33.0ms inference, 1.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_11_open_circuit_10.jpg: 1024x1024 5 open_circuits, 33.0ms\n",
            "Speed: 12.6ms preprocess, 33.0ms inference, 3.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_12_open_circuit_01.jpg: 1024x1024 5 open_circuits, 33.1ms\n",
            "Speed: 11.4ms preprocess, 33.1ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_12_open_circuit_02.jpg: 1024x1024 5 open_circuits, 33.0ms\n",
            "Speed: 12.4ms preprocess, 33.0ms inference, 1.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_12_open_circuit_03.jpg: 1024x1024 5 open_circuits, 33.0ms\n",
            "Speed: 12.1ms preprocess, 33.0ms inference, 1.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_12_open_circuit_04.jpg: 1024x1024 5 open_circuits, 33.0ms\n",
            "Speed: 13.3ms preprocess, 33.0ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_12_open_circuit_05.jpg: 1024x1024 5 open_circuits, 33.0ms\n",
            "Speed: 12.3ms preprocess, 33.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_12_open_circuit_06.jpg: 1024x1024 5 open_circuits, 33.0ms\n",
            "Speed: 12.1ms preprocess, 33.0ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_12_open_circuit_07.jpg: 1024x1024 5 open_circuits, 33.0ms\n",
            "Speed: 11.9ms preprocess, 33.0ms inference, 1.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/open_circuit_12_open_circuit_10.jpg: 1024x1024 5 open_circuits, 33.0ms\n",
            "Speed: 12.1ms preprocess, 33.0ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_01_short_02.jpg: 544x1024 3 shorts, 21.0ms\n",
            "Speed: 6.5ms preprocess, 21.0ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_01_short_03.jpg: 544x1024 3 shorts, 19.9ms\n",
            "Speed: 6.7ms preprocess, 19.9ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_01_short_04.jpg: 544x1024 3 shorts, 19.9ms\n",
            "Speed: 6.5ms preprocess, 19.9ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_01_short_05.jpg: 544x1024 3 shorts, 20.0ms\n",
            "Speed: 6.6ms preprocess, 20.0ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_01_short_06.jpg: 544x1024 3 shorts, 20.0ms\n",
            "Speed: 6.5ms preprocess, 20.0ms inference, 2.4ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_01_short_07.jpg: 544x1024 3 shorts, 20.0ms\n",
            "Speed: 6.7ms preprocess, 20.0ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_01_short_10.jpg: 544x1024 3 shorts, 20.1ms\n",
            "Speed: 6.5ms preprocess, 20.1ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_01_short_12.jpg: 544x1024 4 shorts, 19.9ms\n",
            "Speed: 4.2ms preprocess, 19.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_01_short_13.jpg: 544x1024 4 shorts, 19.9ms\n",
            "Speed: 4.0ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_01_short_14.jpg: 544x1024 4 shorts, 19.9ms\n",
            "Speed: 4.2ms preprocess, 19.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_01_short_15.jpg: 544x1024 4 shorts, 19.9ms\n",
            "Speed: 4.2ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_01_short_16.jpg: 544x1024 5 shorts, 19.9ms\n",
            "Speed: 4.1ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_01_short_17.jpg: 544x1024 4 shorts, 19.9ms\n",
            "Speed: 4.1ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_01_short_18.jpg: 544x1024 4 shorts, 19.9ms\n",
            "Speed: 4.0ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_01_short_19.jpg: 544x1024 4 shorts, 19.9ms\n",
            "Speed: 4.0ms preprocess, 19.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_01_short_20.jpg: 544x1024 4 shorts, 19.9ms\n",
            "Speed: 6.7ms preprocess, 19.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_04_short_02.jpg: 832x1024 3 shorts, 28.6ms\n",
            "Speed: 6.3ms preprocess, 28.6ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_04_short_03.jpg: 832x1024 3 shorts, 27.9ms\n",
            "Speed: 6.5ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_04_short_08.jpg: 832x1024 3 shorts, 27.9ms\n",
            "Speed: 6.6ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_04_short_09.jpg: 832x1024 4 shorts, 27.9ms\n",
            "Speed: 6.4ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_04_short_10.jpg: 832x1024 3 shorts, 27.9ms\n",
            "Speed: 6.3ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_04_short_11.jpg: 832x1024 3 shorts, 27.9ms\n",
            "Speed: 6.4ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_04_short_12.jpg: 832x1024 3 shorts, 27.9ms\n",
            "Speed: 6.5ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_04_short_13.jpg: 832x1024 3 shorts, 27.9ms\n",
            "Speed: 6.5ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_04_short_14.jpg: 832x1024 3 shorts, 27.9ms\n",
            "Speed: 6.5ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_04_short_15.jpg: 832x1024 3 shorts, 27.8ms\n",
            "Speed: 6.5ms preprocess, 27.8ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_04_short_16.jpg: 832x1024 3 shorts, 27.9ms\n",
            "Speed: 6.3ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_04_short_20.jpg: 832x1024 3 shorts, 27.9ms\n",
            "Speed: 6.3ms preprocess, 27.9ms inference, 1.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_05_short_02.jpg: 896x1024 3 shorts, 29.6ms\n",
            "Speed: 6.7ms preprocess, 29.6ms inference, 1.2ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_05_short_03.jpg: 896x1024 3 shorts, 28.8ms\n",
            "Speed: 10.2ms preprocess, 28.8ms inference, 1.4ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_05_short_04.jpg: 896x1024 3 shorts, 28.8ms\n",
            "Speed: 6.4ms preprocess, 28.8ms inference, 1.6ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_05_short_06.jpg: 896x1024 3 shorts, 28.8ms\n",
            "Speed: 6.5ms preprocess, 28.8ms inference, 1.4ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_05_short_07.jpg: 896x1024 4 shorts, 28.8ms\n",
            "Speed: 6.5ms preprocess, 28.8ms inference, 1.6ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_05_short_08.jpg: 896x1024 3 shorts, 28.8ms\n",
            "Speed: 6.7ms preprocess, 28.8ms inference, 1.5ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_05_short_10.jpg: 896x1024 3 shorts, 28.7ms\n",
            "Speed: 6.4ms preprocess, 28.7ms inference, 1.3ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_06_short_01.jpg: 832x1024 5 shorts, 28.8ms\n",
            "Speed: 6.2ms preprocess, 28.8ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_06_short_02.jpg: 832x1024 5 shorts, 27.8ms\n",
            "Speed: 6.1ms preprocess, 27.8ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_06_short_03.jpg: 832x1024 5 shorts, 28.0ms\n",
            "Speed: 9.6ms preprocess, 28.0ms inference, 1.9ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_06_short_04.jpg: 832x1024 6 shorts, 27.9ms\n",
            "Speed: 6.1ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_06_short_05.jpg: 832x1024 5 shorts, 27.9ms\n",
            "Speed: 6.1ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_06_short_06.jpg: 832x1024 6 shorts, 27.9ms\n",
            "Speed: 6.0ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_06_short_07.jpg: 832x1024 5 shorts, 27.9ms\n",
            "Speed: 6.2ms preprocess, 27.9ms inference, 2.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_06_short_09.jpg: 832x1024 5 shorts, 27.9ms\n",
            "Speed: 6.2ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_06_short_11.jpg: 832x1024 5 shorts, 27.9ms\n",
            "Speed: 6.0ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_07_short_01.jpg: 704x1024 5 shorts, 26.0ms\n",
            "Speed: 5.3ms preprocess, 26.0ms inference, 1.3ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_07_short_03.jpg: 704x1024 5 shorts, 25.4ms\n",
            "Speed: 5.2ms preprocess, 25.4ms inference, 4.4ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_07_short_04.jpg: 704x1024 5 shorts, 25.3ms\n",
            "Speed: 5.4ms preprocess, 25.3ms inference, 1.4ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_07_short_05.jpg: 704x1024 5 shorts, 25.3ms\n",
            "Speed: 5.2ms preprocess, 25.3ms inference, 1.3ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_07_short_06.jpg: 704x1024 5 shorts, 25.4ms\n",
            "Speed: 5.2ms preprocess, 25.4ms inference, 1.3ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_07_short_07.jpg: 704x1024 5 shorts, 25.4ms\n",
            "Speed: 5.1ms preprocess, 25.4ms inference, 1.3ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_07_short_08.jpg: 704x1024 5 shorts, 25.3ms\n",
            "Speed: 5.5ms preprocess, 25.3ms inference, 1.4ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_08_short_02.jpg: 800x1024 5 shorts, 28.0ms\n",
            "Speed: 5.9ms preprocess, 28.0ms inference, 1.2ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_08_short_03.jpg: 800x1024 5 shorts, 27.2ms\n",
            "Speed: 5.9ms preprocess, 27.2ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_08_short_04.jpg: 800x1024 5 shorts, 27.2ms\n",
            "Speed: 5.7ms preprocess, 27.2ms inference, 1.7ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_08_short_05.jpg: 800x1024 6 shorts, 27.2ms\n",
            "Speed: 5.8ms preprocess, 27.2ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_08_short_06.jpg: 800x1024 5 shorts, 27.2ms\n",
            "Speed: 5.8ms preprocess, 27.2ms inference, 1.9ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_08_short_07.jpg: 800x1024 5 shorts, 27.2ms\n",
            "Speed: 5.7ms preprocess, 27.2ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_08_short_08.jpg: 800x1024 5 shorts, 27.3ms\n",
            "Speed: 5.8ms preprocess, 27.3ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_08_short_09.jpg: 800x1024 5 shorts, 27.3ms\n",
            "Speed: 6.1ms preprocess, 27.3ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_08_short_10.jpg: 800x1024 5 shorts, 27.2ms\n",
            "Speed: 5.9ms preprocess, 27.2ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_09_short_01.jpg: 800x1024 6 shorts, 27.2ms\n",
            "Speed: 6.1ms preprocess, 27.2ms inference, 2.5ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_09_short_02.jpg: 800x1024 5 shorts, 27.2ms\n",
            "Speed: 6.5ms preprocess, 27.2ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_09_short_05.jpg: 800x1024 5 shorts, 27.3ms\n",
            "Speed: 5.8ms preprocess, 27.3ms inference, 1.5ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_09_short_06.jpg: 800x1024 5 shorts, 27.2ms\n",
            "Speed: 6.4ms preprocess, 27.2ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_09_short_07.jpg: 800x1024 5 shorts, 27.3ms\n",
            "Speed: 5.9ms preprocess, 27.3ms inference, 1.5ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_09_short_08.jpg: 800x1024 5 shorts, 27.3ms\n",
            "Speed: 5.7ms preprocess, 27.3ms inference, 1.7ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_10_short_03.jpg: 928x1024 4 shorts, 31.0ms\n",
            "Speed: 6.9ms preprocess, 31.0ms inference, 1.2ms postprocess per image at shape (1, 3, 928, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_10_short_04.jpg: 928x1024 5 shorts, 30.3ms\n",
            "Speed: 6.6ms preprocess, 30.3ms inference, 1.5ms postprocess per image at shape (1, 3, 928, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_10_short_05.jpg: 928x1024 5 shorts, 30.3ms\n",
            "Speed: 6.6ms preprocess, 30.3ms inference, 1.3ms postprocess per image at shape (1, 3, 928, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_11_short_01.jpg: 1024x1024 5 shorts, 33.7ms\n",
            "Speed: 7.3ms preprocess, 33.7ms inference, 1.2ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_11_short_02.jpg: 1024x1024 5 shorts, 33.1ms\n",
            "Speed: 7.6ms preprocess, 33.1ms inference, 3.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_11_short_03.jpg: 1024x1024 5 shorts, 33.0ms\n",
            "Speed: 11.6ms preprocess, 33.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_11_short_05.jpg: 1024x1024 5 shorts, 32.9ms\n",
            "Speed: 7.5ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_11_short_06.jpg: 1024x1024 5 shorts, 32.9ms\n",
            "Speed: 7.3ms preprocess, 32.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_11_short_07.jpg: 1024x1024 5 shorts, 32.9ms\n",
            "Speed: 7.5ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_11_short_08.jpg: 1024x1024 5 shorts, 33.0ms\n",
            "Speed: 7.5ms preprocess, 33.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_11_short_09.jpg: 1024x1024 4 shorts, 32.9ms\n",
            "Speed: 7.5ms preprocess, 32.9ms inference, 2.2ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_11_short_10.jpg: 1024x1024 6 shorts, 32.9ms\n",
            "Speed: 7.4ms preprocess, 32.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_12_short_04.jpg: 1024x1024 5 shorts, 32.9ms\n",
            "Speed: 7.9ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_12_short_07.jpg: 1024x1024 5 shorts, 32.9ms\n",
            "Speed: 7.4ms preprocess, 32.9ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_12_short_08.jpg: 1024x1024 5 shorts, 32.9ms\n",
            "Speed: 7.4ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/short_12_short_09.jpg: 1024x1024 5 shorts, 32.9ms\n",
            "Speed: 7.5ms preprocess, 32.9ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_01_spur_01.jpg: 544x1024 1 spur, 21.0ms\n",
            "Speed: 3.9ms preprocess, 21.0ms inference, 7.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_01_spur_02.jpg: 544x1024 1 mouse_bite, 1 short, 20.0ms\n",
            "Speed: 6.5ms preprocess, 20.0ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_01_spur_03.jpg: 544x1024 1 mouse_bite, 3 spurs, 20.0ms\n",
            "Speed: 6.5ms preprocess, 20.0ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_01_spur_05.jpg: 544x1024 1 spur, 19.9ms\n",
            "Speed: 6.7ms preprocess, 19.9ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_01_spur_07.jpg: 544x1024 2 spurs, 20.0ms\n",
            "Speed: 6.5ms preprocess, 20.0ms inference, 2.4ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_01_spur_08.jpg: 544x1024 2 spurs, 19.9ms\n",
            "Speed: 6.6ms preprocess, 19.9ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_01_spur_09.jpg: 544x1024 2 spurs, 19.9ms\n",
            "Speed: 6.6ms preprocess, 19.9ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_01_spur_12.jpg: 544x1024 1 spur, 19.9ms\n",
            "Speed: 6.5ms preprocess, 19.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_01_spur_13.jpg: 544x1024 (no detections), 19.9ms\n",
            "Speed: 6.6ms preprocess, 19.9ms inference, 0.8ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_01_spur_14.jpg: 544x1024 (no detections), 20.0ms\n",
            "Speed: 5.2ms preprocess, 20.0ms inference, 0.8ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_01_spur_15.jpg: 544x1024 1 spur, 20.0ms\n",
            "Speed: 6.6ms preprocess, 20.0ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_01_spur_16.jpg: 544x1024 1 spur, 19.9ms\n",
            "Speed: 6.6ms preprocess, 19.9ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_01_spur_17.jpg: 544x1024 1 spur, 19.9ms\n",
            "Speed: 6.5ms preprocess, 19.9ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_01_spur_18.jpg: 544x1024 1 spur, 19.9ms\n",
            "Speed: 6.7ms preprocess, 19.9ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_04_spur_01.jpg: 832x1024 3 spurs, 28.8ms\n",
            "Speed: 10.0ms preprocess, 28.8ms inference, 1.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_04_spur_02.jpg: 832x1024 3 spurs, 28.0ms\n",
            "Speed: 10.0ms preprocess, 28.0ms inference, 1.6ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_04_spur_03.jpg: 832x1024 3 spurs, 28.1ms\n",
            "Speed: 10.5ms preprocess, 28.1ms inference, 1.6ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_04_spur_04.jpg: 832x1024 3 spurs, 28.0ms\n",
            "Speed: 10.0ms preprocess, 28.0ms inference, 1.6ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_04_spur_05.jpg: 832x1024 3 spurs, 27.9ms\n",
            "Speed: 10.2ms preprocess, 27.9ms inference, 1.9ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_04_spur_06.jpg: 832x1024 3 spurs, 28.0ms\n",
            "Speed: 9.8ms preprocess, 28.0ms inference, 1.7ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_04_spur_07.jpg: 832x1024 3 spurs, 28.0ms\n",
            "Speed: 9.7ms preprocess, 28.0ms inference, 1.8ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_04_spur_08.jpg: 832x1024 3 spurs, 27.9ms\n",
            "Speed: 9.5ms preprocess, 27.9ms inference, 1.9ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_04_spur_09.jpg: 832x1024 3 spurs, 28.0ms\n",
            "Speed: 14.2ms preprocess, 28.0ms inference, 1.9ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_04_spur_12.jpg: 832x1024 3 spurs, 28.0ms\n",
            "Speed: 9.7ms preprocess, 28.0ms inference, 1.8ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_04_spur_13.jpg: 832x1024 3 spurs, 27.9ms\n",
            "Speed: 6.3ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_04_spur_15.jpg: 832x1024 3 spurs, 27.8ms\n",
            "Speed: 6.4ms preprocess, 27.8ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_04_spur_16.jpg: 832x1024 3 spurs, 27.9ms\n",
            "Speed: 6.4ms preprocess, 27.9ms inference, 1.9ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_04_spur_17.jpg: 832x1024 3 spurs, 27.9ms\n",
            "Speed: 6.2ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_04_spur_18.jpg: 832x1024 3 spurs, 27.9ms\n",
            "Speed: 6.3ms preprocess, 27.9ms inference, 1.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_04_spur_20.jpg: 832x1024 3 spurs, 27.9ms\n",
            "Speed: 6.4ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_05_spur_02.jpg: 896x1024 5 spurs, 29.5ms\n",
            "Speed: 6.4ms preprocess, 29.5ms inference, 1.3ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_05_spur_03.jpg: 896x1024 5 spurs, 28.8ms\n",
            "Speed: 6.4ms preprocess, 28.8ms inference, 1.5ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_05_spur_04.jpg: 896x1024 6 spurs, 28.7ms\n",
            "Speed: 6.4ms preprocess, 28.7ms inference, 1.5ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_05_spur_05.jpg: 896x1024 5 spurs, 28.8ms\n",
            "Speed: 7.3ms preprocess, 28.8ms inference, 1.4ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_05_spur_06.jpg: 896x1024 5 spurs, 28.7ms\n",
            "Speed: 6.8ms preprocess, 28.7ms inference, 1.3ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_05_spur_07.jpg: 896x1024 5 spurs, 28.8ms\n",
            "Speed: 6.6ms preprocess, 28.8ms inference, 1.3ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_05_spur_10.jpg: 896x1024 6 spurs, 28.7ms\n",
            "Speed: 6.3ms preprocess, 28.7ms inference, 1.4ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_06_spur_01.jpg: 832x1024 5 spurs, 28.6ms\n",
            "Speed: 6.5ms preprocess, 28.6ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_06_spur_02.jpg: 832x1024 5 spurs, 27.9ms\n",
            "Speed: 6.1ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_06_spur_03.jpg: 832x1024 5 spurs, 27.9ms\n",
            "Speed: 6.3ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_06_spur_04.jpg: 832x1024 4 spurs, 27.9ms\n",
            "Speed: 6.2ms preprocess, 27.9ms inference, 1.7ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_06_spur_05.jpg: 832x1024 5 spurs, 27.9ms\n",
            "Speed: 6.2ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_06_spur_08.jpg: 832x1024 5 spurs, 27.9ms\n",
            "Speed: 6.1ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_06_spur_09.jpg: 832x1024 6 spurs, 27.8ms\n",
            "Speed: 6.1ms preprocess, 27.8ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_07_spur_02.jpg: 704x1024 5 spurs, 26.1ms\n",
            "Speed: 5.1ms preprocess, 26.1ms inference, 1.2ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_07_spur_03.jpg: 704x1024 5 spurs, 25.3ms\n",
            "Speed: 5.5ms preprocess, 25.3ms inference, 1.3ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_07_spur_04.jpg: 704x1024 5 spurs, 25.3ms\n",
            "Speed: 5.3ms preprocess, 25.3ms inference, 1.6ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_07_spur_09.jpg: 704x1024 5 spurs, 25.3ms\n",
            "Speed: 5.2ms preprocess, 25.3ms inference, 1.3ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_08_spur_01.jpg: 800x1024 5 spurs, 28.0ms\n",
            "Speed: 6.4ms preprocess, 28.0ms inference, 1.8ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_08_spur_03.jpg: 800x1024 5 spurs, 27.2ms\n",
            "Speed: 6.3ms preprocess, 27.2ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_08_spur_05.jpg: 800x1024 5 spurs, 27.2ms\n",
            "Speed: 5.9ms preprocess, 27.2ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_08_spur_06.jpg: 800x1024 5 spurs, 27.3ms\n",
            "Speed: 5.9ms preprocess, 27.3ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_08_spur_07.jpg: 800x1024 5 spurs, 27.2ms\n",
            "Speed: 5.8ms preprocess, 27.2ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_08_spur_09.jpg: 800x1024 6 spurs, 27.2ms\n",
            "Speed: 6.4ms preprocess, 27.2ms inference, 1.6ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_08_spur_10.jpg: 800x1024 5 spurs, 27.2ms\n",
            "Speed: 6.0ms preprocess, 27.2ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_09_spur_02.jpg: 800x1024 5 spurs, 27.2ms\n",
            "Speed: 6.1ms preprocess, 27.2ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_09_spur_03.jpg: 800x1024 5 spurs, 27.2ms\n",
            "Speed: 6.0ms preprocess, 27.2ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_09_spur_04.jpg: 800x1024 5 spurs, 27.3ms\n",
            "Speed: 5.8ms preprocess, 27.3ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_09_spur_06.jpg: 800x1024 5 spurs, 27.2ms\n",
            "Speed: 5.9ms preprocess, 27.2ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_09_spur_10.jpg: 800x1024 5 spurs, 27.2ms\n",
            "Speed: 6.0ms preprocess, 27.2ms inference, 1.6ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_10_spur_04.jpg: 928x1024 5 spurs, 31.1ms\n",
            "Speed: 6.9ms preprocess, 31.1ms inference, 1.3ms postprocess per image at shape (1, 3, 928, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_10_spur_05.jpg: 928x1024 5 spurs, 30.3ms\n",
            "Speed: 6.7ms preprocess, 30.3ms inference, 1.4ms postprocess per image at shape (1, 3, 928, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_11_spur_01.jpg: 1024x1024 5 spurs, 33.7ms\n",
            "Speed: 7.2ms preprocess, 33.7ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_11_spur_02.jpg: 1024x1024 5 spurs, 32.9ms\n",
            "Speed: 7.4ms preprocess, 32.9ms inference, 1.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_11_spur_03.jpg: 1024x1024 5 spurs, 32.9ms\n",
            "Speed: 7.6ms preprocess, 32.9ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_11_spur_05.jpg: 1024x1024 5 spurs, 32.9ms\n",
            "Speed: 7.3ms preprocess, 32.9ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_11_spur_06.jpg: 1024x1024 5 spurs, 32.9ms\n",
            "Speed: 7.3ms preprocess, 32.9ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_11_spur_07.jpg: 1024x1024 5 spurs, 32.9ms\n",
            "Speed: 7.2ms preprocess, 32.9ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_11_spur_08.jpg: 1024x1024 5 spurs, 33.0ms\n",
            "Speed: 11.4ms preprocess, 33.0ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_11_spur_09.jpg: 1024x1024 5 spurs, 32.9ms\n",
            "Speed: 7.3ms preprocess, 32.9ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_11_spur_10.jpg: 1024x1024 5 spurs, 32.9ms\n",
            "Speed: 7.4ms preprocess, 32.9ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_12_spur_01.jpg: 1024x1024 5 spurs, 32.9ms\n",
            "Speed: 7.7ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_12_spur_02.jpg: 1024x1024 5 spurs, 33.0ms\n",
            "Speed: 7.5ms preprocess, 33.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_12_spur_03.jpg: 1024x1024 5 spurs, 32.9ms\n",
            "Speed: 7.4ms preprocess, 32.9ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_12_spur_04.jpg: 1024x1024 5 spurs, 33.0ms\n",
            "Speed: 7.6ms preprocess, 33.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_12_spur_05.jpg: 1024x1024 5 spurs, 33.0ms\n",
            "Speed: 7.8ms preprocess, 33.0ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_12_spur_06.jpg: 1024x1024 5 spurs, 32.9ms\n",
            "Speed: 7.8ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_12_spur_07.jpg: 1024x1024 5 spurs, 32.9ms\n",
            "Speed: 7.7ms preprocess, 32.9ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_12_spur_09.jpg: 1024x1024 6 spurs, 32.9ms\n",
            "Speed: 8.4ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spur_12_spur_10.jpg: 1024x1024 5 spurs, 33.0ms\n",
            "Speed: 7.8ms preprocess, 33.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_01_spurious_copper_01.jpg: 544x1024 1 missing_hole, 3 spurious_coppers, 20.7ms\n",
            "Speed: 4.2ms preprocess, 20.7ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_01_spurious_copper_02.jpg: 544x1024 3 spurious_coppers, 19.9ms\n",
            "Speed: 4.1ms preprocess, 19.9ms inference, 5.4ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_01_spurious_copper_04.jpg: 544x1024 3 spurious_coppers, 19.9ms\n",
            "Speed: 4.2ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_01_spurious_copper_05.jpg: 544x1024 2 spurious_coppers, 19.9ms\n",
            "Speed: 4.2ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_01_spurious_copper_06.jpg: 544x1024 3 spurious_coppers, 19.9ms\n",
            "Speed: 4.1ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_01_spurious_copper_07.jpg: 544x1024 3 spurious_coppers, 19.9ms\n",
            "Speed: 4.2ms preprocess, 19.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_01_spurious_copper_15.jpg: 544x1024 4 spurious_coppers, 19.9ms\n",
            "Speed: 4.1ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_01_spurious_copper_16.jpg: 544x1024 2 spurious_coppers, 19.9ms\n",
            "Speed: 4.1ms preprocess, 19.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_01_spurious_copper_17.jpg: 544x1024 3 spurious_coppers, 19.9ms\n",
            "Speed: 4.1ms preprocess, 19.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_01_spurious_copper_18.jpg: 544x1024 3 spurious_coppers, 19.9ms\n",
            "Speed: 4.1ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_01_spurious_copper_19.jpg: 544x1024 3 spurious_coppers, 19.9ms\n",
            "Speed: 4.3ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_04_spurious_copper_01.jpg: 832x1024 3 spurious_coppers, 28.6ms\n",
            "Speed: 6.4ms preprocess, 28.6ms inference, 1.2ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_04_spurious_copper_02.jpg: 832x1024 3 spurious_coppers, 27.9ms\n",
            "Speed: 9.7ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_04_spurious_copper_03.jpg: 832x1024 3 spurious_coppers, 27.9ms\n",
            "Speed: 6.5ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_04_spurious_copper_04.jpg: 832x1024 3 spurious_coppers, 27.9ms\n",
            "Speed: 6.4ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_04_spurious_copper_05.jpg: 832x1024 3 spurious_coppers, 27.9ms\n",
            "Speed: 6.3ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_04_spurious_copper_08.jpg: 832x1024 3 spurious_coppers, 27.8ms\n",
            "Speed: 6.2ms preprocess, 27.8ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_04_spurious_copper_09.jpg: 832x1024 3 spurious_coppers, 27.8ms\n",
            "Speed: 6.3ms preprocess, 27.8ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_04_spurious_copper_10.jpg: 832x1024 3 spurious_coppers, 27.9ms\n",
            "Speed: 6.5ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_04_spurious_copper_13.jpg: 832x1024 3 spurious_coppers, 28.0ms\n",
            "Speed: 9.9ms preprocess, 28.0ms inference, 2.0ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_04_spurious_copper_14.jpg: 832x1024 3 spurious_coppers, 28.0ms\n",
            "Speed: 11.3ms preprocess, 28.0ms inference, 1.8ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_04_spurious_copper_15.jpg: 832x1024 3 spurious_coppers, 27.9ms\n",
            "Speed: 9.9ms preprocess, 27.9ms inference, 1.9ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_04_spurious_copper_17.jpg: 832x1024 3 spurious_coppers, 27.9ms\n",
            "Speed: 9.9ms preprocess, 27.9ms inference, 1.8ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_04_spurious_copper_18.jpg: 832x1024 3 spurious_coppers, 27.9ms\n",
            "Speed: 9.9ms preprocess, 27.9ms inference, 1.6ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_04_spurious_copper_20.jpg: 832x1024 3 spurious_coppers, 27.9ms\n",
            "Speed: 10.0ms preprocess, 27.9ms inference, 1.8ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_05_spurious_copper_01.jpg: 896x1024 5 spurious_coppers, 30.0ms\n",
            "Speed: 10.0ms preprocess, 30.0ms inference, 1.9ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_05_spurious_copper_03.jpg: 896x1024 4 spurious_coppers, 28.9ms\n",
            "Speed: 10.6ms preprocess, 28.9ms inference, 2.1ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_05_spurious_copper_06.jpg: 896x1024 5 spurious_coppers, 28.8ms\n",
            "Speed: 10.6ms preprocess, 28.8ms inference, 1.8ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_05_spurious_copper_08.jpg: 896x1024 5 spurious_coppers, 28.8ms\n",
            "Speed: 10.4ms preprocess, 28.8ms inference, 1.7ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_05_spurious_copper_09.jpg: 896x1024 6 spurious_coppers, 28.8ms\n",
            "Speed: 10.6ms preprocess, 28.8ms inference, 1.7ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_06_spurious_copper_03.jpg: 832x1024 5 spurious_coppers, 28.9ms\n",
            "Speed: 10.2ms preprocess, 28.9ms inference, 1.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_06_spurious_copper_05.jpg: 832x1024 5 spurious_coppers, 28.0ms\n",
            "Speed: 10.0ms preprocess, 28.0ms inference, 2.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_06_spurious_copper_08.jpg: 832x1024 5 spurious_coppers, 28.0ms\n",
            "Speed: 10.4ms preprocess, 28.0ms inference, 1.7ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_06_spurious_copper_10.jpg: 832x1024 5 spurious_coppers, 27.9ms\n",
            "Speed: 9.9ms preprocess, 27.9ms inference, 1.6ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_07_spurious_copper_03.jpg: 704x1024 5 spurious_coppers, 26.6ms\n",
            "Speed: 8.3ms preprocess, 26.6ms inference, 2.3ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_07_spurious_copper_05.jpg: 704x1024 5 spurious_coppers, 25.4ms\n",
            "Speed: 8.4ms preprocess, 25.4ms inference, 1.6ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_07_spurious_copper_06.jpg: 704x1024 5 spurious_coppers, 25.4ms\n",
            "Speed: 8.5ms preprocess, 25.4ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_07_spurious_copper_08.jpg: 704x1024 5 spurious_coppers, 25.5ms\n",
            "Speed: 10.1ms preprocess, 25.5ms inference, 2.3ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_07_spurious_copper_09.jpg: 704x1024 5 spurious_coppers, 25.4ms\n",
            "Speed: 10.3ms preprocess, 25.4ms inference, 1.9ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_07_spurious_copper_10.jpg: 704x1024 5 spurious_coppers, 25.4ms\n",
            "Speed: 8.4ms preprocess, 25.4ms inference, 1.9ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_08_spurious_copper_01.jpg: 800x1024 5 spurious_coppers, 28.8ms\n",
            "Speed: 9.9ms preprocess, 28.8ms inference, 1.9ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_08_spurious_copper_02.jpg: 800x1024 5 spurious_coppers, 27.3ms\n",
            "Speed: 9.6ms preprocess, 27.3ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_08_spurious_copper_06.jpg: 800x1024 5 spurious_coppers, 27.3ms\n",
            "Speed: 5.8ms preprocess, 27.3ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_08_spurious_copper_07.jpg: 800x1024 5 spurious_coppers, 27.2ms\n",
            "Speed: 5.9ms preprocess, 27.2ms inference, 1.5ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_08_spurious_copper_08.jpg: 800x1024 5 spurious_coppers, 27.3ms\n",
            "Speed: 5.9ms preprocess, 27.3ms inference, 2.2ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_08_spurious_copper_09.jpg: 800x1024 5 spurious_coppers, 27.2ms\n",
            "Speed: 5.9ms preprocess, 27.2ms inference, 1.5ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_08_spurious_copper_10.jpg: 800x1024 5 spurious_coppers, 27.2ms\n",
            "Speed: 5.9ms preprocess, 27.2ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_09_spurious_copper_01.jpg: 800x1024 5 spurious_coppers, 27.3ms\n",
            "Speed: 6.0ms preprocess, 27.3ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_09_spurious_copper_04.jpg: 800x1024 5 spurious_coppers, 27.2ms\n",
            "Speed: 5.9ms preprocess, 27.2ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_09_spurious_copper_05.jpg: 800x1024 5 spurious_coppers, 27.2ms\n",
            "Speed: 5.8ms preprocess, 27.2ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_09_spurious_copper_06.jpg: 800x1024 6 spurious_coppers, 27.3ms\n",
            "Speed: 5.7ms preprocess, 27.3ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_09_spurious_copper_09.jpg: 800x1024 5 spurious_coppers, 27.3ms\n",
            "Speed: 6.1ms preprocess, 27.3ms inference, 1.5ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_10_spurious_copper_04.jpg: 928x1024 5 spurious_coppers, 31.3ms\n",
            "Speed: 11.7ms preprocess, 31.3ms inference, 1.2ms postprocess per image at shape (1, 3, 928, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_10_spurious_copper_05.jpg: 928x1024 6 spurious_coppers, 30.3ms\n",
            "Speed: 7.0ms preprocess, 30.3ms inference, 1.4ms postprocess per image at shape (1, 3, 928, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_10_spurious_copper_06.jpg: 928x1024 5 spurious_coppers, 30.3ms\n",
            "Speed: 6.8ms preprocess, 30.3ms inference, 1.4ms postprocess per image at shape (1, 3, 928, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_11_spurious_copper_03.jpg: 1024x1024 5 spurious_coppers, 33.6ms\n",
            "Speed: 7.6ms preprocess, 33.6ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_11_spurious_copper_04.jpg: 1024x1024 5 spurious_coppers, 32.9ms\n",
            "Speed: 7.2ms preprocess, 32.9ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_11_spurious_copper_05.jpg: 1024x1024 5 spurious_coppers, 32.9ms\n",
            "Speed: 7.2ms preprocess, 32.9ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_11_spurious_copper_06.jpg: 1024x1024 5 spurious_coppers, 32.9ms\n",
            "Speed: 7.2ms preprocess, 32.9ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_11_spurious_copper_07.jpg: 1024x1024 5 spurious_coppers, 32.9ms\n",
            "Speed: 8.2ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_11_spurious_copper_09.jpg: 1024x1024 6 spurious_coppers, 33.0ms\n",
            "Speed: 11.4ms preprocess, 33.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_11_spurious_copper_10.jpg: 1024x1024 5 spurious_coppers, 32.9ms\n",
            "Speed: 7.7ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_12_spurious_copper_02.jpg: 1024x1024 5 spurious_coppers, 32.9ms\n",
            "Speed: 7.5ms preprocess, 32.9ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_12_spurious_copper_03.jpg: 1024x1024 5 spurious_coppers, 32.9ms\n",
            "Speed: 7.5ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_12_spurious_copper_04.jpg: 1024x1024 5 spurious_coppers, 32.9ms\n",
            "Speed: 7.4ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_12_spurious_copper_05.jpg: 1024x1024 5 spurious_coppers, 32.9ms\n",
            "Speed: 7.5ms preprocess, 32.9ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_12_spurious_copper_06.jpg: 1024x1024 5 spurious_coppers, 32.9ms\n",
            "Speed: 7.5ms preprocess, 32.9ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_12_spurious_copper_07.jpg: 1024x1024 5 spurious_coppers, 32.9ms\n",
            "Speed: 7.4ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_12_spurious_copper_08.jpg: 1024x1024 5 spurious_coppers, 32.9ms\n",
            "Speed: 8.4ms preprocess, 32.9ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_12_spurious_copper_09.jpg: 1024x1024 5 spurious_coppers, 32.9ms\n",
            "Speed: 7.7ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/train/spurious_copper_12_spurious_copper_10.jpg: 1024x1024 5 spurious_coppers, 32.9ms\n",
            "Speed: 7.6ms preprocess, 32.9ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "ìƒì„± ì™„ë£Œ! ì´ 2058ê°œì˜ ROI+maskê°€ ìƒì„±ë¨.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def unet_segment(roi):\n",
        "    ori_h, ori_w = roi.shape[:2]\n",
        "\n",
        "    roi_resized = cv2.resize(roi, (256,256))\n",
        "    inp = roi_resized.astype(np.float32) / 255.\n",
        "    inp = np.expand_dims(inp, axis=0)\n",
        "\n",
        "    mask = unet.predict(inp)[0]\n",
        "    mask = (mask > 0.5).astype(np.uint8) * 255\n",
        "\n",
        "    mask = cv2.resize(mask, (ori_w, ori_h))\n",
        "    return mask\n"
      ],
      "metadata": {
        "id": "aYOrixi-_Syo"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def overlay_masks(original, boxes, masks):\n",
        "    out = original.copy()\n",
        "\n",
        "    for (x1,y1,x2,y2), mask in zip(boxes, masks):\n",
        "        mask_colored = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
        "        colored = np.zeros_like(mask_colored)\n",
        "        colored[:,:,1] = mask  # green highlight\n",
        "\n",
        "        blended = cv2.addWeighted(out[y1:y2, x1:x2], 0.7, colored, 0.3, 0)\n",
        "        out[y1:y2, x1:x2] = blended\n",
        "\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "ZDs5bgIu_UJs"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. U-Net í•™ìŠµ íŒŒíŠ¸\n",
        "\n",
        "7-1. Data Generator\n",
        "\n",
        "tf.keras.utils.Sequenceë¥¼ ìƒì†í•œ ì»¤ìŠ¤í…€ ì œë„ˆë ˆì´í„°\n",
        "\n",
        "ë°°ì¹˜ ë‹¨ìœ„ë¡œ:\n",
        "\n",
        "ì´ë¯¸ì§€ëŠ” 256Ã—256, 0~1ë¡œ ìŠ¤ì¼€ì¼ë§\n",
        "\n",
        "ë§ˆìŠ¤í¬ëŠ” grayscale, 0~1ë¡œ ìŠ¤ì¼€ì¼ë§\n"
      ],
      "metadata": {
        "id": "DYBhPhq_Dr6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "class UNetGenerator(Sequence):\n",
        "    def __init__(self, img_dir, mask_dir, batch_size=8, img_size=(256,256)):\n",
        "        self.img_paths = sorted(glob(f\"{img_dir}/*.png\"))\n",
        "        self.mask_paths = sorted(glob(f\"{mask_dir}/*.png\"))\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_imgs = self.img_paths[idx*self.batch_size:(idx+1)*self.batch_size]\n",
        "        batch_masks = self.mask_paths[idx*self.batch_size:(idx+1)*self.batch_size]\n",
        "\n",
        "        X, y = [], []\n",
        "        for img_p, mask_p in zip(batch_imgs, batch_masks):\n",
        "            img = load_img(img_p, target_size=self.img_size)\n",
        "            mask = load_img(mask_p, target_size=self.img_size, color_mode=\"grayscale\")\n",
        "\n",
        "            X.append(img_to_array(img) / 255.)\n",
        "            y.append(img_to_array(mask) / 255.)\n",
        "\n",
        "        return np.array(X), np.array(y)\n"
      ],
      "metadata": {
        "id": "kgiqjCP-_VJx"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, Model\n",
        "\n",
        "def build_unet(input_shape=(256,256,3)):\n",
        "    inputs = layers.Input(input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    c1 = layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(inputs)\n",
        "    c1 = layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(c1)\n",
        "    p1 = layers.MaxPool2D()(c1)\n",
        "\n",
        "    c2 = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(p1)\n",
        "    c2 = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(c2)\n",
        "    p2 = layers.MaxPool2D()(c2)\n",
        "\n",
        "    c3 = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(p2)\n",
        "    c3 = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(c3)\n",
        "\n",
        "    # Decoder\n",
        "    u4 = layers.UpSampling2D()(c3)\n",
        "    u4 = layers.concatenate([u4, c2])\n",
        "    c4 = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(u4)\n",
        "    c4 = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(c4)\n",
        "\n",
        "    u5 = layers.UpSampling2D()(c4)\n",
        "    u5 = layers.concatenate([u5, c1])\n",
        "    c5 = layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(u5)\n",
        "    c5 = layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(c5)\n",
        "\n",
        "    outputs = layers.Conv2D(1, 1, activation=\"sigmoid\")(c5)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "iy3E3G6-7qKO"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SzTfd58GD0OA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7-2. U-Net ë¹Œë“œ & í•™ìŠµ\n",
        "\n",
        "ê²½ëŸ‰ U-Net êµ¬ì¡°(Encoderâ€“Decoder + Skip connection)\n",
        "\n",
        "Binary segmentationì´ë¼ loss='binary_crossentropy', ì¶œë ¥ ì±„ë„ 1, sigmoid ì‚¬ìš©\n"
      ],
      "metadata": {
        "id": "vwo4eF1FD0ro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen = UNetGenerator(\"/content/unet_dataset/images\",\n",
        "                          \"/content/unet_dataset/masks\",\n",
        "                          batch_size=8)\n",
        "\n",
        "unet = build_unet((256,256,3))\n",
        "unet.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "unet.fit(train_gen, epochs=20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2O2CFI9Jl6N",
        "outputId": "dc4a5e62-aa90-477e-f907-697ec969e7b7",
        "collapsed": true
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m257/257\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 106ms/step - accuracy: 0.8058 - loss: 0.4076\n",
            "Epoch 2/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 104ms/step - accuracy: 0.9382 - loss: 0.1734\n",
            "Epoch 3/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 103ms/step - accuracy: 0.9472 - loss: 0.1485\n",
            "Epoch 4/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 105ms/step - accuracy: 0.9449 - loss: 0.1538\n",
            "Epoch 5/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 104ms/step - accuracy: 0.9463 - loss: 0.1532\n",
            "Epoch 6/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 103ms/step - accuracy: 0.9438 - loss: 0.1583\n",
            "Epoch 7/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 104ms/step - accuracy: 0.9520 - loss: 0.1360\n",
            "Epoch 8/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 104ms/step - accuracy: 0.9528 - loss: 0.1360\n",
            "Epoch 9/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 103ms/step - accuracy: 0.9402 - loss: 0.1661\n",
            "Epoch 10/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 104ms/step - accuracy: 0.9532 - loss: 0.1327\n",
            "Epoch 11/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 104ms/step - accuracy: 0.9447 - loss: 0.1522\n",
            "Epoch 12/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 108ms/step - accuracy: 0.9510 - loss: 0.1391\n",
            "Epoch 13/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 104ms/step - accuracy: 0.9532 - loss: 0.1312\n",
            "Epoch 14/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 104ms/step - accuracy: 0.9487 - loss: 0.1433\n",
            "Epoch 15/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 104ms/step - accuracy: 0.9553 - loss: 0.1269\n",
            "Epoch 16/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 104ms/step - accuracy: 0.9565 - loss: 0.1269\n",
            "Epoch 17/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 104ms/step - accuracy: 0.9505 - loss: 0.1429\n",
            "Epoch 18/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 104ms/step - accuracy: 0.9613 - loss: 0.1131\n",
            "Epoch 19/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 104ms/step - accuracy: 0.9561 - loss: 0.1287\n",
            "Epoch 20/20\n",
            "\u001b[1m257/257\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 104ms/step - accuracy: 0.9525 - loss: 0.1318\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7cd2dd99c9e0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unet.save_weights(\"unet_best.weights.h5\")"
      ],
      "metadata": {
        "id": "n_lEbNd6Jnqm"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet.load_weights(\"unet_best.weights.h5\")"
      ],
      "metadata": {
        "id": "jN37MAUBNB3W"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JfPdTPYVD_2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. U-Net ì¶”ë¡  + ê²°ê³¼ í•©ì„±\n",
        "\n",
        "8-1. ROI í•˜ë‚˜ì— ëŒ€í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜\n",
        "\n",
        "ROIë¥¼ 256Ã—256ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ â†’ U-Net í†µê³¼ â†’ 0~1 í™•ë¥  ì¶œë ¥\n",
        "\n",
        "0.5 ê¸°ì¤€ìœ¼ë¡œ ì´ì§„í™” â†’ ë‹¤ì‹œ ì›ë˜ ROI í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆí•´ì„œ ë°˜í™˜"
      ],
      "metadata": {
        "id": "tYGsv_dYEAQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unet_segment(roi):\n",
        "    h, w = roi.shape[:2]\n",
        "    inp = cv2.resize(roi, (256,256)).astype(np.float32)/255.\n",
        "    mask = unet.predict(np.expand_dims(inp, 0))[0]\n",
        "    mask = (mask > 0.5).astype(np.uint8)*255\n",
        "    mask = cv2.resize(mask, (w,h))\n",
        "    return mask\n"
      ],
      "metadata": {
        "id": "QiF1Yc7JMlvr"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8-2. ì›ë³¸ ì´ë¯¸ì§€ ìœ„ì— ë§ˆìŠ¤í¬ ì…íˆê¸°\n",
        "\n",
        "ë°”ìš´ë”© ë°•ìŠ¤ ì˜ì—­ì— ëŒ€í•´:\n",
        "\n",
        "ë§ˆìŠ¤í¬ë¥¼ ì´ˆë¡ìƒ‰ ì±„ë„ì— ì–¹ê³ \n",
        "\n",
        "ì›ë³¸ê³¼ 0.7 : 0.3 ë¹„ìœ¨ë¡œ í•©ì„±í•´ì„œ ë¶ˆëŸ‰ ë¶€ë¶„ì´ ì´ˆë¡ìƒ‰ìœ¼ë¡œ ê°•ì¡°ëœ ê²°ê³¼ ì´ë¯¸ì§€ ìƒì„±"
      ],
      "metadata": {
        "id": "1DUGfrPiEJOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def overlay(original, boxes, masks):\n",
        "    out = original.copy()\n",
        "    for (x1,y1,x2,y2), mask in zip(boxes, masks):\n",
        "        colored = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
        "        green = np.zeros_like(colored)\n",
        "        green[:,:,1] = mask\n",
        "        out[y1:y2, x1:x2] = cv2.addWeighted(out[y1:y2,x1:x2], 0.7, green, 0.3, 0)\n",
        "    return out\n",
        "\n",
        "def overlay_red(original, boxes, masks):\n",
        "  out = original.copy()\n",
        "\n",
        "  for (x1, y1, x2, y2), mask in zip(boxes, masks):\n",
        "      # maskë¥¼ 3ì±„ë„ë¡œ ë³€í™˜\n",
        "      mask_color = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "      # ë¹¨ê°„ìƒ‰ ì˜ì—­ ìƒì„±\n",
        "      red = np.zeros_like(mask_color)\n",
        "      red[:, :, 2] = mask  # R ì±„ë„ë§Œ í™œì„±í™” â†’ ë¹¨ê°„ìƒ‰\n",
        "\n",
        "      # ë°˜íˆ¬ëª… í•©ì„±: ì›ë³¸ 70% + ë¹¨ê°• 30%\n",
        "      blended = cv2.addWeighted(\n",
        "          out[y1:y2, x1:x2], 0.7,\n",
        "          red, 0.3,\n",
        "          0\n",
        "      )\n",
        "\n",
        "      out[y1:y2, x1:x2] = blended\n",
        "\n",
        "  return out\n",
        "\n"
      ],
      "metadata": {
        "id": "Xi-AXLGMMmk3"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "from pathlib import Path\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "save_overlay_dir = \"runs/predict/overlay_red\"\n",
        "os.makedirs(save_overlay_dir, exist_ok=True)\n",
        "\n",
        "test_images = glob(\"/content/dataset_yolo_seg/images/test/*.jpg\")\n",
        "\n",
        "for img_path in test_images:\n",
        "    original, rois, boxes = extract_rois(img_path)\n",
        "\n",
        "    if len(rois) == 0:\n",
        "        continue\n",
        "\n",
        "    # U-Net masks ìƒì„±\n",
        "    masks = [unet_segment(roi) for roi in rois]\n",
        "\n",
        "    # ë¹¨ê°„ìƒ‰ overlay ìƒì„±\n",
        "    overlay_img = overlay_red(original, boxes, masks)\n",
        "\n",
        "    # ì €ì¥\n",
        "    out_name = f\"{Path(img_path).stem}_overlay_red.png\"\n",
        "    cv2.imwrite(f\"{save_overlay_dir}/{out_name}\", overlay_img)\n",
        "\n",
        "print(\"ğŸ¨ ë¹¨ê°„ìƒ‰ segmentation overlay ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-LzMUJmH89U",
        "outputId": "0e15d2d8-fd82-476a-a228-0f6f596949f8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_11_short_04.jpg: 1024x1024 5 shorts, 34.3ms\n",
            "Speed: 12.3ms preprocess, 34.3ms inference, 2.2ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_05_mouse_bite_02.jpg: 896x1024 5 mouse_bites, 30.6ms\n",
            "Speed: 10.4ms preprocess, 30.6ms inference, 2.4ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_05_missing_hole_01.jpg: 896x1024 3 missing_holes, 28.8ms\n",
            "Speed: 10.7ms preprocess, 28.8ms inference, 1.7ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_08_missing_hole_06.jpg: 800x1024 5 missing_holes, 29.5ms\n",
            "Speed: 8.0ms preprocess, 29.5ms inference, 2.0ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_08_open_circuit_03.jpg: 800x1024 1 mouse_bite, 4 open_circuits, 27.2ms\n",
            "Speed: 6.2ms preprocess, 27.2ms inference, 2.1ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_01_open_circuit_20.jpg: 544x1024 3 open_circuits, 20.7ms\n",
            "Speed: 4.1ms preprocess, 20.7ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_08_short_01.jpg: 800x1024 5 shorts, 28.1ms\n",
            "Speed: 7.2ms preprocess, 28.1ms inference, 1.9ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_05_open_circuit_08.jpg: 896x1024 3 open_circuits, 29.5ms\n",
            "Speed: 9.5ms preprocess, 29.5ms inference, 1.2ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_04_open_circuit_05.jpg: 832x1024 3 open_circuits, 28.7ms\n",
            "Speed: 9.3ms preprocess, 28.7ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_10_mouse_bite_02.jpg: 928x1024 6 mouse_bites, 31.4ms\n",
            "Speed: 7.1ms preprocess, 31.4ms inference, 1.4ms postprocess per image at shape (1, 3, 928, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_12_short_02.jpg: 1024x1024 5 shorts, 33.6ms\n",
            "Speed: 10.2ms preprocess, 33.6ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_04_short_19.jpg: 832x1024 2 shorts, 28.5ms\n",
            "Speed: 6.7ms preprocess, 28.5ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_07_spurious_copper_07.jpg: 704x1024 5 spurious_coppers, 26.1ms\n",
            "Speed: 5.6ms preprocess, 26.1ms inference, 1.3ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_04_missing_hole_09.jpg: 832x1024 3 missing_holes, 28.6ms\n",
            "Speed: 6.1ms preprocess, 28.6ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_10_mouse_bite_05.jpg: 928x1024 5 mouse_bites, 31.0ms\n",
            "Speed: 6.6ms preprocess, 31.0ms inference, 1.3ms postprocess per image at shape (1, 3, 928, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_05_open_circuit_03.jpg: 896x1024 3 open_circuits, 29.5ms\n",
            "Speed: 8.3ms preprocess, 29.5ms inference, 1.3ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_09_spurious_copper_02.jpg: 800x1024 5 spurious_coppers, 28.1ms\n",
            "Speed: 9.5ms preprocess, 28.1ms inference, 1.7ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_05_mouse_bite_03.jpg: 896x1024 5 mouse_bites, 30.3ms\n",
            "Speed: 12.5ms preprocess, 30.3ms inference, 2.1ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_07_spur_01.jpg: 704x1024 5 spurs, 26.7ms\n",
            "Speed: 8.0ms preprocess, 26.7ms inference, 1.9ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_01_missing_hole_10.jpg: 544x1024 3 missing_holes, 20.7ms\n",
            "Speed: 4.1ms preprocess, 20.7ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_09_spur_07.jpg: 800x1024 5 spurs, 28.2ms\n",
            "Speed: 6.1ms preprocess, 28.2ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_08_spur_02.jpg: 800x1024 4 spurs, 27.2ms\n",
            "Speed: 7.4ms preprocess, 27.2ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_06_missing_hole_10.jpg: 832x1024 5 missing_holes, 28.7ms\n",
            "Speed: 8.3ms preprocess, 28.7ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_06_open_circuit_02.jpg: 832x1024 5 open_circuits, 28.0ms\n",
            "Speed: 8.5ms preprocess, 28.0ms inference, 1.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_04_mouse_bite_02.jpg: 832x1024 3 mouse_bites, 27.9ms\n",
            "Speed: 6.2ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_01_spurious_copper_20.jpg: 544x1024 3 spurious_coppers, 20.6ms\n",
            "Speed: 4.5ms preprocess, 20.6ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_01_short_09.jpg: 544x1024 6 shorts, 19.9ms\n",
            "Speed: 4.7ms preprocess, 19.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_04_short_04.jpg: 832x1024 3 shorts, 29.0ms\n",
            "Speed: 6.5ms preprocess, 29.0ms inference, 1.9ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_06_spurious_copper_07.jpg: 832x1024 5 spurious_coppers, 27.9ms\n",
            "Speed: 6.6ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_06_mouse_bite_10.jpg: 832x1024 5 mouse_bites, 27.9ms\n",
            "Speed: 9.2ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_08_missing_hole_01.jpg: 800x1024 5 missing_holes, 27.9ms\n",
            "Speed: 6.0ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_09_missing_hole_04.jpg: 800x1024 6 missing_holes, 27.3ms\n",
            "Speed: 6.2ms preprocess, 27.3ms inference, 2.0ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_07_spurious_copper_01.jpg: 704x1024 5 spurious_coppers, 26.6ms\n",
            "Speed: 9.1ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_01_spurious_copper_12.jpg: 544x1024 2 spurious_coppers, 21.0ms\n",
            "Speed: 6.5ms preprocess, 21.0ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_06_missing_hole_08.jpg: 832x1024 5 missing_holes, 29.0ms\n",
            "Speed: 9.8ms preprocess, 29.0ms inference, 3.7ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_04_mouse_bite_13.jpg: 832x1024 3 mouse_bites, 28.0ms\n",
            "Speed: 7.7ms preprocess, 28.0ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_07_mouse_bite_02.jpg: 704x1024 5 mouse_bites, 26.5ms\n",
            "Speed: 8.2ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_01_spurious_copper_09.jpg: 544x1024 3 spurious_coppers, 20.6ms\n",
            "Speed: 4.5ms preprocess, 20.6ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_04_spur_14.jpg: 832x1024 3 spurs, 28.8ms\n",
            "Speed: 7.6ms preprocess, 28.8ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_01_short_01.jpg: 544x1024 1 short, 20.7ms\n",
            "Speed: 6.5ms preprocess, 20.7ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_12_mouse_bite_06.jpg: 1024x1024 6 mouse_bites, 33.5ms\n",
            "Speed: 7.8ms preprocess, 33.5ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_07_mouse_bite_04.jpg: 704x1024 5 mouse_bites, 26.2ms\n",
            "Speed: 6.9ms preprocess, 26.2ms inference, 1.3ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_04_spur_19.jpg: 832x1024 3 spurs, 28.6ms\n",
            "Speed: 6.4ms preprocess, 28.6ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_06_spurious_copper_02.jpg: 832x1024 5 spurious_coppers, 27.9ms\n",
            "Speed: 6.7ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_08_mouse_bite_05.jpg: 800x1024 6 mouse_bites, 28.0ms\n",
            "Speed: 8.4ms preprocess, 28.0ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_11_mouse_bite_01.jpg: 1024x1024 5 mouse_bites, 33.7ms\n",
            "Speed: 8.6ms preprocess, 33.7ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_08_open_circuit_01.jpg: 800x1024 5 open_circuits, 27.9ms\n",
            "Speed: 6.0ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_08_spurious_copper_03.jpg: 800x1024 1 mouse_bite, 5 spurious_coppers, 27.3ms\n",
            "Speed: 6.1ms preprocess, 27.3ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_11_missing_hole_09.jpg: 1024x1024 5 missing_holes, 33.9ms\n",
            "Speed: 12.3ms preprocess, 33.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_11_open_circuit_05.jpg: 1024x1024 5 open_circuits, 33.0ms\n",
            "Speed: 12.2ms preprocess, 33.0ms inference, 1.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_01_spur_10.jpg: 544x1024 1 mouse_bite, 1 spur, 21.3ms\n",
            "Speed: 7.5ms preprocess, 21.3ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_01_missing_hole_14.jpg: 544x1024 3 missing_holes, 19.9ms\n",
            "Speed: 4.2ms preprocess, 19.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_09_spur_05.jpg: 800x1024 5 spurs, 27.9ms\n",
            "Speed: 8.1ms preprocess, 27.9ms inference, 1.6ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_01_open_circuit_13.jpg: 544x1024 2 open_circuits, 20.7ms\n",
            "Speed: 4.3ms preprocess, 20.7ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_09_short_10.jpg: 800x1024 5 shorts, 27.9ms\n",
            "Speed: 6.2ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_06_spur_10.jpg: 832x1024 5 spurs, 28.7ms\n",
            "Speed: 7.7ms preprocess, 28.7ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_01_open_circuit_04.jpg: 544x1024 3 open_circuits, 20.7ms\n",
            "Speed: 4.3ms preprocess, 20.7ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_09_mouse_bite_10.jpg: 800x1024 5 mouse_bites, 28.1ms\n",
            "Speed: 5.9ms preprocess, 28.1ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_07_short_09.jpg: 704x1024 5 shorts, 26.2ms\n",
            "Speed: 6.3ms preprocess, 26.2ms inference, 1.3ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_10_short_02.jpg: 928x1024 4 shorts, 31.1ms\n",
            "Speed: 12.0ms preprocess, 31.1ms inference, 1.3ms postprocess per image at shape (1, 3, 928, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_01_open_circuit_17.jpg: 544x1024 2 open_circuits, 20.5ms\n",
            "Speed: 4.2ms preprocess, 20.5ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_05_spurious_copper_07.jpg: 896x1024 7 spurious_coppers, 29.5ms\n",
            "Speed: 7.5ms preprocess, 29.5ms inference, 1.3ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_06_spurious_copper_06.jpg: 832x1024 5 spurious_coppers, 28.6ms\n",
            "Speed: 9.7ms preprocess, 28.6ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_04_spurious_copper_16.jpg: 832x1024 2 spurious_coppers, 27.9ms\n",
            "Speed: 6.3ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_04_spurious_copper_11.jpg: 832x1024 2 spurious_coppers, 27.9ms\n",
            "Speed: 7.8ms preprocess, 27.9ms inference, 1.9ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_05_spurious_copper_10.jpg: 896x1024 7 spurious_coppers, 29.7ms\n",
            "Speed: 12.0ms preprocess, 29.7ms inference, 1.6ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_05_missing_hole_06.jpg: 896x1024 5 missing_holes, 28.8ms\n",
            "Speed: 12.5ms preprocess, 28.8ms inference, 1.6ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_07_open_circuit_09.jpg: 704x1024 5 open_circuits, 26.6ms\n",
            "Speed: 9.1ms preprocess, 26.6ms inference, 1.8ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_09_spur_08.jpg: 800x1024 5 spurs, 27.9ms\n",
            "Speed: 6.1ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "ğŸ¨ ë¹¨ê°„ìƒ‰ segmentation overlay ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save_overlay_dir = \"runs/predict/overlay\"\n",
        "# os.makedirs(save_overlay_dir, exist_ok=True)\n",
        "\n",
        "# test_images = glob(\"/content/dataset_yolo_seg/images/test/*.jpg\")\n",
        "\n",
        "# for img_path in test_images:\n",
        "#     original, rois, boxes = extract_rois(img_path)\n",
        "\n",
        "#     # U-Net masks\n",
        "#     masks = [unet_segment(roi) for roi in rois]\n",
        "\n",
        "#     # overlay ìƒì„±\n",
        "#     # overlay_img = overlay(original, boxes, masks)\n",
        "#     overlay_img = overlay_red(original, boxes, masks)\n",
        "\n",
        "#     out_name = f\"{Path(img_path).stem}_overlay.png\"\n",
        "#     cv2.imwrite(f\"{save_overlay_dir}/{out_name}\", overlay_img)\n",
        "\n",
        "# print(\"ğŸ¨ Overlay ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ!\")"
      ],
      "metadata": {
        "id": "SQODy90kEPoh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edb6a76e-f63b-4087-dcc0-1511ef2cd670"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_11_short_04.jpg: 1024x1024 5 shorts, 33.1ms\n",
            "Speed: 13.1ms preprocess, 33.1ms inference, 2.1ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_05_mouse_bite_02.jpg: 896x1024 5 mouse_bites, 15.5ms\n",
            "Speed: 9.3ms preprocess, 15.5ms inference, 1.4ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_05_missing_hole_01.jpg: 896x1024 3 missing_holes, 28.8ms\n",
            "Speed: 7.0ms preprocess, 28.8ms inference, 1.4ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_08_missing_hole_06.jpg: 800x1024 5 missing_holes, 28.0ms\n",
            "Speed: 7.9ms preprocess, 28.0ms inference, 1.2ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_08_open_circuit_03.jpg: 800x1024 1 mouse_bite, 4 open_circuits, 27.3ms\n",
            "Speed: 8.0ms preprocess, 27.3ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_01_open_circuit_20.jpg: 544x1024 3 open_circuits, 20.6ms\n",
            "Speed: 4.3ms preprocess, 20.6ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_08_short_01.jpg: 800x1024 5 shorts, 27.9ms\n",
            "Speed: 6.1ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_05_open_circuit_08.jpg: 896x1024 3 open_circuits, 29.4ms\n",
            "Speed: 8.8ms preprocess, 29.4ms inference, 1.2ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_04_open_circuit_05.jpg: 832x1024 3 open_circuits, 28.7ms\n",
            "Speed: 6.6ms preprocess, 28.7ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_10_mouse_bite_02.jpg: 928x1024 6 mouse_bites, 30.9ms\n",
            "Speed: 6.9ms preprocess, 30.9ms inference, 1.3ms postprocess per image at shape (1, 3, 928, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_12_short_02.jpg: 1024x1024 5 shorts, 33.7ms\n",
            "Speed: 8.3ms preprocess, 33.7ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_04_short_19.jpg: 832x1024 2 shorts, 28.7ms\n",
            "Speed: 9.2ms preprocess, 28.7ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_07_spurious_copper_07.jpg: 704x1024 5 spurious_coppers, 26.1ms\n",
            "Speed: 5.4ms preprocess, 26.1ms inference, 1.3ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_04_missing_hole_09.jpg: 832x1024 3 missing_holes, 28.9ms\n",
            "Speed: 10.1ms preprocess, 28.9ms inference, 1.6ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_10_mouse_bite_05.jpg: 928x1024 5 mouse_bites, 31.2ms\n",
            "Speed: 10.5ms preprocess, 31.2ms inference, 1.5ms postprocess per image at shape (1, 3, 928, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_05_open_circuit_03.jpg: 896x1024 3 open_circuits, 30.2ms\n",
            "Speed: 10.4ms preprocess, 30.2ms inference, 2.5ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_09_spurious_copper_02.jpg: 800x1024 5 spurious_coppers, 28.0ms\n",
            "Speed: 6.0ms preprocess, 28.0ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_05_mouse_bite_03.jpg: 896x1024 5 mouse_bites, 30.0ms\n",
            "Speed: 6.8ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_07_spur_01.jpg: 704x1024 5 spurs, 26.1ms\n",
            "Speed: 5.4ms preprocess, 26.1ms inference, 1.3ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_01_missing_hole_10.jpg: 544x1024 3 missing_holes, 20.6ms\n",
            "Speed: 5.3ms preprocess, 20.6ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_09_spur_07.jpg: 800x1024 5 spurs, 28.0ms\n",
            "Speed: 8.0ms preprocess, 28.0ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_08_spur_02.jpg: 800x1024 4 spurs, 27.2ms\n",
            "Speed: 6.2ms preprocess, 27.2ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_06_missing_hole_10.jpg: 832x1024 5 missing_holes, 29.4ms\n",
            "Speed: 10.1ms preprocess, 29.4ms inference, 2.2ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_06_open_circuit_02.jpg: 832x1024 5 open_circuits, 27.9ms\n",
            "Speed: 6.6ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_04_mouse_bite_02.jpg: 832x1024 3 mouse_bites, 27.9ms\n",
            "Speed: 6.6ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_01_spurious_copper_20.jpg: 544x1024 3 spurious_coppers, 20.6ms\n",
            "Speed: 4.8ms preprocess, 20.6ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_01_short_09.jpg: 544x1024 6 shorts, 19.9ms\n",
            "Speed: 4.6ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_04_short_04.jpg: 832x1024 3 shorts, 28.6ms\n",
            "Speed: 7.2ms preprocess, 28.6ms inference, 1.2ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_06_spurious_copper_07.jpg: 832x1024 5 spurious_coppers, 28.0ms\n",
            "Speed: 10.7ms preprocess, 28.0ms inference, 2.0ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_06_mouse_bite_10.jpg: 832x1024 5 mouse_bites, 27.9ms\n",
            "Speed: 9.9ms preprocess, 27.9ms inference, 1.6ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_08_missing_hole_01.jpg: 800x1024 5 missing_holes, 28.5ms\n",
            "Speed: 13.0ms preprocess, 28.5ms inference, 1.7ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_09_missing_hole_04.jpg: 800x1024 6 missing_holes, 27.2ms\n",
            "Speed: 6.0ms preprocess, 27.2ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_07_spurious_copper_01.jpg: 704x1024 5 spurious_coppers, 26.3ms\n",
            "Speed: 8.9ms preprocess, 26.3ms inference, 1.4ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_01_spurious_copper_12.jpg: 544x1024 2 spurious_coppers, 20.6ms\n",
            "Speed: 6.4ms preprocess, 20.6ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_06_missing_hole_08.jpg: 832x1024 5 missing_holes, 28.9ms\n",
            "Speed: 6.9ms preprocess, 28.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_04_mouse_bite_13.jpg: 832x1024 3 mouse_bites, 27.9ms\n",
            "Speed: 8.1ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_07_mouse_bite_02.jpg: 704x1024 5 mouse_bites, 26.1ms\n",
            "Speed: 5.4ms preprocess, 26.1ms inference, 1.3ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_01_spurious_copper_09.jpg: 544x1024 3 spurious_coppers, 20.7ms\n",
            "Speed: 4.4ms preprocess, 20.7ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_04_spur_14.jpg: 832x1024 3 spurs, 28.6ms\n",
            "Speed: 6.6ms preprocess, 28.6ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_01_short_01.jpg: 544x1024 1 short, 20.6ms\n",
            "Speed: 4.2ms preprocess, 20.6ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_12_mouse_bite_06.jpg: 1024x1024 6 mouse_bites, 33.6ms\n",
            "Speed: 8.9ms preprocess, 33.6ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_07_mouse_bite_04.jpg: 704x1024 5 mouse_bites, 26.1ms\n",
            "Speed: 6.4ms preprocess, 26.1ms inference, 1.2ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_04_spur_19.jpg: 832x1024 3 spurs, 28.6ms\n",
            "Speed: 7.0ms preprocess, 28.6ms inference, 1.2ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_06_spurious_copper_02.jpg: 832x1024 5 spurious_coppers, 27.9ms\n",
            "Speed: 6.5ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_08_mouse_bite_05.jpg: 800x1024 6 mouse_bites, 28.2ms\n",
            "Speed: 9.7ms preprocess, 28.2ms inference, 1.6ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_11_mouse_bite_01.jpg: 1024x1024 5 mouse_bites, 34.1ms\n",
            "Speed: 16.4ms preprocess, 34.1ms inference, 3.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_08_open_circuit_01.jpg: 800x1024 5 open_circuits, 28.5ms\n",
            "Speed: 9.6ms preprocess, 28.5ms inference, 1.9ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_08_spurious_copper_03.jpg: 800x1024 1 mouse_bite, 5 spurious_coppers, 27.2ms\n",
            "Speed: 6.1ms preprocess, 27.2ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_11_missing_hole_09.jpg: 1024x1024 5 missing_holes, 34.1ms\n",
            "Speed: 10.4ms preprocess, 34.1ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_11_open_circuit_05.jpg: 1024x1024 5 open_circuits, 32.9ms\n",
            "Speed: 7.5ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_01_spur_10.jpg: 544x1024 1 mouse_bite, 1 spur, 20.6ms\n",
            "Speed: 4.2ms preprocess, 20.6ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_01_missing_hole_14.jpg: 544x1024 3 missing_holes, 19.9ms\n",
            "Speed: 4.1ms preprocess, 19.9ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_09_spur_05.jpg: 800x1024 5 spurs, 27.9ms\n",
            "Speed: 6.0ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_01_open_circuit_13.jpg: 544x1024 2 open_circuits, 20.7ms\n",
            "Speed: 4.1ms preprocess, 20.7ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_09_short_10.jpg: 800x1024 5 shorts, 27.9ms\n",
            "Speed: 6.1ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_06_spur_10.jpg: 832x1024 5 spurs, 28.7ms\n",
            "Speed: 7.1ms preprocess, 28.7ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_01_open_circuit_04.jpg: 544x1024 3 open_circuits, 20.6ms\n",
            "Speed: 5.1ms preprocess, 20.6ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_09_mouse_bite_10.jpg: 800x1024 5 mouse_bites, 28.0ms\n",
            "Speed: 6.4ms preprocess, 28.0ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_07_short_09.jpg: 704x1024 5 shorts, 26.7ms\n",
            "Speed: 8.3ms preprocess, 26.7ms inference, 2.1ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_10_short_02.jpg: 928x1024 4 shorts, 31.0ms\n",
            "Speed: 10.9ms preprocess, 31.0ms inference, 1.4ms postprocess per image at shape (1, 3, 928, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_01_open_circuit_17.jpg: 544x1024 2 open_circuits, 21.3ms\n",
            "Speed: 6.8ms preprocess, 21.3ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_05_spurious_copper_07.jpg: 896x1024 7 spurious_coppers, 29.9ms\n",
            "Speed: 10.6ms preprocess, 29.9ms inference, 2.9ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_06_spurious_copper_06.jpg: 832x1024 5 spurious_coppers, 29.3ms\n",
            "Speed: 14.3ms preprocess, 29.3ms inference, 1.9ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_04_spurious_copper_16.jpg: 832x1024 2 spurious_coppers, 27.9ms\n",
            "Speed: 6.6ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_04_spurious_copper_11.jpg: 832x1024 2 spurious_coppers, 27.9ms\n",
            "Speed: 8.3ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_05_spurious_copper_10.jpg: 896x1024 7 spurious_coppers, 29.5ms\n",
            "Speed: 7.0ms preprocess, 29.5ms inference, 1.3ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_05_missing_hole_06.jpg: 896x1024 5 missing_holes, 28.8ms\n",
            "Speed: 6.4ms preprocess, 28.8ms inference, 2.0ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_07_open_circuit_09.jpg: 704x1024 5 open_circuits, 26.0ms\n",
            "Speed: 5.6ms preprocess, 26.0ms inference, 1.2ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_09_spur_08.jpg: 800x1024 5 spurs, 27.9ms\n",
            "Speed: 5.8ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "ğŸ¨ Overlay ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8-3. YOLO â†’ U-Netê¹Œì§€ í•œ ë²ˆì— ëŒë¦¬ëŠ” íŒŒì´í”„ë¼ì¸\n",
        "\n",
        "ì…ë ¥: ì›ë³¸ PCB ì´ë¯¸ì§€ ê²½ë¡œ\n",
        "\n",
        "ì¶œë ¥: YOLOê°€ ì°¾ì€ ì˜ì—­ì— ëŒ€í•´ U-Net ë§ˆìŠ¤í¬ë¥¼ ì˜¬ë ¤ì„œ ìƒ‰ì¹ í•œ ìµœì¢… ê²°ê³¼ ì´ë¯¸ì§€"
      ],
      "metadata": {
        "id": "fOtxmNeUEQJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def full_pipeline(image_path):\n",
        "    original, rois, boxes = extract_rois(image_path)\n",
        "    masks = [unet_segment(roi) for roi in rois]\n",
        "    result = overlay(original, boxes, masks)\n",
        "    return result"
      ],
      "metadata": {
        "id": "tSK2k7UvMpTl"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img_path = \"/content/dataset_yolo_seg/images/test/open_circuit_01_open_circuit_04.jpg\"\n",
        "\n",
        "original, rois, boxes = extract_rois(img_path, conf=0.05)\n",
        "\n",
        "plt.imshow(cv2.cvtColor(rois[0], cv2.COLOR_BGR2RGB))\n",
        "plt.title(\"ROI\")\n",
        "plt.show()\n",
        "\n",
        "mask = unet_segment(rois[0])\n",
        "plt.imshow(mask, cmap='gray')\n",
        "plt.title(\"U-Net Prediction Mask\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "D1lc_LN2Mpzf",
        "outputId": "575a68d5-316a-4ad4-f8f0-41934e14d126"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_01_open_circuit_04.jpg: 544x1024 3 open_circuits, 21.1ms\n",
            "Speed: 13.5ms preprocess, 21.1ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y2CGThRoEaP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. IoU / Dice ê³„ì‚° & í…ŒìŠ¤íŠ¸ì…‹ ì „ì²´ í‰ê°€\n",
        "\n",
        "mask_true = create_auto_mask()ë¡œ ë§Œë“  ìë™ ë§ˆìŠ¤í¬ (pseudo GT)\n",
        "\n",
        "mask_pred = U-Net ì˜ˆì¸¡ ë§ˆìŠ¤í¬\n",
        "\n",
        "ë‘˜ ê°„ì˜ êµì§‘í•©/í•©ì§‘í•©ìœ¼ë¡œ IoU, Dice ê³„ì‚°"
      ],
      "metadata": {
        "id": "zBRQh8J0EbIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_iou(mask_true, mask_pred):\n",
        "    # binary masks (0 or 255)\n",
        "    mask_true = (mask_true > 127).astype(np.uint8)\n",
        "    mask_pred = (mask_pred > 127).astype(np.uint8)\n",
        "\n",
        "    intersection = np.logical_and(mask_true, mask_pred).sum()\n",
        "    union = np.logical_or(mask_true, mask_pred).sum()\n",
        "\n",
        "    if union == 0:\n",
        "        return 1.0 if intersection == 0 else 0.0\n",
        "    return intersection / union\n",
        "\n",
        "\n",
        "def compute_dice(mask_true, mask_pred):\n",
        "    mask_true = (mask_true > 127).astype(np.uint8)\n",
        "    mask_pred = (mask_pred > 127).astype(np.uint8)\n",
        "\n",
        "    intersection = np.logical_and(mask_true, mask_pred).sum()\n",
        "    total = mask_true.sum() + mask_pred.sum()\n",
        "\n",
        "    if total == 0:\n",
        "        return 1.0 if intersection == 0 else 0.0\n",
        "    return 2 * intersection / total\n"
      ],
      "metadata": {
        "id": "55ZYrOgCOARi"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L7Xxg0JcEhWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10-2. ROIë³„ ì¶œë ¥ & í´ë” ë‹¨ìœ„ í‰ê·  í‰ê°€\n",
        "\n",
        "íŠ¹ì • ì´ë¯¸ì§€ ì•ˆì— ìˆëŠ” ê° ROIë³„ë¡œ IoU/Dice ì¶œë ¥\n",
        "\n",
        "IoU 0.88 ~ 0.96, Dice 0.93 ~ 0.98 ìˆ˜ì¤€ì˜ ë§¤ìš° ë†’ì€ ê°’ì´ ë‚˜ì˜¤ëŠ” ê±¸ í™•ì¸í•  ìˆ˜ ìˆìŒ"
      ],
      "metadata": {
        "id": "qCOCUrIhEhtb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = \"/content/dataset_yolo_seg/images/test/open_circuit_01_open_circuit_04.jpg\"\n",
        "\n",
        "original, rois, boxes = extract_rois(img_path, conf=0.05)\n",
        "\n",
        "for i, roi in enumerate(rois):\n",
        "    true_mask = create_auto_mask(roi)\n",
        "    pred_mask = unet_segment(roi)\n",
        "\n",
        "    iou = compute_iou(true_mask, pred_mask)\n",
        "    dice = compute_dice(true_mask, pred_mask)\n",
        "\n",
        "    print(f\"[ROI {i}] IoU: {iou:.4f}, Dice: {dice:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiMbI9nlONbo",
        "outputId": "ec1b96ff-dd0c-4436-f08b-5d94a08ef5f3"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_01_open_circuit_04.jpg: 544x1024 3 open_circuits, 19.9ms\n",
            "Speed: 4.2ms preprocess, 19.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "[ROI 0] IoU: 0.9861, Dice: 0.9930\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "[ROI 1] IoU: 0.9691, Dice: 0.9843\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "[ROI 2] IoU: 0.9947, Dice: 0.9973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "608iSEChEsim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "í…ŒìŠ¤íŠ¸ì…‹ í´ë” ì „ì²´ ì´ë¯¸ì§€ì— ëŒ€í•´ ROIë¥¼ ëª¨ë‘ ëŒë©´ì„œ í‰ê·  IoU, Dice ê³„ì‚°\n",
        "\n",
        "ìµœì¢…ì ìœ¼ë¡œ â€œU-Netì´ PCB ë¶ˆëŸ‰ ì˜ì—­ì„ ì–¼ë§ˆë‚˜ ì˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ í–ˆëŠ”ì§€â€ë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ ë³´ì—¬ì£¼ëŠ” ë¶€ë¶„"
      ],
      "metadata": {
        "id": "zfgzZ7vLEs6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "\n",
        "def evaluate_unet_on_folder(folder):\n",
        "    img_paths = sorted(glob(f\"{folder}/*.jpg\"))\n",
        "    total_iou = 0\n",
        "    total_dice = 0\n",
        "    count = 0\n",
        "\n",
        "    for img_path in img_paths:\n",
        "        original, rois, boxes = extract_rois(img_path, conf=0.05)\n",
        "\n",
        "        for roi in rois:\n",
        "            true_mask = create_auto_mask(roi)\n",
        "            pred_mask = unet_segment(roi)\n",
        "\n",
        "            iou = compute_iou(true_mask, pred_mask)\n",
        "            dice = compute_dice(true_mask, pred_mask)\n",
        "\n",
        "            total_iou += iou\n",
        "            total_dice += dice\n",
        "            count += 1\n",
        "\n",
        "    avg_iou = total_iou / count if count > 0 else 0\n",
        "    avg_dice = total_dice / count if count > 0 else 0\n",
        "\n",
        "    print(f\"\\nğŸ“Š U-Net ì„±ëŠ¥ í‰ê°€ ê²°ê³¼ ({count}ê°œì˜ ROI)\")\n",
        "    print(f\"   í‰ê·  IoU  : {avg_iou:.4f}\")\n",
        "    print(f\"   í‰ê·  Dice : {avg_dice:.4f}\")\n",
        "\n",
        "    return avg_iou, avg_dice\n"
      ],
      "metadata": {
        "id": "irAQsGr2OTd2"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_unet_on_folder(\"/content/dataset_yolo_seg/images/test\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9DMG4WzOWnw",
        "outputId": "85dfcdbe-5ae8-44c7-e503-2a04913a65d6"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_01_missing_hole_10.jpg: 544x1024 3 missing_holes, 29.4ms\n",
            "Speed: 6.6ms preprocess, 29.4ms inference, 2.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_01_missing_hole_14.jpg: 544x1024 3 missing_holes, 20.0ms\n",
            "Speed: 6.3ms preprocess, 20.0ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_04_missing_hole_09.jpg: 832x1024 3 missing_holes, 30.5ms\n",
            "Speed: 15.5ms preprocess, 30.5ms inference, 1.8ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_05_missing_hole_01.jpg: 896x1024 3 missing_holes, 29.6ms\n",
            "Speed: 7.6ms preprocess, 29.6ms inference, 1.3ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_05_missing_hole_06.jpg: 896x1024 5 missing_holes, 28.7ms\n",
            "Speed: 6.7ms preprocess, 28.7ms inference, 1.4ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_06_missing_hole_08.jpg: 832x1024 5 missing_holes, 28.8ms\n",
            "Speed: 6.1ms preprocess, 28.8ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_06_missing_hole_10.jpg: 832x1024 5 missing_holes, 27.9ms\n",
            "Speed: 6.1ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_08_missing_hole_01.jpg: 800x1024 5 missing_holes, 28.0ms\n",
            "Speed: 6.2ms preprocess, 28.0ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_08_missing_hole_06.jpg: 800x1024 5 missing_holes, 27.3ms\n",
            "Speed: 6.7ms preprocess, 27.3ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_09_missing_hole_04.jpg: 800x1024 6 missing_holes, 27.2ms\n",
            "Speed: 8.4ms preprocess, 27.2ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_11_missing_hole_09.jpg: 1024x1024 5 missing_holes, 33.7ms\n",
            "Speed: 10.2ms preprocess, 33.7ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_04_mouse_bite_02.jpg: 832x1024 3 mouse_bites, 28.6ms\n",
            "Speed: 6.9ms preprocess, 28.6ms inference, 1.6ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_04_mouse_bite_13.jpg: 832x1024 3 mouse_bites, 27.9ms\n",
            "Speed: 6.7ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_05_mouse_bite_02.jpg: 896x1024 5 mouse_bites, 30.0ms\n",
            "Speed: 17.4ms preprocess, 30.0ms inference, 1.6ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_05_mouse_bite_03.jpg: 896x1024 5 mouse_bites, 28.8ms\n",
            "Speed: 10.7ms preprocess, 28.8ms inference, 1.7ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_06_mouse_bite_10.jpg: 832x1024 5 mouse_bites, 29.0ms\n",
            "Speed: 10.1ms preprocess, 29.0ms inference, 1.7ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_07_mouse_bite_02.jpg: 704x1024 5 mouse_bites, 26.8ms\n",
            "Speed: 9.1ms preprocess, 26.8ms inference, 1.8ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_07_mouse_bite_04.jpg: 704x1024 5 mouse_bites, 25.4ms\n",
            "Speed: 9.2ms preprocess, 25.4ms inference, 2.3ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_08_mouse_bite_05.jpg: 800x1024 6 mouse_bites, 28.0ms\n",
            "Speed: 5.8ms preprocess, 28.0ms inference, 1.2ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_09_mouse_bite_10.jpg: 800x1024 5 mouse_bites, 27.3ms\n",
            "Speed: 5.8ms preprocess, 27.3ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_10_mouse_bite_02.jpg: 928x1024 6 mouse_bites, 31.1ms\n",
            "Speed: 9.7ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 928, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_10_mouse_bite_05.jpg: 928x1024 5 mouse_bites, 30.3ms\n",
            "Speed: 6.8ms preprocess, 30.3ms inference, 1.3ms postprocess per image at shape (1, 3, 928, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_11_mouse_bite_01.jpg: 1024x1024 5 mouse_bites, 33.7ms\n",
            "Speed: 10.5ms preprocess, 33.7ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_12_mouse_bite_06.jpg: 1024x1024 6 mouse_bites, 32.9ms\n",
            "Speed: 7.8ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_01_open_circuit_04.jpg: 544x1024 3 open_circuits, 20.7ms\n",
            "Speed: 4.1ms preprocess, 20.7ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_01_open_circuit_13.jpg: 544x1024 2 open_circuits, 19.9ms\n",
            "Speed: 4.2ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_01_open_circuit_17.jpg: 544x1024 2 open_circuits, 19.9ms\n",
            "Speed: 4.1ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_01_open_circuit_20.jpg: 544x1024 3 open_circuits, 19.9ms\n",
            "Speed: 4.2ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_04_open_circuit_05.jpg: 832x1024 3 open_circuits, 28.7ms\n",
            "Speed: 6.8ms preprocess, 28.7ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_05_open_circuit_03.jpg: 896x1024 3 open_circuits, 29.5ms\n",
            "Speed: 7.4ms preprocess, 29.5ms inference, 1.3ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_05_open_circuit_08.jpg: 896x1024 3 open_circuits, 28.7ms\n",
            "Speed: 6.6ms preprocess, 28.7ms inference, 1.3ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_06_open_circuit_02.jpg: 832x1024 5 open_circuits, 28.7ms\n",
            "Speed: 9.2ms preprocess, 28.7ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_07_open_circuit_09.jpg: 704x1024 5 open_circuits, 26.3ms\n",
            "Speed: 6.0ms preprocess, 26.3ms inference, 1.3ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_08_open_circuit_01.jpg: 800x1024 5 open_circuits, 28.1ms\n",
            "Speed: 6.1ms preprocess, 28.1ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_08_open_circuit_03.jpg: 800x1024 1 mouse_bite, 4 open_circuits, 27.3ms\n",
            "Speed: 8.0ms preprocess, 27.3ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_11_open_circuit_05.jpg: 1024x1024 5 open_circuits, 33.9ms\n",
            "Speed: 7.4ms preprocess, 33.9ms inference, 1.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_01_short_01.jpg: 544x1024 1 short, 20.7ms\n",
            "Speed: 4.2ms preprocess, 20.7ms inference, 4.1ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_01_short_09.jpg: 544x1024 6 shorts, 19.9ms\n",
            "Speed: 4.9ms preprocess, 19.9ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_04_short_04.jpg: 832x1024 3 shorts, 28.6ms\n",
            "Speed: 7.4ms preprocess, 28.6ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_04_short_19.jpg: 832x1024 2 shorts, 27.9ms\n",
            "Speed: 7.9ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_07_short_09.jpg: 704x1024 5 shorts, 26.2ms\n",
            "Speed: 8.2ms preprocess, 26.2ms inference, 1.3ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_08_short_01.jpg: 800x1024 5 shorts, 28.6ms\n",
            "Speed: 9.9ms preprocess, 28.6ms inference, 1.8ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_09_short_10.jpg: 800x1024 5 shorts, 27.2ms\n",
            "Speed: 9.5ms preprocess, 27.2ms inference, 1.6ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_10_short_02.jpg: 928x1024 4 shorts, 31.2ms\n",
            "Speed: 12.1ms preprocess, 31.2ms inference, 1.6ms postprocess per image at shape (1, 3, 928, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_11_short_04.jpg: 1024x1024 5 shorts, 34.7ms\n",
            "Speed: 17.2ms preprocess, 34.7ms inference, 1.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_12_short_02.jpg: 1024x1024 5 shorts, 33.2ms\n",
            "Speed: 15.1ms preprocess, 33.2ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_01_spur_10.jpg: 544x1024 1 mouse_bite, 1 spur, 20.7ms\n",
            "Speed: 4.4ms preprocess, 20.7ms inference, 3.7ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_04_spur_14.jpg: 832x1024 3 spurs, 28.6ms\n",
            "Speed: 7.0ms preprocess, 28.6ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_04_spur_19.jpg: 832x1024 3 spurs, 27.9ms\n",
            "Speed: 6.3ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_06_spur_10.jpg: 832x1024 5 spurs, 27.9ms\n",
            "Speed: 6.2ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_07_spur_01.jpg: 704x1024 5 spurs, 26.3ms\n",
            "Speed: 5.2ms preprocess, 26.3ms inference, 1.7ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_08_spur_02.jpg: 800x1024 4 spurs, 28.1ms\n",
            "Speed: 6.0ms preprocess, 28.1ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_09_spur_05.jpg: 800x1024 5 spurs, 27.2ms\n",
            "Speed: 6.4ms preprocess, 27.2ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_09_spur_07.jpg: 800x1024 5 spurs, 27.2ms\n",
            "Speed: 9.3ms preprocess, 27.2ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_09_spur_08.jpg: 800x1024 5 spurs, 27.3ms\n",
            "Speed: 6.3ms preprocess, 27.3ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_01_spurious_copper_09.jpg: 544x1024 3 spurious_coppers, 20.6ms\n",
            "Speed: 4.2ms preprocess, 20.6ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_01_spurious_copper_12.jpg: 544x1024 2 spurious_coppers, 19.9ms\n",
            "Speed: 4.7ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_01_spurious_copper_20.jpg: 544x1024 3 spurious_coppers, 19.9ms\n",
            "Speed: 4.3ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_04_spurious_copper_11.jpg: 832x1024 2 spurious_coppers, 28.9ms\n",
            "Speed: 9.1ms preprocess, 28.9ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_04_spurious_copper_16.jpg: 832x1024 2 spurious_coppers, 27.9ms\n",
            "Speed: 6.5ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_05_spurious_copper_07.jpg: 896x1024 7 spurious_coppers, 29.4ms\n",
            "Speed: 7.0ms preprocess, 29.4ms inference, 1.3ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_05_spurious_copper_10.jpg: 896x1024 7 spurious_coppers, 28.9ms\n",
            "Speed: 15.0ms preprocess, 28.9ms inference, 1.4ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_06_spurious_copper_02.jpg: 832x1024 5 spurious_coppers, 28.7ms\n",
            "Speed: 6.3ms preprocess, 28.7ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_06_spurious_copper_06.jpg: 832x1024 5 spurious_coppers, 27.9ms\n",
            "Speed: 6.7ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_06_spurious_copper_07.jpg: 832x1024 5 spurious_coppers, 27.9ms\n",
            "Speed: 6.7ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_07_spurious_copper_01.jpg: 704x1024 5 spurious_coppers, 26.3ms\n",
            "Speed: 5.3ms preprocess, 26.3ms inference, 1.3ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_07_spurious_copper_07.jpg: 704x1024 5 spurious_coppers, 25.4ms\n",
            "Speed: 5.7ms preprocess, 25.4ms inference, 1.5ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_08_spurious_copper_03.jpg: 800x1024 1 mouse_bite, 5 spurious_coppers, 28.0ms\n",
            "Speed: 7.1ms preprocess, 28.0ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_09_spurious_copper_02.jpg: 800x1024 5 spurious_coppers, 27.3ms\n",
            "Speed: 12.2ms preprocess, 27.3ms inference, 1.7ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "\n",
            "ğŸ“Š U-Net ì„±ëŠ¥ í‰ê°€ ê²°ê³¼ (296ê°œì˜ ROI)\n",
            "   í‰ê·  IoU  : 0.9113\n",
            "   í‰ê·  Dice : 0.9477\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(0.9113103751255164), np.float64(0.9477174355486394))"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for img_path in test_images:\n",
        "    results = detector(img_path)[0]\n",
        "    print(img_path, \"â†’ Detected:\", len(results.boxes))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lU0K7CaKJpMl",
        "outputId": "c0115950-734f-4a1b-daf3-9304a8f719fd"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_11_short_04.jpg: 1024x1024 5 shorts, 44.0ms\n",
            "Speed: 61.7ms preprocess, 44.0ms inference, 6.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/short_11_short_04.jpg â†’ Detected: 5\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_05_mouse_bite_02.jpg: 896x1024 5 mouse_bites, 31.5ms\n",
            "Speed: 26.3ms preprocess, 31.5ms inference, 5.8ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/mouse_bite_05_mouse_bite_02.jpg â†’ Detected: 5\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_05_missing_hole_01.jpg: 896x1024 3 missing_holes, 30.6ms\n",
            "Speed: 21.6ms preprocess, 30.6ms inference, 5.4ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/missing_hole_05_missing_hole_01.jpg â†’ Detected: 3\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_08_missing_hole_06.jpg: 800x1024 5 missing_holes, 30.9ms\n",
            "Speed: 19.2ms preprocess, 30.9ms inference, 4.2ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/missing_hole_08_missing_hole_06.jpg â†’ Detected: 5\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_08_open_circuit_03.jpg: 800x1024 1 mouse_bite, 4 open_circuits, 29.6ms\n",
            "Speed: 22.0ms preprocess, 29.6ms inference, 3.5ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/open_circuit_08_open_circuit_03.jpg â†’ Detected: 5\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_01_open_circuit_20.jpg: 544x1024 3 open_circuits, 23.2ms\n",
            "Speed: 13.9ms preprocess, 23.2ms inference, 6.2ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/open_circuit_01_open_circuit_20.jpg â†’ Detected: 3\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_08_short_01.jpg: 800x1024 5 shorts, 29.9ms\n",
            "Speed: 19.2ms preprocess, 29.9ms inference, 2.7ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/short_08_short_01.jpg â†’ Detected: 5\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_05_open_circuit_08.jpg: 896x1024 3 open_circuits, 30.8ms\n",
            "Speed: 15.2ms preprocess, 30.8ms inference, 4.3ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/open_circuit_05_open_circuit_08.jpg â†’ Detected: 3\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_04_open_circuit_05.jpg: 832x1024 3 open_circuits, 40.9ms\n",
            "Speed: 31.2ms preprocess, 40.9ms inference, 6.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/open_circuit_04_open_circuit_05.jpg â†’ Detected: 3\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_10_mouse_bite_02.jpg: 928x1024 6 mouse_bites, 33.0ms\n",
            "Speed: 71.7ms preprocess, 33.0ms inference, 1.7ms postprocess per image at shape (1, 3, 928, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/mouse_bite_10_mouse_bite_02.jpg â†’ Detected: 6\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_12_short_02.jpg: 1024x1024 5 shorts, 34.0ms\n",
            "Speed: 12.4ms preprocess, 34.0ms inference, 1.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/short_12_short_02.jpg â†’ Detected: 5\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_04_short_19.jpg: 832x1024 2 shorts, 28.7ms\n",
            "Speed: 6.5ms preprocess, 28.7ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/short_04_short_19.jpg â†’ Detected: 2\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_07_spurious_copper_07.jpg: 704x1024 5 spurious_coppers, 26.1ms\n",
            "Speed: 5.0ms preprocess, 26.1ms inference, 1.3ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/spurious_copper_07_spurious_copper_07.jpg â†’ Detected: 5\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_04_missing_hole_09.jpg: 832x1024 3 missing_holes, 28.6ms\n",
            "Speed: 6.2ms preprocess, 28.6ms inference, 1.2ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/missing_hole_04_missing_hole_09.jpg â†’ Detected: 3\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_10_mouse_bite_05.jpg: 928x1024 5 mouse_bites, 31.0ms\n",
            "Speed: 8.2ms preprocess, 31.0ms inference, 1.4ms postprocess per image at shape (1, 3, 928, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/mouse_bite_10_mouse_bite_05.jpg â†’ Detected: 5\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_05_open_circuit_03.jpg: 896x1024 3 open_circuits, 29.9ms\n",
            "Speed: 6.9ms preprocess, 29.9ms inference, 1.9ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/open_circuit_05_open_circuit_03.jpg â†’ Detected: 3\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_09_spurious_copper_02.jpg: 800x1024 5 spurious_coppers, 26.5ms\n",
            "Speed: 7.1ms preprocess, 26.5ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/spurious_copper_09_spurious_copper_02.jpg â†’ Detected: 5\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_05_mouse_bite_03.jpg: 896x1024 5 mouse_bites, 27.8ms\n",
            "Speed: 6.6ms preprocess, 27.8ms inference, 1.2ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/mouse_bite_05_mouse_bite_03.jpg â†’ Detected: 5\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_07_spur_01.jpg: 704x1024 5 spurs, 24.5ms\n",
            "Speed: 5.1ms preprocess, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/spur_07_spur_01.jpg â†’ Detected: 5\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_01_missing_hole_10.jpg: 544x1024 3 missing_holes, 19.6ms\n",
            "Speed: 4.4ms preprocess, 19.6ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/missing_hole_01_missing_hole_10.jpg â†’ Detected: 3\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_09_spur_07.jpg: 800x1024 5 spurs, 26.4ms\n",
            "Speed: 6.1ms preprocess, 26.4ms inference, 1.6ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/spur_09_spur_07.jpg â†’ Detected: 5\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_08_spur_02.jpg: 800x1024 4 spurs, 25.6ms\n",
            "Speed: 6.1ms preprocess, 25.6ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/spur_08_spur_02.jpg â†’ Detected: 4\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_06_missing_hole_10.jpg: 832x1024 5 missing_holes, 27.0ms\n",
            "Speed: 6.4ms preprocess, 27.0ms inference, 1.2ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/missing_hole_06_missing_hole_10.jpg â†’ Detected: 5\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_06_open_circuit_02.jpg: 832x1024 5 open_circuits, 26.2ms\n",
            "Speed: 6.0ms preprocess, 26.2ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/open_circuit_06_open_circuit_02.jpg â†’ Detected: 5\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_04_mouse_bite_02.jpg: 832x1024 3 mouse_bites, 26.3ms\n",
            "Speed: 8.6ms preprocess, 26.3ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/mouse_bite_04_mouse_bite_02.jpg â†’ Detected: 3\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_01_spurious_copper_20.jpg: 544x1024 3 spurious_coppers, 19.4ms\n",
            "Speed: 4.4ms preprocess, 19.4ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/spurious_copper_01_spurious_copper_20.jpg â†’ Detected: 3\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_01_short_09.jpg: 544x1024 6 shorts, 18.7ms\n",
            "Speed: 4.2ms preprocess, 18.7ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/short_01_short_09.jpg â†’ Detected: 6\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_04_short_04.jpg: 832x1024 3 shorts, 27.0ms\n",
            "Speed: 6.5ms preprocess, 27.0ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/short_04_short_04.jpg â†’ Detected: 3\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_06_spurious_copper_07.jpg: 832x1024 5 spurious_coppers, 26.2ms\n",
            "Speed: 6.5ms preprocess, 26.2ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/spurious_copper_06_spurious_copper_07.jpg â†’ Detected: 5\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_06_mouse_bite_10.jpg: 832x1024 5 mouse_bites, 26.2ms\n",
            "Speed: 6.6ms preprocess, 26.2ms inference, 2.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/mouse_bite_06_mouse_bite_10.jpg â†’ Detected: 5\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_08_missing_hole_01.jpg: 800x1024 5 missing_holes, 26.3ms\n",
            "Speed: 5.8ms preprocess, 26.3ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/missing_hole_08_missing_hole_01.jpg â†’ Detected: 5\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_09_missing_hole_04.jpg: 800x1024 6 missing_holes, 25.6ms\n",
            "Speed: 6.3ms preprocess, 25.6ms inference, 2.2ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/missing_hole_09_missing_hole_04.jpg â†’ Detected: 6\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_07_spurious_copper_01.jpg: 704x1024 5 spurious_coppers, 24.5ms\n",
            "Speed: 5.3ms preprocess, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/spurious_copper_07_spurious_copper_01.jpg â†’ Detected: 5\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_01_spurious_copper_12.jpg: 544x1024 2 spurious_coppers, 19.8ms\n",
            "Speed: 4.3ms preprocess, 19.8ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/spurious_copper_01_spurious_copper_12.jpg â†’ Detected: 2\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_06_missing_hole_08.jpg: 832x1024 5 missing_holes, 26.9ms\n",
            "Speed: 6.2ms preprocess, 26.9ms inference, 1.2ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/missing_hole_06_missing_hole_08.jpg â†’ Detected: 5\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_04_mouse_bite_13.jpg: 832x1024 3 mouse_bites, 27.9ms\n",
            "Speed: 6.9ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/mouse_bite_04_mouse_bite_13.jpg â†’ Detected: 3\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_07_mouse_bite_02.jpg: 704x1024 5 mouse_bites, 26.0ms\n",
            "Speed: 5.2ms preprocess, 26.0ms inference, 1.2ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/mouse_bite_07_mouse_bite_02.jpg â†’ Detected: 5\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_01_spurious_copper_09.jpg: 544x1024 3 spurious_coppers, 20.5ms\n",
            "Speed: 4.2ms preprocess, 20.5ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/spurious_copper_01_spurious_copper_09.jpg â†’ Detected: 3\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_04_spur_14.jpg: 832x1024 3 spurs, 28.7ms\n",
            "Speed: 7.2ms preprocess, 28.7ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/spur_04_spur_14.jpg â†’ Detected: 3\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_01_short_01.jpg: 544x1024 1 short, 20.6ms\n",
            "Speed: 4.1ms preprocess, 20.6ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/short_01_short_01.jpg â†’ Detected: 1\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_12_mouse_bite_06.jpg: 1024x1024 6 mouse_bites, 33.5ms\n",
            "Speed: 8.3ms preprocess, 33.5ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/mouse_bite_12_mouse_bite_06.jpg â†’ Detected: 6\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_07_mouse_bite_04.jpg: 704x1024 5 mouse_bites, 26.0ms\n",
            "Speed: 5.4ms preprocess, 26.0ms inference, 1.3ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/mouse_bite_07_mouse_bite_04.jpg â†’ Detected: 5\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_04_spur_19.jpg: 832x1024 3 spurs, 28.4ms\n",
            "Speed: 6.2ms preprocess, 28.4ms inference, 1.2ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/spur_04_spur_19.jpg â†’ Detected: 3\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_06_spurious_copper_02.jpg: 832x1024 5 spurious_coppers, 27.8ms\n",
            "Speed: 6.3ms preprocess, 27.8ms inference, 1.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/spurious_copper_06_spurious_copper_02.jpg â†’ Detected: 5\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_08_mouse_bite_05.jpg: 800x1024 6 mouse_bites, 27.9ms\n",
            "Speed: 5.9ms preprocess, 27.9ms inference, 1.2ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/mouse_bite_08_mouse_bite_05.jpg â†’ Detected: 6\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_11_mouse_bite_01.jpg: 1024x1024 5 mouse_bites, 33.8ms\n",
            "Speed: 7.6ms preprocess, 33.8ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/mouse_bite_11_mouse_bite_01.jpg â†’ Detected: 5\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_08_open_circuit_01.jpg: 800x1024 5 open_circuits, 28.2ms\n",
            "Speed: 6.4ms preprocess, 28.2ms inference, 1.6ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/open_circuit_08_open_circuit_01.jpg â†’ Detected: 5\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_08_spurious_copper_03.jpg: 800x1024 1 mouse_bite, 5 spurious_coppers, 25.6ms\n",
            "Speed: 6.2ms preprocess, 25.6ms inference, 1.4ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/spurious_copper_08_spurious_copper_03.jpg â†’ Detected: 6\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_11_missing_hole_09.jpg: 1024x1024 5 missing_holes, 31.7ms\n",
            "Speed: 7.9ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/missing_hole_11_missing_hole_09.jpg â†’ Detected: 5\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_11_open_circuit_05.jpg: 1024x1024 5 open_circuits, 31.1ms\n",
            "Speed: 7.7ms preprocess, 31.1ms inference, 1.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/open_circuit_11_open_circuit_05.jpg â†’ Detected: 5\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_01_spur_10.jpg: 544x1024 1 mouse_bite, 1 spur, 19.4ms\n",
            "Speed: 4.3ms preprocess, 19.4ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/spur_01_spur_10.jpg â†’ Detected: 2\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_01_missing_hole_14.jpg: 544x1024 3 missing_holes, 18.7ms\n",
            "Speed: 4.2ms preprocess, 18.7ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/missing_hole_01_missing_hole_14.jpg â†’ Detected: 3\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_09_spur_05.jpg: 800x1024 5 spurs, 26.5ms\n",
            "Speed: 6.5ms preprocess, 26.5ms inference, 1.2ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/spur_09_spur_05.jpg â†’ Detected: 5\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_01_open_circuit_13.jpg: 544x1024 2 open_circuits, 19.4ms\n",
            "Speed: 4.0ms preprocess, 19.4ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/open_circuit_01_open_circuit_13.jpg â†’ Detected: 2\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_09_short_10.jpg: 800x1024 5 shorts, 26.7ms\n",
            "Speed: 5.9ms preprocess, 26.7ms inference, 1.2ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/short_09_short_10.jpg â†’ Detected: 5\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_06_spur_10.jpg: 832x1024 5 spurs, 26.8ms\n",
            "Speed: 6.1ms preprocess, 26.8ms inference, 1.2ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/spur_06_spur_10.jpg â†’ Detected: 5\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_01_open_circuit_04.jpg: 544x1024 3 open_circuits, 19.3ms\n",
            "Speed: 4.0ms preprocess, 19.3ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/open_circuit_01_open_circuit_04.jpg â†’ Detected: 3\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/mouse_bite_09_mouse_bite_10.jpg: 800x1024 5 mouse_bites, 26.3ms\n",
            "Speed: 6.1ms preprocess, 26.3ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/mouse_bite_09_mouse_bite_10.jpg â†’ Detected: 5\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_07_short_09.jpg: 704x1024 5 shorts, 24.7ms\n",
            "Speed: 5.2ms preprocess, 24.7ms inference, 1.3ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/short_07_short_09.jpg â†’ Detected: 5\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/short_10_short_02.jpg: 928x1024 4 shorts, 29.3ms\n",
            "Speed: 10.4ms preprocess, 29.3ms inference, 1.3ms postprocess per image at shape (1, 3, 928, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/short_10_short_02.jpg â†’ Detected: 4\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_01_open_circuit_17.jpg: 544x1024 2 open_circuits, 19.3ms\n",
            "Speed: 4.2ms preprocess, 19.3ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/open_circuit_01_open_circuit_17.jpg â†’ Detected: 2\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_05_spurious_copper_07.jpg: 896x1024 7 spurious_coppers, 28.5ms\n",
            "Speed: 6.7ms preprocess, 28.5ms inference, 2.0ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/spurious_copper_05_spurious_copper_07.jpg â†’ Detected: 7\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_06_spurious_copper_06.jpg: 832x1024 5 spurious_coppers, 26.9ms\n",
            "Speed: 6.2ms preprocess, 26.9ms inference, 1.2ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/spurious_copper_06_spurious_copper_06.jpg â†’ Detected: 5\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_04_spurious_copper_16.jpg: 832x1024 2 spurious_coppers, 26.2ms\n",
            "Speed: 6.4ms preprocess, 26.2ms inference, 1.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/spurious_copper_04_spurious_copper_16.jpg â†’ Detected: 2\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_04_spurious_copper_11.jpg: 832x1024 2 spurious_coppers, 26.2ms\n",
            "Speed: 6.2ms preprocess, 26.2ms inference, 1.2ms postprocess per image at shape (1, 3, 832, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/spurious_copper_04_spurious_copper_11.jpg â†’ Detected: 2\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spurious_copper_05_spurious_copper_10.jpg: 896x1024 7 spurious_coppers, 27.7ms\n",
            "Speed: 6.8ms preprocess, 27.7ms inference, 1.2ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/spurious_copper_05_spurious_copper_10.jpg â†’ Detected: 7\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/missing_hole_05_missing_hole_06.jpg: 896x1024 5 missing_holes, 27.1ms\n",
            "Speed: 6.7ms preprocess, 27.1ms inference, 1.3ms postprocess per image at shape (1, 3, 896, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/missing_hole_05_missing_hole_06.jpg â†’ Detected: 5\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/open_circuit_07_open_circuit_09.jpg: 704x1024 5 open_circuits, 25.4ms\n",
            "Speed: 5.2ms preprocess, 25.4ms inference, 1.2ms postprocess per image at shape (1, 3, 704, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/open_circuit_07_open_circuit_09.jpg â†’ Detected: 5\n",
            "\n",
            "image 1/1 /content/dataset_yolo_seg/images/test/spur_09_spur_08.jpg: 800x1024 5 spurs, 27.8ms\n",
            "Speed: 6.2ms preprocess, 27.8ms inference, 1.2ms postprocess per image at shape (1, 3, 800, 1024)\n",
            "Results saved to \u001b[1m/content/runs/predict/exp_results\u001b[0m\n",
            "552 labels saved to /content/runs/predict/exp_results/labels\n",
            "/content/dataset_yolo_seg/images/test/spur_09_spur_08.jpg â†’ Detected: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gaez_oJ0MfsE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}